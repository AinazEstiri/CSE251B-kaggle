{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch_geometric.data import Data, Batch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape: (10000, 50, 110, 6)\n",
      "test_data's shape: (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create submission folder if it doesn't exist\n",
    "submission_dir = './submission'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# Uncomment the following block ONLY if you wish to inspect file paths in a Kaggle-like directory structure.\n",
    "# On your local system, you likely have the files in your local folder so this is not needed.\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "# Data Loading for Local Environment\n",
    "# Files are assumed to be in:\n",
    "# ./cse-251-b-2025/train.npz\n",
    "# ./cse-251-b-2025/test_input.npz\n",
    "\n",
    "train_file = np.load(\"./cse-251-b-2025/train.npz\")\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape:\", train_data.shape)  # Expected shape: (10000, 50, 110, 6)\n",
    "\n",
    "test_file = np.load(\"./cse-251-b-2025/test_input.npz\")\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape:\", test_data.shape)    # Expected shape: (2100, 50, 50, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot trajectories from one training scene (static plot)\n",
    "data_matrix = train_data[0]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for agent in range(data_matrix.shape[0]):\n",
    "    xs = data_matrix[agent, :, 0]\n",
    "    ys = data_matrix[agent, :, 1]\n",
    "    # Remove zeros (padding)\n",
    "    xs = xs[xs != 0]\n",
    "    ys = ys[ys != 0]\n",
    "    plt.plot(xs, ys, alpha=0.7)\n",
    "plt.title(\"Trajectories from one training scene\")\n",
    "plt.xlabel(\"x-coordinate\")\n",
    "plt.ylabel(\"y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# Create an animated gif for one training scene (exact code provided on kaggle)\n",
    "def make_gif(data_matrix, name='example'):\n",
    "    cmap = None\n",
    "    if sys.version_info.minor <= 7:\n",
    "        cmap = plt.cm.get_cmap(\"viridis\", 50)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"viridis\", 50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # Function to update plot for each frame\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        # Get data for current timestep\n",
    "        for i in range(1, data_matrix.shape[0]):\n",
    "            x = data_matrix[i, frame, 0]\n",
    "            y = data_matrix[i, frame, 1]\n",
    "            if x != 0 and y != 0:\n",
    "                xs = data_matrix[i, :frame+1, 0]  # Include current frame\n",
    "                ys = data_matrix[i, :frame+1, 1]  # Include current frame\n",
    "                # trim all zeros\n",
    "                mask = (xs != 0) & (ys != 0)  # Only keep points where both x and y are non-zero\n",
    "                xs = xs[mask]\n",
    "                ys = ys[mask]\n",
    "                # Only plot if we have points to plot\n",
    "                if len(xs) > 0 and len(ys) > 0:\n",
    "                    color = cmap(i)\n",
    "                    ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                    ax.scatter(x, y, s=80, color=color)\n",
    "        ax.plot(data_matrix[0, :frame, 0], data_matrix[0, :frame, 1],\n",
    "                color='tab:orange', label='Ego Vehicle')\n",
    "        ax.scatter(data_matrix[0, frame, 0], data_matrix[0, frame, 1],\n",
    "                   s=80, color='tab:orange')\n",
    "        # Set title with timestep\n",
    "        ax.set_title(f'Timestep {frame}')\n",
    "        # Set consistent axis limits\n",
    "        ax.set_xlim(data_matrix[:,:,0][data_matrix[:,:,0] != 0].min() - 10, \n",
    "                    data_matrix[:,:,0][data_matrix[:,:,0] != 0].max() + 10)\n",
    "        ax.set_ylim(data_matrix[:,:,1][data_matrix[:,:,1] != 0].min() - 10, \n",
    "                    data_matrix[:,:,1][data_matrix[:,:,1] != 0].max() + 10)\n",
    "        ax.legend()\n",
    "        return ax.collections + ax.lines\n",
    "\n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, data_matrix.shape[1], 3)),\n",
    "                                   interval=100, blit=True)\n",
    "    # Save as GIF\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "data_matrix = train_data[0]\n",
    "\n",
    "# make_gif(data_matrix, 'index0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant velocity from test set\n",
    "Untouched from original data loading notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this?\n",
    "run_constant_velocity_model = False\n",
    "\n",
    "if run_constant_velocity_model:\n",
    "    # Compute the velocity differences for the ego vehicle (agent index 0)\n",
    "    velocity_diff = test_data[..., 1:, :2] - test_data[..., :-1, :2]\n",
    "    print(\"Velocity difference shape:\", velocity_diff.shape)\n",
    "\n",
    "    # Compute average velocity for the ego vehicle (index 0) in each scene\n",
    "    constant_vel = np.mean(velocity_diff[:, 0, :, :], axis=1)\n",
    "    print(\"Constant velocity shape:\", constant_vel.shape)\n",
    "\n",
    "    # Generate predictions for 60 future time steps based on constant velocity\n",
    "    pred_y_const = np.zeros((test_data.shape[0], 60, 2))\n",
    "    starting_point = test_data[:, 0, -1, :2]  # Last observed position of ego vehicle\n",
    "\n",
    "    for t in range(60):\n",
    "        pred_y_const[:, t, :] = starting_point + (t + 1) * constant_vel\n",
    "\n",
    "    # Reshape predictions to submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_output_const = pred_y_const.reshape(-1, 2)\n",
    "    output_df_const = pd.DataFrame(pred_output_const, columns=['x', 'y'])\n",
    "    output_df_const.index.name = 'index'\n",
    "    # Save output in the submission folder\n",
    "    constant_vel_path = os.path.join(submission_dir, 'constant_vel_submission.csv')\n",
    "    output_df_const.to_csv(constant_vel_path)\n",
    "    print(f\"Constant velocity submission saved locally as '{constant_vel_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base LSTM given to us in the milestone notebook\n",
    "class BaseLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_dim=128, output_dim=60 * 2, dropout=0):\n",
    "        super(BaseLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi agent scene context model\n",
    "class SceneContextModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.agent_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ego_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 60 * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_flat):# In case you passed in a DataBatch\n",
    "        if not isinstance(x_flat, torch.Tensor):\n",
    "            x_flat = x_flat.x\n",
    "\n",
    "        B = x_flat.size(0)\n",
    "        x = x_flat.view(B, 50, 50, 6) #(B, agents, timesteps, features)\n",
    "        x_agents = x.view(B, 50, -1)  #(B, 50, 300)\n",
    "        agent_feats = self.agent_encoder(x_agents) #(B, 50, hidden_dim)\n",
    "        scene_context = agent_feats.mean(dim=1) #(B, hidden_dim)\n",
    "\n",
    "        ego_input = x[:, 0, :, :].reshape(B, -1) #(B, 300)\n",
    "        ego_feat = self.ego_encoder(ego_input) #(B, hidden_dim)\n",
    "\n",
    "        combined = torch.cat([ego_feat, scene_context], dim=1)\n",
    "        return self.decoder(combined) #(B, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "\n",
    "`TrajectoryDataset*` are taken from the milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                # future = future @ R gives DeprecationWarning: future a torch.Tensor\n",
    "                future = torch.from_numpy(np.dot(future.numpy(), R)) \n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        # future = future - origin -> same DeprecationWarning\n",
    "        future = torch.from_numpy(future.numpy() - origin)\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Change which model is used at the `model = ...(input_features, output_features)` line.\n",
    "\n",
    "Change which optimizer is used at the `optimizer = optim...` line.\n",
    "\n",
    "Do **NOT** change the `criterion`, as MSE is stated in the Data tab of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Taken from milestone notebook\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1/5 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:11<04:29, 11.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.009600 | train normalized MSE   0.7408 | val normalized MSE   0.1907, | val MAE   2.3548 | val MSE  19.0675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:22<04:15, 11.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.009216 | train normalized MSE   0.1947 | val normalized MSE   0.1869, | val MAE   2.2650 | val MSE  18.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:38<05:00, 13.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.008847 | train normalized MSE   0.1848 | val normalized MSE   0.1758, | val MAE   2.3501 | val MSE  17.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [00:54<05:01, 14.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.008493 | train normalized MSE   0.1657 | val normalized MSE   0.1597, | val MAE   2.2617 | val MSE  15.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [01:11<05:03, 15.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.008154 | train normalized MSE   0.1511 | val normalized MSE   0.1471, | val MAE   2.0130 | val MSE  14.7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [01:23<04:30, 14.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.007828 | train normalized MSE   0.1385 | val normalized MSE   0.1361, | val MAE   2.0576 | val MSE  13.6086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:34<03:59, 13.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.007514 | train normalized MSE   0.1297 | val normalized MSE   0.1275, | val MAE   1.8753 | val MSE  12.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 8/25 [01:46<03:36, 12.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.007214 | train normalized MSE   0.1235 | val normalized MSE   0.1131, | val MAE   1.7374 | val MSE  11.3069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 9/25 [01:59<03:26, 12.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.006925 | train normalized MSE   0.1176 | val normalized MSE   0.1160, | val MAE   1.7814 | val MSE  11.5956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 10/25 [02:12<03:14, 12.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.006648 | train normalized MSE   0.1143 | val normalized MSE   0.1194, | val MAE   1.8093 | val MSE  11.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 11/25 [02:26<03:03, 13.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.006382 | train normalized MSE   0.1156 | val normalized MSE   0.1181, | val MAE   1.7507 | val MSE  11.8076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 12/25 [02:38<02:47, 12.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.006127 | train normalized MSE   0.1138 | val normalized MSE   0.1190, | val MAE   1.7530 | val MSE  11.9023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [02:51<02:34, 12.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.005882 | train normalized MSE   0.1087 | val normalized MSE   0.1105, | val MAE   1.6732 | val MSE  11.0514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 14/25 [03:04<02:21, 12.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.005647 | train normalized MSE   0.1035 | val normalized MSE   0.1155, | val MAE   1.6756 | val MSE  11.5450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 15/25 [03:16<02:07, 12.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.005421 | train normalized MSE   0.1044 | val normalized MSE   0.1065, | val MAE   1.6508 | val MSE  10.6490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 16/25 [03:29<01:55, 12.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.005204 | train normalized MSE   0.1359 | val normalized MSE   0.1138, | val MAE   1.7823 | val MSE  11.3780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 17/25 [03:40<01:38, 12.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.004996 | train normalized MSE   0.1085 | val normalized MSE   0.1068, | val MAE   1.6582 | val MSE  10.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▏  | 18/25 [03:54<01:28, 12.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.004796 | train normalized MSE   0.1089 | val normalized MSE   0.1143, | val MAE   1.7086 | val MSE  11.4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  76%|███████▌  | 19/25 [04:11<01:23, 13.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.004604 | train normalized MSE   0.1040 | val normalized MSE   0.0989, | val MAE   1.5191 | val MSE   9.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 20/25 [04:22<01:05, 13.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.004420 | train normalized MSE   0.1004 | val normalized MSE   0.1037, | val MAE   1.6150 | val MSE  10.3678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  84%|████████▍ | 21/25 [04:33<00:49, 12.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.004243 | train normalized MSE   0.0975 | val normalized MSE   0.0993, | val MAE   1.5592 | val MSE   9.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 22/25 [04:44<00:36, 12.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.004073 | train normalized MSE   0.0956 | val normalized MSE   0.0981, | val MAE   1.5352 | val MSE   9.8106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▏| 23/25 [04:55<00:23, 11.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.003911 | train normalized MSE   0.0950 | val normalized MSE   0.0977, | val MAE   1.5294 | val MSE   9.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 24/25 [05:07<00:11, 11.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.003754 | train normalized MSE   0.0934 | val normalized MSE   0.0960, | val MAE   1.4886 | val MSE   9.5985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 25/25 [05:18<00:00, 12.75s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.003604 | train normalized MSE   0.0938 | val normalized MSE   0.0967, | val MAE   1.5176 | val MSE   9.6745\n",
      "\n",
      "FOLD 2/5 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:14<05:43, 14.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.009600 | train normalized MSE   0.1132 | val normalized MSE   0.1103, | val MAE   1.8102 | val MSE  11.0308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:30<05:57, 15.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.009216 | train normalized MSE   0.1077 | val normalized MSE   0.1035, | val MAE   1.6229 | val MSE  10.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:45<05:36, 15.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.008847 | train normalized MSE   0.1052 | val normalized MSE   0.1080, | val MAE   1.6936 | val MSE  10.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [00:59<05:08, 14.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.008493 | train normalized MSE   0.1046 | val normalized MSE   0.1060, | val MAE   1.6695 | val MSE  10.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [01:12<04:38, 13.92s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.008154 | train normalized MSE   0.0994 | val normalized MSE   0.1074, | val MAE   1.7136 | val MSE  10.7435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [01:23<04:11, 13.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.007828 | train normalized MSE   0.1040 | val normalized MSE   0.1068, | val MAE   1.6845 | val MSE  10.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:35<03:50, 12.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.007514 | train normalized MSE   0.1026 | val normalized MSE   0.0979, | val MAE   1.5907 | val MSE   9.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 8/25 [01:53<04:04, 14.36s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.007214 | train normalized MSE   0.0962 | val normalized MSE   0.0964, | val MAE   1.5672 | val MSE   9.6437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 9/25 [02:10<04:03, 15.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.006925 | train normalized MSE   0.0944 | val normalized MSE   0.0962, | val MAE   1.5420 | val MSE   9.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 10/25 [02:28<03:59, 15.96s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.006648 | train normalized MSE   0.0952 | val normalized MSE   0.0954, | val MAE   1.5949 | val MSE   9.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 11/25 [02:45<03:46, 16.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.006382 | train normalized MSE   0.0935 | val normalized MSE   0.0946, | val MAE   1.5133 | val MSE   9.4564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 12/25 [03:02<03:35, 16.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.006127 | train normalized MSE   0.0922 | val normalized MSE   0.0955, | val MAE   1.5693 | val MSE   9.5519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [03:17<03:12, 16.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.005882 | train normalized MSE   0.0917 | val normalized MSE   0.0968, | val MAE   1.5191 | val MSE   9.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 14/25 [03:30<02:45, 15.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.005647 | train normalized MSE   0.1821 | val normalized MSE   0.1149, | val MAE   1.8422 | val MSE  11.4893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 14/25 [03:44<02:56, 16.07s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.005421 | train normalized MSE   0.1082 | val normalized MSE   0.1050, | val MAE   1.7097 | val MSE  10.5047\n",
      "Early stop!\n",
      "\n",
      "FOLD 3/5 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:13<05:16, 13.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.009600 | train normalized MSE   0.1078 | val normalized MSE   0.0984, | val MAE   1.6015 | val MSE   9.8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:26<05:05, 13.29s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.009216 | train normalized MSE   0.1056 | val normalized MSE   0.1082, | val MAE   1.6804 | val MSE  10.8169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:39<04:47, 13.06s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.008847 | train normalized MSE   0.1010 | val normalized MSE   0.0958, | val MAE   1.5883 | val MSE   9.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [00:55<05:02, 14.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.008493 | train normalized MSE   0.0975 | val normalized MSE   0.0950, | val MAE   1.5023 | val MSE   9.5049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [01:06<04:22, 13.12s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.008154 | train normalized MSE   0.0953 | val normalized MSE   0.0945, | val MAE   1.5539 | val MSE   9.4457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [01:17<03:55, 12.37s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.007828 | train normalized MSE   0.0999 | val normalized MSE   0.0957, | val MAE   1.5235 | val MSE   9.5734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:29<03:37, 12.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.007514 | train normalized MSE   0.0947 | val normalized MSE   0.0954, | val MAE   1.5778 | val MSE   9.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 8/25 [01:40<03:20, 11.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.007214 | train normalized MSE   0.0948 | val normalized MSE   0.0957, | val MAE   1.5742 | val MSE   9.5674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 9/25 [01:52<03:11, 11.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.006925 | train normalized MSE   0.0937 | val normalized MSE   0.0900, | val MAE   1.4533 | val MSE   8.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 10/25 [02:08<03:16, 13.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.006648 | train normalized MSE   0.0918 | val normalized MSE   0.0905, | val MAE   1.4825 | val MSE   9.0490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 11/25 [02:20<03:01, 12.93s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.006382 | train normalized MSE   0.0931 | val normalized MSE   0.0904, | val MAE   1.4733 | val MSE   9.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 12/25 [02:32<02:42, 12.52s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.006127 | train normalized MSE   0.0905 | val normalized MSE   0.0895, | val MAE   1.4611 | val MSE   8.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [02:44<02:27, 12.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.005882 | train normalized MSE   0.0907 | val normalized MSE   0.0888, | val MAE   1.4415 | val MSE   8.8774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 14/25 [02:54<02:10, 11.88s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.005647 | train normalized MSE   0.0908 | val normalized MSE   0.0890, | val MAE   1.5090 | val MSE   8.9034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 15/25 [03:06<01:56, 11.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.005421 | train normalized MSE   0.0891 | val normalized MSE   0.0927, | val MAE   1.5699 | val MSE   9.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 16/25 [03:17<01:44, 11.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.005204 | train normalized MSE   0.0878 | val normalized MSE   0.0888, | val MAE   1.4475 | val MSE   8.8801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 17/25 [03:29<01:32, 11.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.004996 | train normalized MSE   0.0883 | val normalized MSE   0.0893, | val MAE   1.5154 | val MSE   8.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 17/25 [03:40<01:43, 12.95s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.004796 | train normalized MSE   0.0874 | val normalized MSE   0.0892, | val MAE   1.4528 | val MSE   8.9185\n",
      "Early stop!\n",
      "\n",
      "FOLD 4/5 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:10<04:14, 10.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.009600 | train normalized MSE   0.0982 | val normalized MSE   0.0841, | val MAE   1.4852 | val MSE   8.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:21<04:08, 10.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.009216 | train normalized MSE   0.0952 | val normalized MSE   0.0873, | val MAE   1.4940 | val MSE   8.7343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:32<03:58, 10.84s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.008847 | train normalized MSE   0.0941 | val normalized MSE   0.0826, | val MAE   1.4069 | val MSE   8.2641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [00:43<03:45, 10.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.008493 | train normalized MSE   0.0937 | val normalized MSE   0.0938, | val MAE   1.5416 | val MSE   9.3790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [00:54<03:39, 10.99s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.008154 | train normalized MSE   0.0945 | val normalized MSE   0.0822, | val MAE   1.3856 | val MSE   8.2153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [01:05<03:29, 11.03s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.007828 | train normalized MSE   0.0912 | val normalized MSE   0.0874, | val MAE   1.5367 | val MSE   8.7420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:16<03:19, 11.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.007514 | train normalized MSE   0.1003 | val normalized MSE   0.0942, | val MAE   1.6383 | val MSE   9.4165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:28<03:47, 12.62s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.007214 | train normalized MSE   0.0963 | val normalized MSE   0.0846, | val MAE   1.4081 | val MSE   8.4637\n",
      "Early stop!\n",
      "\n",
      "FOLD 5/5 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 1/25 [00:12<05:02, 12.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.009600 | train normalized MSE   0.0966 | val normalized MSE   0.0971, | val MAE   1.6028 | val MSE   9.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 2/25 [00:29<05:53, 15.37s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.009216 | train normalized MSE   0.0929 | val normalized MSE   0.1002, | val MAE   1.6194 | val MSE  10.0250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 3/25 [00:47<05:57, 16.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.008847 | train normalized MSE   0.0911 | val normalized MSE   0.0946, | val MAE   1.4750 | val MSE   9.4552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 4/25 [01:05<05:56, 16.97s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.008493 | train normalized MSE   0.0912 | val normalized MSE   0.0999, | val MAE   1.5941 | val MSE   9.9876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 5/25 [01:21<05:31, 16.56s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.008154 | train normalized MSE   0.0900 | val normalized MSE   0.0922, | val MAE   1.4544 | val MSE   9.2159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 6/25 [01:35<04:58, 15.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.007828 | train normalized MSE   0.0904 | val normalized MSE   0.0952, | val MAE   1.5162 | val MSE   9.5216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 7/25 [01:49<04:31, 15.11s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.007514 | train normalized MSE   0.0880 | val normalized MSE   0.0923, | val MAE   1.4602 | val MSE   9.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 8/25 [02:01<04:00, 14.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.007214 | train normalized MSE   0.0877 | val normalized MSE   0.0910, | val MAE   1.4303 | val MSE   9.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 9/25 [02:13<03:38, 13.63s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.006925 | train normalized MSE   0.0883 | val normalized MSE   0.0885, | val MAE   1.4257 | val MSE   8.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 10/25 [02:25<03:17, 13.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.006648 | train normalized MSE   0.0855 | val normalized MSE   0.0915, | val MAE   1.4713 | val MSE   9.1465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 11/25 [02:36<02:55, 12.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.006382 | train normalized MSE   0.0858 | val normalized MSE   0.0898, | val MAE   1.4198 | val MSE   8.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 12/25 [02:47<02:35, 11.98s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.006127 | train normalized MSE   0.0849 | val normalized MSE   0.0918, | val MAE   1.4674 | val MSE   9.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [02:58<02:20, 11.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.005882 | train normalized MSE   0.0876 | val normalized MSE   0.0902, | val MAE   1.4761 | val MSE   9.0184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 13/25 [03:09<02:55, 14.59s/epoch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.005647 | train normalized MSE   0.0852 | val normalized MSE   0.0895, | val MAE   1.4648 | val MSE   8.9457\n",
      "Early stop!\n",
      "Submission saved locally as: './submission\\submission-2025-05-08_05-46PM.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of input features after flattening and number of output features\n",
    "# Note: LSTM models take features in different dimensions\n",
    "input_features = 50 * 50 * 6   # 50 agents, 50 time steps, 6 dimensions each (15000 input features)\n",
    "output_features = 60 * 2       # 60 future time steps, 2 dimensions (x, y) (120 output features)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "starting_lr = 1e-2\n",
    "gamma = 0.96\n",
    "scale = 10.0\n",
    "\n",
    "# Ensure this is pointing to the right model\n",
    "OurModel = BaseLSTM(input_dim=6, hidden_dim=256, output_dim=output_features).to(device)\n",
    "# OurModel = SceneContextModel(hidden_dim=864).to(device)\n",
    "\n",
    "def train_model(full_training_data: np.ndarray, \n",
    "                batch_size: int =64, epochs: int =10, num_folds: int =5,\n",
    "                early_stopping_patience: int=5, early_stopping_threshold: float=1e-3):\n",
    "    global starting_lr, gamma, scale\n",
    "\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True, random_state=SEED)\n",
    "\n",
    "    # Perform K-fold cross validation, then pick the best model\n",
    "    best_model = None\n",
    "    overall_best_val_loss = float(\"inf\")\n",
    "\n",
    "    # Resources used:\n",
    "    # Project milestone notebook\n",
    "    # https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md\n",
    "    for fold_i, (train_idx, val_idx) in enumerate(kfold.split(full_training_data)):\n",
    "        print(f\"\\nFOLD {fold_i + 1}/{num_folds} ==================================\")\n",
    "\n",
    "        # Prepare data from this fold\n",
    "        train_fold = full_training_data[train_idx]\n",
    "        val_fold = full_training_data[val_idx]\n",
    "        collate_func = None     # Optional for DataLoader, taken from milestone notebook\n",
    "        if isinstance(OurModel, SceneContextModel):\n",
    "            train_x = train_fold[..., :50, :]\n",
    "            train_y = train_fold[:, 0, 50:, :2]\n",
    "            X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n",
    "            y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n",
    "            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "            val_x = val_fold[..., :50, :]\n",
    "            val_y = val_fold[:, 0, 50:, :2]\n",
    "            X_val_tensor = torch.FloatTensor(val_x).reshape((-1, input_features))\n",
    "            y_val_tensor = torch.FloatTensor(val_y).reshape((-1, output_features))\n",
    "            val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "            # Smaller LR, more patience\n",
    "            starting_lr = 1e-2\n",
    "            early_stopping_patience = 10\n",
    "        else:\n",
    "            # TrajectoryDataset expects numpy arrays\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            train_dataset = TrajectoryDatasetTrain(train_fold, scale=scale, augment=True)\n",
    "            val_dataset = TrajectoryDatasetTrain(val_fold, scale=scale, augment=False)\n",
    "       \n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "        # Create the model, loss criterion, and optimizer (reset per fold, to find the best model)\n",
    "        # DO NOT CHANGE CRITERION\n",
    "        criterion = nn.MSELoss()\n",
    "        model = OurModel\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=starting_lr, weight_decay=1e-2)\n",
    "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "        # How many epochs to allow for stagnant val losses (within a threshold)\n",
    "        best_val_loss = float(\"inf\")\n",
    "        no_improvement = 0\n",
    "\n",
    "        # Training loop: taken from milestone notebook\n",
    "        for epoch in tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch in train_dataloader:\n",
    "                batch_x = None\n",
    "                batch_y = None\n",
    "                if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                    batch_x, batch_y = batch\n",
    "                else: # DataBatch type\n",
    "                    batch = batch.to(device)\n",
    "                    batch_x = batch.x\n",
    "                    batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation (fully taken from milestone notebook)\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_mae = 0\n",
    "            val_mse = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    batch_x = None\n",
    "                    batch_y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        batch_x, batch_y = batch\n",
    "                    else: # DataBatch type\n",
    "                        batch = batch.to(device)\n",
    "                        batch_x = batch.x\n",
    "                        batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                    pred = model(batch_x)\n",
    "                    val_loss += criterion(pred, batch_y).item()\n",
    "\n",
    "                    # show MAE and MSE with unnormalized data\n",
    "                    y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        y = batch_y\n",
    "                    else: # DataBatch type\n",
    "                        y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                        pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                        y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                    val_mae += nn.L1Loss()(pred, y).item()\n",
    "                    val_mse += nn.MSELoss()(pred, y).item()\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_mae /= len(val_dataloader)\n",
    "            val_mse /= len(val_dataloader)\n",
    "            \n",
    "            scheduler.step()\n",
    "\n",
    "            tqdm.write(f\"Epoch {(epoch + 1):03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "            if val_loss < best_val_loss - early_stopping_threshold:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "\n",
    "                # Better than the overall seen so far?\n",
    "                if best_val_loss < overall_best_val_loss:\n",
    "                    best_model = model\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                if no_improvement >= early_stopping_patience:\n",
    "                    print(\"Early stop!\")\n",
    "                    break\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# Train the model (tweak batch_size and epochs as needed)\n",
    "trained_model = train_model(train_data, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Define a function for prediction on the test set\n",
    "# Mostly taken from milestone notebook\n",
    "def predict(model, X_test):\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        if isinstance(OurModel, SceneContextModel):\n",
    "            X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features)).to(device)\n",
    "            pred = model(X_test_tensor).cpu().reshape((-1, 60, 2))\n",
    "            pred_list.append(pred.numpy())\n",
    "        else: # Using DataBatch type from a DataLoader\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            test_dataset = TrajectoryDatasetTest(X_test, scale=scale)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred_norm = model(batch.x)\n",
    "            \n",
    "            # Reshape the prediction to (N, 60, 2)\n",
    "                pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
    "                pred_list.append(pred.cpu().numpy())\n",
    "\n",
    "    # Reshape predictions to match submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "    pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "    output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "    output_df.index.name = 'index'\n",
    "    return output_df\n",
    "\n",
    "# Make predictions on the test set\n",
    "model_predictions_df = predict(trained_model, test_data)\n",
    "\n",
    "# Save output in the submission foldder, timestamped!\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "\n",
    "submission_path = os.path.join(submission_dir, f\"submission-{timestamp}.csv\")\n",
    "model_predictions_df.to_csv(submission_path)\n",
    "print(f\"Submission saved locally as: '{submission_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save and load the model (should correspond to what was trained!)\n",
    "def save_model(model, path=\"our_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "\n",
    "def load_model(path=\"our_model.pth\"):\n",
    "    loaded_model = OurModel(input_features, output_features)\n",
    "    loaded_model.load_state_dict(torch.load(path))\n",
    "    loaded_model.eval()\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# save_model(model)\n",
    "# model = load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
