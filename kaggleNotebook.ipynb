{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission folder if it doesn't exist\n",
    "submission_dir = './submission'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# Uncomment the following block ONLY if you wish to inspect file paths in a Kaggle-like directory structure.\n",
    "# On your local system, you likely have the files in your local folder so this is not needed.\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "# Data Loading for Local Environment\n",
    "# Files are assumed to be in:\n",
    "# ./cse-251-b-2025/train.npz\n",
    "# ./cse-251-b-2025/test_input.npz\n",
    "\n",
    "running_on_kaggle = False\n",
    "\n",
    "if running_on_kaggle:\n",
    "    train_file = np.load(\"/kaggle/input/cse-251-b-2025/train.npz\")\n",
    "    test_file = np.load(\"/kaggle/input/cse-251-b-2025/test_input.npz\")\n",
    "else:\n",
    "    train_file = np.load(\"./cse-251-b-2025/train.npz\")\n",
    "    test_file = np.load(\"./cse-251-b-2025/test_input.npz\")\n",
    "\n",
    "train_data = train_file['data']\n",
    "test_data = test_file['data']\n",
    "\n",
    "print(\"train_data's shape:\", train_data.shape)  # Expected shape: (10000, 50, 110, 6)\n",
    "print(\"test_data's shape:\", test_data.shape)    # Expected shape: (2100, 50, 50, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run visualizations?\n",
    "run_visualizations: bool = False\n",
    "\n",
    "# From data loading notebook\n",
    "def plot_one_training_scene(idx: int = 0):\n",
    "    # Plot trajectories from one training scene (static plot)\n",
    "    data_matrix = train_data[idx]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for agent in range(data_matrix.shape[idx]):\n",
    "        xs = data_matrix[agent, :, 0]\n",
    "        ys = data_matrix[agent, :, 1]\n",
    "        # Remove zeros (padding)\n",
    "        xs = xs[xs != 0]\n",
    "        ys = ys[ys != 0]\n",
    "        plt.plot(xs, ys, alpha=0.7)\n",
    "    plt.title(\"Trajectories from one training scene\")\n",
    "    plt.xlabel(\"x-coordinate\")\n",
    "    plt.ylabel(\"y-coordinate\")\n",
    "    plt.show()\n",
    "\n",
    "# Create an animated gif for one training scene (exact code provided on kaggle)\n",
    "def make_gif(data_matrix, name='example'):\n",
    "    cmap = None\n",
    "    if sys.version_info.minor <= 7:\n",
    "        cmap = plt.cm.get_cmap(\"viridis\", 50)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"viridis\", 50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # Function to update plot for each frame\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        # Get data for current timestep\n",
    "        for i in range(1, data_matrix.shape[0]):\n",
    "            x = data_matrix[i, frame, 0]\n",
    "            y = data_matrix[i, frame, 1]\n",
    "            if x != 0 and y != 0:\n",
    "                xs = data_matrix[i, :frame+1, 0]  # Include current frame\n",
    "                ys = data_matrix[i, :frame+1, 1]  # Include current frame\n",
    "                # trim all zeros\n",
    "                mask = (xs != 0) & (ys != 0)  # Only keep points where both x and y are non-zero\n",
    "                xs = xs[mask]\n",
    "                ys = ys[mask]\n",
    "                # Only plot if we have points to plot\n",
    "                if len(xs) > 0 and len(ys) > 0:\n",
    "                    color = cmap(i)\n",
    "                    ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                    ax.scatter(x, y, s=80, color=color)\n",
    "        ax.plot(data_matrix[0, :frame, 0], data_matrix[0, :frame, 1],\n",
    "                color='tab:orange', label='Ego Vehicle')\n",
    "        ax.scatter(data_matrix[0, frame, 0], data_matrix[0, frame, 1],\n",
    "                   s=80, color='tab:orange')\n",
    "        # Set title with timestep\n",
    "        ax.set_title(f'Timestep {frame}')\n",
    "        # Set consistent axis limits\n",
    "        ax.set_xlim(data_matrix[:,:,0][data_matrix[:,:,0] != 0].min() - 10, \n",
    "                    data_matrix[:,:,0][data_matrix[:,:,0] != 0].max() + 10)\n",
    "        ax.set_ylim(data_matrix[:,:,1][data_matrix[:,:,1] != 0].min() - 10, \n",
    "                    data_matrix[:,:,1][data_matrix[:,:,1] != 0].max() + 10)\n",
    "        ax.legend()\n",
    "        return ax.collections + ax.lines\n",
    "\n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, data_matrix.shape[1], 3)),\n",
    "                                   interval=100, blit=True)\n",
    "    # Save as GIF\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "if run_visualizations:\n",
    "    plot_one_training_scene(0)\n",
    "    make_gif(train_data[0], 'index0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant velocity from test set\n",
    "Untouched from original data loading notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run constant velocity model (Kaggle score of ~50)?\n",
    "run_constant_velocity_model: bool = False\n",
    "\n",
    "if run_constant_velocity_model:\n",
    "    # Compute the velocity differences for the ego vehicle (agent index 0)\n",
    "    velocity_diff = test_data[..., 1:, :2] - test_data[..., :-1, :2]\n",
    "    print(\"Velocity difference shape:\", velocity_diff.shape)\n",
    "\n",
    "    # Compute average velocity for the ego vehicle (index 0) in each scene\n",
    "    constant_vel = np.mean(velocity_diff[:, 0, :, :], axis=1)\n",
    "    print(\"Constant velocity shape:\", constant_vel.shape)\n",
    "\n",
    "    # Generate predictions for 60 future time steps based on constant velocity\n",
    "    pred_y_const = np.zeros((test_data.shape[0], 60, 2))\n",
    "    starting_point = test_data[:, 0, -1, :2]  # Last observed position of ego vehicle\n",
    "\n",
    "    for t in range(60):\n",
    "        pred_y_const[:, t, :] = starting_point + (t + 1) * constant_vel\n",
    "\n",
    "    # Reshape predictions to submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_output_const = pred_y_const.reshape(-1, 2)\n",
    "    output_df_const = pd.DataFrame(pred_output_const, columns=['x', 'y'])\n",
    "    output_df_const.index.name = 'index'\n",
    "    # Save output in the submission folder\n",
    "    constant_vel_path = os.path.join(submission_dir, 'constant_vel_submission.csv')\n",
    "    output_df_const.to_csv(constant_vel_path)\n",
    "    print(f\"Constant velocity submission saved locally as '{constant_vel_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model with residual blocks: ineffective for TimeSeries data\n",
    "class BasicMLP(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # Lazy layers infer the input size instead of having to explicitly pass it in\n",
    "        # Backbone: linear -> BatchNorm -> PReLU -> Dropout\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        ) # Note: residual width must match the last width of the net\n",
    "\n",
    "        # Residual block added to avoid vanishing gradient issue\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(256),\n",
    "        )\n",
    "\n",
    "        # Infer last input shape, then do final projection (60*2)\n",
    "        self.head = nn.LazyLinear(output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Original forward loop\n",
    "        # # (batch, 50, 50, 6) or flattened already\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # h = self.net(x) #(batch, 256)\n",
    "        # h = h + self.residual(h)  # residual skip\n",
    "        # return self.head(h) #(batch, 120)\n",
    "\n",
    "        # Taken from milestone notebook (tensor format)\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        # x = x[:, :, :, :2] # (batch, 50, 50, 2)\n",
    "        x = x.reshape(-1, 50 * 50 * 6)\n",
    "        x = self.net(x)\n",
    "        x = x + self.residual(x)\n",
    "        x = self.head(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base LSTM given to us in the milestone notebook\n",
    "class BaseLSTM(nn.Module):\n",
    "    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n",
    "        super(BaseLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi agent scene context model\n",
    "class SceneContextModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.agent_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ego_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 60 * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_flat):\n",
    "        # x = data.x\n",
    "        # x = x[:, :, :, :2] # (batch, 50, 50, 2)\n",
    "        # x = x.reshape(-1, 50 * 50 * 6)\n",
    "        # x = self.mlp(x)\n",
    "        # return x.view(-1, 60, 2)\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x_flat, torch.Tensor):\n",
    "            x_flat = x_flat.x\n",
    "\n",
    "        B = x_flat.size(0)\n",
    "        x = x_flat.view(B, 50, 50, 6) #(B, agents, timesteps, features)\n",
    "        x_agents = x.view(B, 50, -1)  #(B, 50, 300)\n",
    "        agent_feats = self.agent_encoder(x_agents) #(B, 50, hidden_dim)\n",
    "        scene_context = agent_feats.mean(dim=1) #(B, hidden_dim)\n",
    "\n",
    "        ego_input = x[:, 0, :, :].reshape(B, -1) #(B, 300)\n",
    "        ego_feat = self.ego_encoder(ego_input) #(B, hidden_dim)\n",
    "\n",
    "        combined = torch.cat([ego_feat, scene_context], dim=1)\n",
    "\n",
    "        out = self.decoder(combined) #(B, 120)\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended from the base LSTM model\n",
    "class LSTMWithMLP(nn.Module):\n",
    "    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n",
    "        super(LSTMWithMLP, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.fc = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        x = self.net(lstm_out[:, -1, :])\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMButTwo(nn.Module):\n",
    "    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n",
    "        super(LSTMButTwo, self).__init__()\n",
    "        self.second_out_dim = 128\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.lstm_2 = nn.LSTM(hidden_dim, self.second_out_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(self.second_out_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_first_out, _ = self.lstm_1(x)\n",
    "        lstm_second_out, _ = self.lstm_2(lstm_first_out)\n",
    "\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        lstm_out = lstm_second_out[:, -1, :]\n",
    "        x = self.fc(lstm_out)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "\n",
    "`TrajectoryDataset*` are taken from the milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                # future = future @ R gives DeprecationWarning: future a torch.Tensor\n",
    "                future = torch.from_numpy(np.dot(future.numpy(), R)) \n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        # future = future - origin -> same DeprecationWarning\n",
    "        future = torch.from_numpy(future.numpy() - origin)\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Change which model is used at the `model = ...(input_features, output_features)` line.\n",
    "\n",
    "Change which optimizer is used at the `optimizer = optim...` line.\n",
    "\n",
    "Do **NOT** change the `criterion`, as MSE is stated in the Data tab of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from milestone notebook\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save and load the model (should correspond to what was trained!)\n",
    "def save_model(model, path=\"our_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "\n",
    "def load_model(model_instance, path=\"our_model.pth\"):\n",
    "    loaded_model = model_instance\n",
    "    loaded_model.load_state_dict(torch.load(path))\n",
    "    loaded_model.eval()\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# save_model(trained_model)\n",
    "# model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d_%I-%M%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters\n",
    "\n",
    "# Calculate number of input features after flattening and number of output features\n",
    "# Note: LSTM models take features in different dimensions\n",
    "input_features:int = 50 * 50 * 6   # 50 agents, 50 time steps, 6 dimensions each (15000 input features)\n",
    "output_features:int = 60 * 2       # 60 future time steps, 2 dimensions (x, y) (120 output features)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size: int = 32\n",
    "num_folds: int = 4\n",
    "early_stopping_patience: int = 40\n",
    "early_stopping_threshold: float = 1e-5\n",
    "epochs: int = 300\n",
    "starting_lr: float = 1e-3\n",
    "scale: float = 10.0\n",
    "weight_decay: float = 1e-2\n",
    "\n",
    "lstm_hidden_dim: int = 128\n",
    "\n",
    "\n",
    "SEED: int = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! To change which model is used: comment/uncomment below\n",
    "# Easily swap models by changing what is returned (called in training and test to avoid conflicts)\n",
    "def get_model():\n",
    "    global lstm_hidden_dim, input_features, output_features\n",
    "\n",
    "    # return BasicMLP(input_features, output_features).to(device)\n",
    "    # return BaseLSTM(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n",
    "    # return SceneContextModel(hidden_dim=864).to(device)\n",
    "    # return LSTMWithMLP(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n",
    "    return LSTMButTwo(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(full_training_data: np.ndarray, \n",
    "                batch_size:int = 64, epochs:int = 10, num_folds:int = 5,\n",
    "                early_stopping_patience:int = 5, early_stopping_threshold:float = 1e-3):\n",
    "    global starting_lr, gamma, scale, lstm_hidden_dim, output_features, weight_decay\n",
    "\n",
    "    # Time series data needs to keep its data in relative order, so no shuffling can occur\n",
    "    #   like in regular KFold cross validation\n",
    "    splitter = TimeSeriesSplit(n_splits=num_folds, test_size=int(0.15 * len(full_training_data)))\n",
    "\n",
    "    # Perform cross-validation, the best model will be saved as \"best_model.pt\" to be loaded in later\n",
    "    overall_best_val_loss = float(\"inf\")\n",
    "    overall_best_seen_at = (0, 0) #(epoch, fold)\n",
    "\n",
    "    # Resources used:\n",
    "    # Project milestone notebook\n",
    "    # https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md\n",
    "    # https://www.geeksforgeeks.org/time-series-cross-validation/\n",
    "    for fold_i, (train_idx, val_idx) in enumerate(splitter.split(full_training_data)):\n",
    "        print(f\"\\nFOLD {fold_i + 1}/{num_folds} ==================================\")\n",
    "\n",
    "        # Create the model, loss criterion, and optimizer (reset per fold, to find the best model)\n",
    "        # If you change the model here, ensure its the same in the test loop!\n",
    "        # DO NOT CHANGE CRITERION\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        model = get_model()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=starting_lr, weight_decay=weight_decay)\n",
    "        schedulers: list[lr_scheduler.LRScheduler] =[\n",
    "            lr_scheduler.ExponentialLR(optimizer, gamma=0.995),\n",
    "            lr_scheduler.MultiStepLR(\n",
    "                optimizer,\n",
    "                milestones= list(range(25, epochs, 25)),\n",
    "                gamma=0.80,\n",
    "            ),\n",
    "            # lr_scheduler.MultiStepLR(\n",
    "            #     optimizer,\n",
    "            #     milestones= list(range(100, epochs, 100)),\n",
    "            #     gamma=0.5,\n",
    "            # ),\n",
    "            lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, \n",
    "                T_max= int(epochs * 0.9),\n",
    "                # T_0 = 50,\n",
    "                # T_mult = 2,\n",
    "                eta_min=1e-6\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Prepare data from this fold\n",
    "        train_fold: np.ndarray = full_training_data[train_idx]\n",
    "        val_fold: np.ndarray = full_training_data[val_idx]\n",
    "        collate_func = None     # Optional for DataLoader, taken from milestone notebook\n",
    "        if not isinstance(model, SceneContextModel):\n",
    "            # LSTM can handle the timeseries data directly\n",
    "            # TrajectoryDataset expects numpy arrays\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            train_dataset = TrajectoryDatasetTrain(train_fold, scale=scale, augment=True)\n",
    "            val_dataset = TrajectoryDatasetTrain(val_fold, scale=scale, augment=False)\n",
    "        else:\n",
    "            train_x: np.ndarray = train_fold[..., :50, :]\n",
    "            train_y: np.ndarray = train_fold[:, 0, 50:, :2]\n",
    "            X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n",
    "            y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n",
    "            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "            val_x: np.ndarray = val_fold[..., :50, :]\n",
    "            val_y: np.ndarray = val_fold[:, 0, 50:, :2]\n",
    "            X_val_tensor = torch.FloatTensor(val_x).reshape((-1, input_features))\n",
    "            y_val_tensor = torch.FloatTensor(val_y).reshape((-1, output_features))\n",
    "            val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "        best_val_loss: float = float(\"inf\")\n",
    "        no_improvement: int = 0\n",
    "\n",
    "        # Training and validation loops are taken from the milestone notebook,\n",
    "        #   with modifications to allow for different data loading shapes      \n",
    "        for epoch in tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch in train_dataloader:\n",
    "                batch_x = None\n",
    "                batch_y = None\n",
    "                if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                    batch_x, batch_y = batch\n",
    "                    batch_y = batch_y.view(-1, 60, 2)\n",
    "                else: # DataBatch type\n",
    "                    batch = batch.to(device)\n",
    "                    batch_x = batch.x\n",
    "                    batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_mae = 0\n",
    "            val_mse = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    batch_x = None\n",
    "                    batch_y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        batch_x, batch_y = batch\n",
    "                        batch_y = batch_y.view(-1, 60, 2)\n",
    "                    else: # DataBatch type\n",
    "                        batch = batch.to(device)\n",
    "                        batch_x = batch.x\n",
    "                        batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                    pred = model(batch_x)\n",
    "                    val_loss += criterion(pred, batch_y).item()\n",
    "\n",
    "                    # show MAE and MSE with unnormalized data\n",
    "                    y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        y = batch_y.view(-1, 60, 2)\n",
    "                    else: # DataBatch type\n",
    "                        pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                        y = batch_y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                    val_mae += nn.L1Loss()(pred, y).item()\n",
    "                    val_mse += nn.MSELoss()(pred, y).item()\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_mae /= len(val_dataloader)\n",
    "            val_mse /= len(val_dataloader)\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                tqdm.write(f\"Epoch {(epoch + 1):03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss - early_stopping_threshold:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "\n",
    "                # Better than the overall seen so far?\n",
    "                if best_val_loss < overall_best_val_loss:\n",
    "                    overall_best_val_loss = best_val_loss\n",
    "                    overall_best_seen_at = (epoch + 1, fold_i + 1)\n",
    "                    torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                if no_improvement >= early_stopping_patience:\n",
    "                    print(f\"==== EARLY STOP at epoch {(epoch + 1):03d}\")\n",
    "                    break\n",
    "\n",
    "            for sched in schedulers:\n",
    "                sched.step()\n",
    "\n",
    "        # Clean up after the fold finishes to prevent slower folds later\n",
    "        # https://discuss.pytorch.org/t/how-to-delete-a-tensor-in-gpu-to-free-up-memory/48879\n",
    "        torch.cuda.empty_cache()\n",
    "        del train_dataloader, train_dataset, val_dataloader, val_dataset\n",
    "\n",
    "    print(f\"BEST VALIDATION LOSS (NORMALIZED MSE) SEEN: {overall_best_val_loss}, AT (epoch, fold) = {overall_best_seen_at}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model saved during testing to use on X_test\n",
    "# Mostly taken from milestone notebook\n",
    "def predict(X_test: np.ndarray, best_model_path: str = \"best_model.pt\"):\n",
    "    global scale, batch_size, lstm_hidden_dim, output_features\n",
    "\n",
    "    # Ensure this aligns with the trained model!\n",
    "    best_model = torch.load(best_model_path)\n",
    "    model = get_model()\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        if not isinstance(model, SceneContextModel): # Using DataBatch type from a DataLoader\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            test_dataset = TrajectoryDatasetTest(X_test, scale=scale)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred_norm = model(batch.x)\n",
    "\n",
    "                # Reshape the prediction to (N, 60, 2)\n",
    "                pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
    "                pred_list.append(pred.cpu().numpy())\n",
    "        else:\n",
    "            X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features)).to(device)\n",
    "            pred = model(X_test_tensor).cpu().reshape((-1, 60, 2))\n",
    "            pred_list.append(pred.numpy())\n",
    "\n",
    "    # Reshape predictions to match submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "    pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "    output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "    output_df.index.name = 'index'\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model (tweak batch_size and epochs as needed at top of this block)\n",
    "# Saved as \"best_model.pt\" to be loaded in during testing\n",
    "train_model(train_data, batch_size=batch_size, epochs=epochs, num_folds=num_folds,\n",
    "            early_stopping_patience=early_stopping_patience,\n",
    "            early_stopping_threshold=early_stopping_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "model_predictions_df = predict(test_data)\n",
    "assert len(model_predictions_df) == 126000, f\"Incorrect number of rows in output, expected 126000, got {len(model_predictions_df)}\"\n",
    "\n",
    "# Save output in the submission foldder, timestamped!\n",
    "submission_path = os.path.join(submission_dir, f\"submission-{get_timestamp()}.csv\")\n",
    "model_predictions_df.to_csv(submission_path)\n",
    "print(f\"Submission saved locally as: '{submission_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize predictions\n",
    "\n",
    "These functions are taken from the milestone notebook, with minor additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(ax, pred, gt, title=None):\n",
    "    ax.cla()\n",
    "    # Plot the predicted future trajectory\n",
    "    ax.plot(pred[0,:60,0], pred[0,:60,1], color='palevioletred', label='Predicted Future Trajectory')\n",
    "    \n",
    "    # Plot the ground truth future trajectory\n",
    "    ax.plot(gt[0,:60,0], gt[0,:60,1], color='navy', label='Ground Truth Future Trajectory')\n",
    "    \n",
    "    # Optionally set axis limits, labels, and title.\n",
    "    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n",
    "    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n",
    "    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n",
    "    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n",
    "    \n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlabel('X-axis')\n",
    "    ax.set_ylabel('Y-axis')\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, val_dataset, graph_save_path: str = f\"{get_timestamp()}_graph.png\"):\n",
    "    global input_features\n",
    "\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    # randomly select 4 samples from the validation set\n",
    "    random_indices = random.sample(range(len(val_dataset)), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "    axes = axes.flatten()  # Flatten the array to iterate single axes objects\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        batch = val_dataset[idx]\n",
    "        batch_x, batch_y = None, None\n",
    "        if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "            batch_x, batch_y = batch\n",
    "            X_val_tensor = torch.FloatTensor(batch_x).reshape((-1, input_features)).to(device)\n",
    "            y_val_tensor = torch.FloatTensor(batch_y.view(-1, 60, 2))\n",
    "\n",
    "            pred = model(X_val_tensor).cpu().reshape((-1, 60, 2))\n",
    "            gt = torch.stack(torch.split(y_val_tensor, 60, dim=0), dim=0).squeeze(dim=0) # getting a phantom dimension\n",
    "        else:\n",
    "            batch = batch.to(device)\n",
    "            batch_x = batch.x\n",
    "            batch_y = batch.y\n",
    "        \n",
    "            pred = model(batch_x)\n",
    "            gt = torch.stack(torch.split(batch_y, 60, dim=0), dim=0)\n",
    "\n",
    "            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "            gt = torch.stack(torch.split(batch_y, 60, dim=0), dim=0) * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        gt = gt.detach().cpu().numpy()\n",
    "\n",
    "        # Plot the trajectory using the i-th axis\n",
    "        plot_trajectory(axes[i], pred, gt, title=f\"Sample {idx}\")\n",
    "\n",
    "    plt.savefig(fname=graph_save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "if not isinstance(model, SceneContextModel):\n",
    "    # LSTM can handle the timeseries data directly\n",
    "    # TrajectoryDataset expects numpy arrays\n",
    "    collate_func = lambda x: Batch.from_data_list(x)\n",
    "    train_dataset = TrajectoryDatasetTrain(train_data, scale=scale, augment=True)\n",
    "else:\n",
    "    train_x: np.ndarray = train_data[..., :50, :]\n",
    "    train_y: np.ndarray = train_data[:, 0, 50:, :2]\n",
    "    X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n",
    "    y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "visualize_predictions(model, train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
