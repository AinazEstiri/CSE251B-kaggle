{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Kaggle does not automatically have this\n!pip install torch_geometric -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:57:35.785975Z","iopub.execute_input":"2025-05-22T21:57:35.786795Z","iopub.status.idle":"2025-05-22T21:57:41.525811Z","shell.execute_reply.started":"2025-05-22T21:57:35.786770Z","shell.execute_reply":"2025-05-22T21:57:41.524791Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nfrom sklearn.model_selection import TimeSeriesSplit\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torch_geometric.data import Data, Batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:57:41.528220Z","iopub.execute_input":"2025-05-22T21:57:41.528958Z","iopub.status.idle":"2025-05-22T21:57:52.659628Z","shell.execute_reply.started":"2025-05-22T21:57:41.528926Z","shell.execute_reply":"2025-05-22T21:57:52.658906Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Create submission folder if it doesn't exist\nsubmission_dir = './submission'\nos.makedirs(submission_dir, exist_ok=True)\n\n# Uncomment the following block ONLY if you wish to inspect file paths in a Kaggle-like directory structure.\n# On your local system, you likely have the files in your local folder so this is not needed.\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\n# Data Loading for Local Environment\n# Files are assumed to be in:\n# ./cse-251-b-2025/train.npz\n# ./cse-251-b-2025/test_input.npz\n\nrunning_on_kaggle = True\n\nif running_on_kaggle:\n    train_file = np.load(\"/kaggle/input/cse-251-b-2025/train.npz\")\n    test_file = np.load(\"/kaggle/input/cse-251-b-2025/test_input.npz\")\nelse:\n    train_file = np.load(\"./cse-251-b-2025/train.npz\")\n    test_file = np.load(\"./cse-251-b-2025/test_input.npz\")\n\ntrain_data = train_file['data']\ntest_data = test_file['data']\n\nprint(\"train_data's shape:\", train_data.shape)  # Expected shape: (10000, 50, 110, 6)\nprint(\"test_data's shape:\", test_data.shape)    # Expected shape: (2100, 50, 50, 6)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:57:52.660526Z","iopub.execute_input":"2025-05-22T21:57:52.660973Z","iopub.status.idle":"2025-05-22T21:58:10.732240Z","shell.execute_reply.started":"2025-05-22T21:57:52.660946Z","shell.execute_reply":"2025-05-22T21:58:10.731600Z"}},"outputs":[{"name":"stdout","text":"train_data's shape: (10000, 50, 110, 6)\ntest_data's shape: (2100, 50, 50, 6)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Visualization: ","metadata":{}},{"cell_type":"code","source":"# Run visualizations?\nrun_visualizations: bool = False\n\n# From data loading notebook\ndef plot_one_training_scene(idx: int = 0):\n    # Plot trajectories from one training scene (static plot)\n    data_matrix = train_data[idx]\n\n    plt.figure(figsize=(8, 8))\n    for agent in range(data_matrix.shape[idx]):\n        xs = data_matrix[agent, :, 0]\n        ys = data_matrix[agent, :, 1]\n        # Remove zeros (padding)\n        xs = xs[xs != 0]\n        ys = ys[ys != 0]\n        plt.plot(xs, ys, alpha=0.7)\n    plt.title(\"Trajectories from one training scene\")\n    plt.xlabel(\"x-coordinate\")\n    plt.ylabel(\"y-coordinate\")\n    plt.show()\n\n# Create an animated gif for one training scene (exact code provided on kaggle)\ndef make_gif(data_matrix, name='example'):\n    cmap = None\n    if sys.version_info.minor <= 7:\n        cmap = plt.cm.get_cmap(\"viridis\", 50)\n    else:\n        cmap = plt.get_cmap(\"viridis\", 50)\n\n    fig, ax = plt.subplots(figsize=(10, 10))\n    # Function to update plot for each frame\n    def update(frame):\n        ax.clear()\n        # Get data for current timestep\n        for i in range(1, data_matrix.shape[0]):\n            x = data_matrix[i, frame, 0]\n            y = data_matrix[i, frame, 1]\n            if x != 0 and y != 0:\n                xs = data_matrix[i, :frame+1, 0]  # Include current frame\n                ys = data_matrix[i, :frame+1, 1]  # Include current frame\n                # trim all zeros\n                mask = (xs != 0) & (ys != 0)  # Only keep points where both x and y are non-zero\n                xs = xs[mask]\n                ys = ys[mask]\n                # Only plot if we have points to plot\n                if len(xs) > 0 and len(ys) > 0:\n                    color = cmap(i)\n                    ax.plot(xs, ys, alpha=0.9, color=color)\n                    ax.scatter(x, y, s=80, color=color)\n        ax.plot(data_matrix[0, :frame, 0], data_matrix[0, :frame, 1],\n                color='tab:orange', label='Ego Vehicle')\n        ax.scatter(data_matrix[0, frame, 0], data_matrix[0, frame, 1],\n                   s=80, color='tab:orange')\n        # Set title with timestep\n        ax.set_title(f'Timestep {frame}')\n        # Set consistent axis limits\n        ax.set_xlim(data_matrix[:,:,0][data_matrix[:,:,0] != 0].min() - 10, \n                    data_matrix[:,:,0][data_matrix[:,:,0] != 0].max() + 10)\n        ax.set_ylim(data_matrix[:,:,1][data_matrix[:,:,1] != 0].min() - 10, \n                    data_matrix[:,:,1][data_matrix[:,:,1] != 0].max() + 10)\n        ax.legend()\n        return ax.collections + ax.lines\n\n    # Create animation\n    anim = animation.FuncAnimation(fig, update, frames=list(range(0, data_matrix.shape[1], 3)),\n                                   interval=100, blit=True)\n    # Save as GIF\n    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n    plt.close()\n\nif run_visualizations:\n    plot_one_training_scene(0)\n    make_gif(train_data[0], 'index0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.732934Z","iopub.execute_input":"2025-05-22T21:58:10.733171Z","iopub.status.idle":"2025-05-22T21:58:10.744199Z","shell.execute_reply.started":"2025-05-22T21:58:10.733144Z","shell.execute_reply":"2025-05-22T21:58:10.743601Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Constant velocity from test set\nUntouched from original data loading notebook.","metadata":{}},{"cell_type":"code","source":"# Run constant velocity model (Kaggle score of ~50)?\nrun_constant_velocity_model: bool = False\n\nif run_constant_velocity_model:\n    # Compute the velocity differences for the ego vehicle (agent index 0)\n    velocity_diff = test_data[..., 1:, :2] - test_data[..., :-1, :2]\n    print(\"Velocity difference shape:\", velocity_diff.shape)\n\n    # Compute average velocity for the ego vehicle (index 0) in each scene\n    constant_vel = np.mean(velocity_diff[:, 0, :, :], axis=1)\n    print(\"Constant velocity shape:\", constant_vel.shape)\n\n    # Generate predictions for 60 future time steps based on constant velocity\n    pred_y_const = np.zeros((test_data.shape[0], 60, 2))\n    starting_point = test_data[:, 0, -1, :2]  # Last observed position of ego vehicle\n\n    for t in range(60):\n        pred_y_const[:, t, :] = starting_point + (t + 1) * constant_vel\n\n    # Reshape predictions to submission format: (2100, 60, 2) -> (12600, 2)\n    pred_output_const = pred_y_const.reshape(-1, 2)\n    output_df_const = pd.DataFrame(pred_output_const, columns=['x', 'y'])\n    output_df_const.index.name = 'index'\n    # Save output in the submission folder\n    constant_vel_path = os.path.join(submission_dir, 'constant_vel_submission.csv')\n    output_df_const.to_csv(constant_vel_path)\n    print(f\"Constant velocity submission saved locally as '{constant_vel_path}'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.744958Z","iopub.execute_input":"2025-05-22T21:58:10.745158Z","iopub.status.idle":"2025-05-22T21:58:10.772057Z","shell.execute_reply.started":"2025-05-22T21:58:10.745143Z","shell.execute_reply":"2025-05-22T21:58:10.771418Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Our Work","metadata":{}},{"cell_type":"code","source":"# MLP model with residual blocks: ineffective for TimeSeries data\nclass BasicMLP(nn.Module):\n    def __init__(self, input_features, output_features):\n        super().__init__()\n\n        # Lazy layers infer the input size instead of having to explicitly pass it in\n        # Backbone: linear -> BatchNorm -> PReLU -> Dropout\n        self.net = nn.Sequential(\n            nn.Linear(input_features, 1024),\n            nn.BatchNorm1d(1024),\n            nn.PReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(1024, 512),\n            nn.BatchNorm1d(512),\n            nn.PReLU(),\n            nn.Dropout(0.2),\n\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.PReLU(),\n            nn.Dropout(0.2),\n        ) # Note: residual width must match the last width of the net\n\n        # Residual block added to avoid vanishing gradient issue\n        self.residual = nn.Sequential(\n            nn.LazyLinear(256),\n            nn.ReLU(),\n            nn.LazyLinear(256),\n        )\n\n        # Infer last input shape, then do final projection (60*2)\n        self.head = nn.LazyLinear(output_features)\n\n    def forward(self, x):\n        # Original forward loop\n        # # (batch, 50, 50, 6) or flattened already\n        # x = x.view(x.size(0), -1)\n        # h = self.net(x) #(batch, 256)\n        # h = h + self.residual(h)  # residual skip\n        # return self.head(h) #(batch, 120)\n\n        # Taken from milestone notebook (tensor format)\n        # In case you passed in a DataBatch\n        if not isinstance(x, torch.Tensor):\n            x = x.x\n\n        # x = x[:, :, :, :2] # (batch, 50, 50, 2)\n        x = x.reshape(-1, 50 * 50 * 6)\n        x = self.net(x)\n        x = x + self.residual(x)\n        x = self.head(x)\n        return x.view(-1, 60, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.772796Z","iopub.execute_input":"2025-05-22T21:58:10.773057Z","iopub.status.idle":"2025-05-22T21:58:10.792413Z","shell.execute_reply.started":"2025-05-22T21:58:10.773036Z","shell.execute_reply":"2025-05-22T21:58:10.791851Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Base LSTM given to us in the milestone notebook\nclass BaseLSTM(nn.Module):\n    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n        super(BaseLSTM, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        # In case you passed in a DataBatch\n        if not isinstance(x, torch.Tensor):\n            x = x.x\n\n        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n        x = x[:, 0, :, :] # Only Consider ego agent index 0\n\n        lstm_out, _ = self.lstm(x)\n        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n        out = self.fc(lstm_out[:, -1, :])\n        return out.view(-1, 60, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.795173Z","iopub.execute_input":"2025-05-22T21:58:10.795401Z","iopub.status.idle":"2025-05-22T21:58:10.811497Z","shell.execute_reply.started":"2025-05-22T21:58:10.795385Z","shell.execute_reply":"2025-05-22T21:58:10.810910Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Multi agent scene context model\nclass SceneContextModel(nn.Module):\n    def __init__(self, hidden_dim=128):\n        super().__init__()\n        self.agent_encoder = nn.Sequential(\n            nn.Linear(50 * 6, hidden_dim),\n            nn.ReLU()\n        )\n        self.ego_encoder = nn.Sequential(\n            nn.Linear(50 * 6, hidden_dim),\n            nn.ReLU()\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(2 * hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 60 * 2)\n        )\n\n    def forward(self, x_flat):\n        # x = data.x\n        # x = x[:, :, :, :2] # (batch, 50, 50, 2)\n        # x = x.reshape(-1, 50 * 50 * 6)\n        # x = self.mlp(x)\n        # return x.view(-1, 60, 2)\n        # In case you passed in a DataBatch\n        if not isinstance(x_flat, torch.Tensor):\n            x_flat = x_flat.x\n\n        B = x_flat.size(0)\n        x = x_flat.view(B, 50, 50, 6) #(B, agents, timesteps, features)\n        x_agents = x.view(B, 50, -1)  #(B, 50, 300)\n        agent_feats = self.agent_encoder(x_agents) #(B, 50, hidden_dim)\n        scene_context = agent_feats.mean(dim=1) #(B, hidden_dim)\n\n        ego_input = x[:, 0, :, :].reshape(B, -1) #(B, 300)\n        ego_feat = self.ego_encoder(ego_input) #(B, hidden_dim)\n\n        combined = torch.cat([ego_feat, scene_context], dim=1)\n\n        out = self.decoder(combined) #(B, 120)\n        return out.view(-1, 60, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.812166Z","iopub.execute_input":"2025-05-22T21:58:10.812431Z","iopub.status.idle":"2025-05-22T21:58:10.830876Z","shell.execute_reply.started":"2025-05-22T21:58:10.812407Z","shell.execute_reply":"2025-05-22T21:58:10.830121Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Extended from the base LSTM model\nclass LSTMWithMLP(nn.Module):\n    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n        super(LSTMWithMLP, self).__init__()\n        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n        self.net = nn.Sequential(\n            nn.Linear(hidden_dim, 128),\n            nn.BatchNorm1d(128),\n            nn.LeakyReLU(),\n\n            nn.Linear(128, 64),\n            nn.BatchNorm1d(64),\n            nn.LeakyReLU(),\n        )\n        self.fc = nn.Linear(64, output_dim)\n\n    def forward(self, x):\n        # In case you passed in a DataBatch\n        if not isinstance(x, torch.Tensor):\n            x = x.x\n\n        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n        x = x[:, 0, :, :] # Only Consider ego agent index 0\n\n        lstm_out, _ = self.lstm(x)\n        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n        x = self.net(lstm_out[:, -1, :])\n        x = self.fc(x)\n        return x.view(-1, 60, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.831653Z","iopub.execute_input":"2025-05-22T21:58:10.831901Z","iopub.status.idle":"2025-05-22T21:58:10.849206Z","shell.execute_reply.started":"2025-05-22T21:58:10.831880Z","shell.execute_reply":"2025-05-22T21:58:10.848506Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class LSTMButTwo(nn.Module):\n    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n        super(LSTMButTwo, self).__init__()\n        self.second_out_dim = 128\n\n        self.lstm_1 = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n        self.lstm_2 = nn.LSTM(hidden_dim, self.second_out_dim, batch_first=True, dropout=dropout)\n        self.fc = nn.Linear(self.second_out_dim, output_dim)\n\n    def forward(self, x):\n        # In case you passed in a DataBatch\n        if not isinstance(x, torch.Tensor):\n            x = x.x\n\n        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n        x = x[:, 0, :, :] # Only Consider ego agent index 0\n\n        lstm_first_out, _ = self.lstm_1(x)\n        lstm_second_out, _ = self.lstm_2(lstm_first_out)\n\n        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n        lstm_out = lstm_second_out[:, -1, :]\n        x = self.fc(lstm_out)\n        return x.view(-1, 60, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.849976Z","iopub.execute_input":"2025-05-22T21:58:10.850206Z","iopub.status.idle":"2025-05-22T21:58:10.868765Z","shell.execute_reply.started":"2025-05-22T21:58:10.850186Z","shell.execute_reply":"2025-05-22T21:58:10.868199Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Preparing data\n\n`TrajectoryDataset*` are taken from the milestone notebook.","metadata":{}},{"cell_type":"code","source":"class TrajectoryDatasetTrain(Dataset):\n    def __init__(self, data, scale=10.0, augment=True):\n        \"\"\"\n        data: Shape (N, 50, 110, 6) Training data\n        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n        augment: Whether to apply data augmentation (only for training)\n        \"\"\"\n        self.data = data\n        self.scale = scale\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        scene = self.data[idx]\n        # Getting 50 historical timestamps and 60 future timestamps\n        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n        \n        # Data augmentation(only for training)\n        if self.augment:\n            if np.random.rand() < 0.5:\n                theta = np.random.uniform(-np.pi, np.pi)\n                R = np.array([[np.cos(theta), -np.sin(theta)],\n                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n                # Rotate the historical trajectory and future trajectory\n                hist[..., :2] = hist[..., :2] @ R\n                hist[..., 2:4] = hist[..., 2:4] @ R\n                # future = future @ R gives DeprecationWarning: future a torch.Tensor\n                future = torch.from_numpy(np.dot(future.numpy(), R)) \n            if np.random.rand() < 0.5:\n                hist[..., 0] *= -1\n                hist[..., 2] *= -1\n                future[:, 0] *= -1\n\n        # Use the last timeframe of the historical trajectory as the origin\n        origin = hist[0, 49, :2].copy()  # (2,)\n        hist[..., :2] = hist[..., :2] - origin\n        # future = future - origin -> same DeprecationWarning\n        future = torch.from_numpy(future.numpy() - origin)\n\n        # Normalize the historical trajectory and future trajectory\n        hist[..., :4] = hist[..., :4] / self.scale\n        future = future / self.scale\n\n        data_item = Data(\n            x=torch.tensor(hist, dtype=torch.float32),\n            y=future.type(torch.float32),\n            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n            scale=torch.tensor(self.scale, dtype=torch.float32),\n        )\n\n        return data_item\n    \n\nclass TrajectoryDatasetTest(Dataset):\n    def __init__(self, data, scale=10.0):\n        \"\"\"\n        data: Shape (N, 50, 110, 6) Testing data\n        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n        \"\"\"\n        self.data = data\n        self.scale = scale\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # Testing data only contains historical trajectory\n        scene = self.data[idx]  # (50, 50, 6)\n        hist = scene.copy()\n        \n        origin = hist[0, 49, :2].copy()\n        hist[..., :2] = hist[..., :2] - origin\n        hist[..., :4] = hist[..., :4] / self.scale\n\n        data_item = Data(\n            x=torch.tensor(hist, dtype=torch.float32),\n            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n            scale=torch.tensor(self.scale, dtype=torch.float32),\n        )\n        return data_item","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.869346Z","iopub.execute_input":"2025-05-22T21:58:10.869515Z","iopub.status.idle":"2025-05-22T21:58:10.892263Z","shell.execute_reply.started":"2025-05-22T21:58:10.869502Z","shell.execute_reply":"2025-05-22T21:58:10.891671Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Training loop\n\nChange which model is used at the `model = ...(input_features, output_features)` line.\n\nChange which optimizer is used at the `optimizer = optim...` line.\n\nDo **NOT** change the `criterion`, as MSE is stated in the Data tab of the competition.","metadata":{}},{"cell_type":"code","source":"# Taken from milestone notebook\n# Set device for training speedup\nif torch.backends.mps.is_available():\n    device = torch.device('mps')\n    print(\"Using Apple Silicon GPU\")\nelif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(\"Using CUDA GPU\")\nelse:\n    device = torch.device('cpu')\n    print(\"Using CPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.892902Z","iopub.execute_input":"2025-05-22T21:58:10.893117Z","iopub.status.idle":"2025-05-22T21:58:10.911309Z","shell.execute_reply.started":"2025-05-22T21:58:10.893102Z","shell.execute_reply":"2025-05-22T21:58:10.910764Z"}},"outputs":[{"name":"stdout","text":"Using CUDA GPU\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Functions to save and load the model (should correspond to what was trained!)\ndef save_model(model, path=\"our_model.pth\"):\n    torch.save(model.state_dict(), path)\n    print(f\"Model saved to {path}\")\n\n\ndef load_model(model_instance, path=\"our_model.pth\"):\n    loaded_model = model_instance\n    loaded_model.load_state_dict(torch.load(path))\n    loaded_model.eval()\n    return loaded_model\n\n\n# Example usage:\n# save_model(trained_model)\n# model = load_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.911970Z","iopub.execute_input":"2025-05-22T21:58:10.912140Z","iopub.status.idle":"2025-05-22T21:58:10.928250Z","shell.execute_reply.started":"2025-05-22T21:58:10.912127Z","shell.execute_reply":"2025-05-22T21:58:10.927743Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def get_timestamp() -> str:\n    return datetime.now().strftime(\"%Y-%m-%d_%I-%M%p\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.929048Z","iopub.execute_input":"2025-05-22T21:58:10.929311Z","iopub.status.idle":"2025-05-22T21:58:10.942088Z","shell.execute_reply.started":"2025-05-22T21:58:10.929290Z","shell.execute_reply":"2025-05-22T21:58:10.941577Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Set up hyperparameters\n\n# Calculate number of input features after flattening and number of output features\n# Note: LSTM models take features in different dimensions\ninput_features:int = 50 * 50 * 6   # 50 agents, 50 time steps, 6 dimensions each (15000 input features)\noutput_features:int = 60 * 2       # 60 future time steps, 2 dimensions (x, y) (120 output features)\n\n# Hyperparameters\nbatch_size: int = 32\nnum_folds: int = 4\nearly_stopping_patience: int = 25\nearly_stopping_threshold: float = 1e-5\nepochs: int = 150\nstarting_lr: float = 5e-3\nscale: float = 10.0\nweight_decay: float = 1e-2\n\nlstm_hidden_dim: int = 128\n\n\nSEED: int = 42\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.942834Z","iopub.execute_input":"2025-05-22T21:58:10.943067Z","iopub.status.idle":"2025-05-22T21:58:10.968574Z","shell.execute_reply.started":"2025-05-22T21:58:10.943045Z","shell.execute_reply":"2025-05-22T21:58:10.967947Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# IMPORTANT! To change which model is used: comment/uncomment below\n# Easily swap models by changing what is returned (called in training and test to avoid conflicts)\ndef get_model():\n    global lstm_hidden_dim, input_features, output_features\n\n    # return BasicMLP(input_features, output_features).to(device)\n    # return BaseLSTM(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n    # return SceneContextModel(hidden_dim=864).to(device)\n    # return LSTMWithMLP(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n    return LSTMButTwo(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.969193Z","iopub.execute_input":"2025-05-22T21:58:10.969438Z","iopub.status.idle":"2025-05-22T21:58:10.973569Z","shell.execute_reply.started":"2025-05-22T21:58:10.969415Z","shell.execute_reply":"2025-05-22T21:58:10.972981Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_model(full_training_data: np.ndarray, \n                batch_size:int = 64, epochs:int = 10, num_folds:int = 5,\n                early_stopping_patience:int = 5, early_stopping_threshold:float = 1e-3):\n    global starting_lr, gamma, scale, lstm_hidden_dim, output_features, weight_decay\n\n    # Time series data needs to keep its data in relative order, so no shuffling can occur\n    #   like in regular KFold cross validation\n    splitter = TimeSeriesSplit(n_splits=num_folds, test_size=int(0.15 * len(full_training_data)))\n\n    # Perform cross-validation, the best model will be saved as \"best_model.pt\" to be loaded in later\n    overall_best_val_loss = float(\"inf\")\n    overall_best_seen_at = (0, 0) #(epoch, fold)\n\n    # Resources used:\n    # Project milestone notebook\n    # https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md\n    # https://www.geeksforgeeks.org/time-series-cross-validation/\n    for fold_i, (train_idx, val_idx) in enumerate(splitter.split(full_training_data)):\n        print(f\"\\nFOLD {fold_i + 1}/{num_folds} ==================================\")\n\n        # Create the model, loss criterion, and optimizer (reset per fold, to find the best model)\n        # If you change the model here, ensure its the same in the test loop!\n        # DO NOT CHANGE CRITERION\n        criterion = nn.MSELoss()\n\n        model = get_model()\n        optimizer = optim.AdamW(model.parameters(), lr=starting_lr, weight_decay=weight_decay)\n        schedulers: list[lr_scheduler.LRScheduler] =[\n            lr_scheduler.ExponentialLR(optimizer, gamma=0.995),\n            lr_scheduler.MultiStepLR(\n                optimizer,\n                milestones= list(range(25, epochs, 25)),\n                gamma=0.80,\n            ),\n            # lr_scheduler.MultiStepLR(\n            #     optimizer,\n            #     milestones= list(range(100, epochs, 100)),\n            #     gamma=0.5,\n            # ),\n            lr_scheduler.CosineAnnealingLR(\n                optimizer, \n                T_max= int(epochs * 0.9),\n                # T_0 = 50,\n                # T_mult = 2,\n                eta_min=1e-6\n            ),\n        ]\n\n        # Prepare data from this fold\n        train_fold: np.ndarray = full_training_data[train_idx]\n        val_fold: np.ndarray = full_training_data[val_idx]\n        collate_func = None     # Optional for DataLoader, taken from milestone notebook\n        if not isinstance(model, SceneContextModel):\n            # LSTM can handle the timeseries data directly\n            # TrajectoryDataset expects numpy arrays\n            collate_func = lambda x: Batch.from_data_list(x)\n            train_dataset = TrajectoryDatasetTrain(train_fold, scale=scale, augment=True)\n            val_dataset = TrajectoryDatasetTrain(val_fold, scale=scale, augment=False)\n        else:\n            train_x: np.ndarray = train_fold[..., :50, :]\n            train_y: np.ndarray = train_fold[:, 0, 50:, :2]\n            X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n            y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n\n            val_x: np.ndarray = val_fold[..., :50, :]\n            val_y: np.ndarray = val_fold[:, 0, 50:, :2]\n            X_val_tensor = torch.FloatTensor(val_x).reshape((-1, input_features))\n            y_val_tensor = torch.FloatTensor(val_y).reshape((-1, output_features))\n            val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\n        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n\n        best_val_loss: float = float(\"inf\")\n        no_improvement: int = 0\n\n        # Training and validation loops are taken from the milestone notebook,\n        #   with modifications to allow for different data loading shapes      \n        for epoch in tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n            # Training loop\n            model.train()\n            train_loss = 0\n            for batch in train_dataloader:\n                batch_x = None\n                batch_y = None\n                if isinstance(batch, tuple) or isinstance(batch, list):\n                    batch_x, batch_y = batch\n                    batch_y = batch_y.view(-1, 60, 2)\n                else: # DataBatch type\n                    batch = batch.to(device)\n                    batch_x = batch.x\n                    batch_y = batch.y.view(batch.num_graphs, 60, 2)\n\n                optimizer.zero_grad()\n                outputs = model(batch_x)\n                loss = criterion(outputs, batch_y)\n                loss.backward()\n                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n                optimizer.step()\n                train_loss += loss.item()\n\n            # Validation loop\n            model.eval()\n            val_loss = 0\n            val_mae = 0\n            val_mse = 0\n            with torch.no_grad():\n                for batch in val_dataloader:\n                    batch_x = None\n                    batch_y = None\n                    if isinstance(batch, tuple) or isinstance(batch, list):\n                        batch_x, batch_y = batch\n                        batch_y = batch_y.view(-1, 60, 2)\n                    else: # DataBatch type\n                        batch = batch.to(device)\n                        batch_x = batch.x\n                        batch_y = batch.y.view(batch.num_graphs, 60, 2)\n\n                    pred = model(batch_x)\n                    val_loss += criterion(pred, batch_y).item()\n\n                    # show MAE and MSE with unnormalized data\n                    y = None\n                    if isinstance(batch, tuple) or isinstance(batch, list):\n                        y = batch_y.view(-1, 60, 2)\n                    else: # DataBatch type\n                        pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n                        y = batch_y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n                    val_mae += nn.L1Loss()(pred, y).item()\n                    val_mse += nn.MSELoss()(pred, y).item()\n\n            train_loss /= len(train_dataloader)\n            val_loss /= len(val_dataloader)\n            val_mae /= len(val_dataloader)\n            val_mse /= len(val_dataloader)\n\n            if (epoch + 1) % 5 == 0:\n                tqdm.write(f\"Epoch {(epoch + 1):03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n\n            if val_loss < best_val_loss - early_stopping_threshold:\n                best_val_loss = val_loss\n                no_improvement = 0\n\n                # Better than the overall seen so far?\n                if best_val_loss < overall_best_val_loss:\n                    overall_best_val_loss = best_val_loss\n                    overall_best_seen_at = (epoch + 1, fold_i + 1)\n                    torch.save(model.state_dict(), \"best_model.pt\")\n            else:\n                no_improvement += 1\n                if no_improvement >= early_stopping_patience:\n                    print(f\"==== EARLY STOP at epoch {(epoch + 1):03d}\")\n                    break\n\n            for sched in schedulers:\n                sched.step()\n\n        # Clean up after the fold finishes to prevent slower folds later\n        # https://discuss.pytorch.org/t/how-to-delete-a-tensor-in-gpu-to-free-up-memory/48879\n        torch.cuda.empty_cache()\n        del train_dataloader, train_dataset, val_dataloader, val_dataset\n\n    print(f\"BEST VALIDATION LOSS (NORMALIZED MSE) SEEN: {overall_best_val_loss}, AT (epoch, fold) = {overall_best_seen_at}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.974379Z","iopub.execute_input":"2025-05-22T21:58:10.974577Z","iopub.status.idle":"2025-05-22T21:58:10.993403Z","shell.execute_reply.started":"2025-05-22T21:58:10.974562Z","shell.execute_reply":"2025-05-22T21:58:10.992771Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Load in the model saved during testing to use on X_test\n# Mostly taken from milestone notebook\ndef predict(X_test: np.ndarray, best_model_path: str = \"best_model.pt\"):\n    global scale, batch_size, lstm_hidden_dim, output_features\n\n    # Ensure this aligns with the trained model!\n    best_model = torch.load(best_model_path)\n    model = get_model()\n    model.load_state_dict(best_model)\n    model.eval()\n\n    pred_list = []\n    with torch.no_grad():\n        if not isinstance(model, SceneContextModel): # Using DataBatch type from a DataLoader\n            collate_func = lambda x: Batch.from_data_list(x)\n            test_dataset = TrajectoryDatasetTest(X_test, scale=scale)\n            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n\n            for batch in test_loader:\n                batch = batch.to(device)\n                pred_norm = model(batch.x)\n\n                # Reshape the prediction to (N, 60, 2)\n                pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n                pred_list.append(pred.cpu().numpy())\n        else:\n            X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features)).to(device)\n            pred = model(X_test_tensor).cpu().reshape((-1, 60, 2))\n            pred_list.append(pred.numpy())\n\n    # Reshape predictions to match submission format: (2100, 60, 2) -> (12600, 2)\n    pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n    pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n    output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n    output_df.index.name = 'index'\n    return output_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:10.994064Z","iopub.execute_input":"2025-05-22T21:58:10.994281Z","iopub.status.idle":"2025-05-22T21:58:11.008552Z","shell.execute_reply.started":"2025-05-22T21:58:10.994262Z","shell.execute_reply":"2025-05-22T21:58:11.007727Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Train the model (tweak batch_size and epochs as needed at top of this block)\n# Saved as \"best_model.pt\" to be loaded in during testing\ntrain_model(train_data, batch_size=batch_size, epochs=epochs, num_folds=num_folds,\n            early_stopping_patience=early_stopping_patience,\n            early_stopping_threshold=early_stopping_threshold)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T21:58:11.009327Z","iopub.execute_input":"2025-05-22T21:58:11.009565Z","iopub.status.idle":"2025-05-22T22:35:40.746427Z","shell.execute_reply.started":"2025-05-22T21:58:11.009541Z","shell.execute_reply":"2025-05-22T22:35:40.745757Z"}},"outputs":[{"name":"stdout","text":"\nFOLD 1/4 ==================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   3%|▎         | 5/150 [00:17<08:02,  3.33s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 005 | Learning rate 0.004890 | train normalized MSE   0.1762 | val normalized MSE   0.1649, | val MAE   2.2116 | val MSE  16.4906\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   7%|▋         | 10/150 [00:33<07:31,  3.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 010 | Learning rate 0.004727 | train normalized MSE   0.1328 | val normalized MSE   0.1310, | val MAE   1.9133 | val MSE  13.1036\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  10%|█         | 15/150 [00:49<07:18,  3.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 015 | Learning rate 0.004539 | train normalized MSE   0.1162 | val normalized MSE   0.1107, | val MAE   1.8135 | val MSE  11.0732\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  13%|█▎        | 20/150 [01:05<07:00,  3.23s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 020 | Learning rate 0.004327 | train normalized MSE   0.1094 | val normalized MSE   0.1011, | val MAE   1.6482 | val MSE  10.1064\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  17%|█▋        | 25/150 [01:21<06:48,  3.27s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 025 | Learning rate 0.004097 | train normalized MSE   0.1081 | val normalized MSE   0.1050, | val MAE   1.6495 | val MSE  10.5006\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  20%|██        | 30/150 [01:38<06:27,  3.23s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 030 | Learning rate 0.003080 | train normalized MSE   0.0951 | val normalized MSE   0.1040, | val MAE   1.6447 | val MSE  10.3960\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  23%|██▎       | 35/150 [01:54<06:08,  3.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 035 | Learning rate 0.002872 | train normalized MSE   0.0934 | val normalized MSE   0.0976, | val MAE   1.6269 | val MSE   9.7568\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  27%|██▋       | 40/150 [02:10<05:56,  3.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 040 | Learning rate 0.002658 | train normalized MSE   0.0935 | val normalized MSE   0.0959, | val MAE   1.5233 | val MSE   9.5941\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  30%|███       | 45/150 [02:26<05:40,  3.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 045 | Learning rate 0.002439 | train normalized MSE   0.0981 | val normalized MSE   0.0934, | val MAE   1.5544 | val MSE   9.3428\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  33%|███▎      | 50/150 [02:42<05:21,  3.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 050 | Learning rate 0.002218 | train normalized MSE   0.0882 | val normalized MSE   0.0875, | val MAE   1.4313 | val MSE   8.7494\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  37%|███▋      | 55/150 [02:58<05:05,  3.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 055 | Learning rate 0.001598 | train normalized MSE   0.0828 | val normalized MSE   0.0864, | val MAE   1.4152 | val MSE   8.6400\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 60/150 [03:15<04:54,  3.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 060 | Learning rate 0.001425 | train normalized MSE   0.0798 | val normalized MSE   0.0889, | val MAE   1.5010 | val MSE   8.8915\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  43%|████▎     | 65/150 [03:31<04:38,  3.27s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 065 | Learning rate 0.001256 | train normalized MSE   0.0787 | val normalized MSE   0.0844, | val MAE   1.4040 | val MSE   8.4366\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  47%|████▋     | 70/150 [03:47<04:20,  3.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 070 | Learning rate 0.001093 | train normalized MSE   0.0773 | val normalized MSE   0.0840, | val MAE   1.4046 | val MSE   8.4016\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  50%|█████     | 75/150 [04:03<04:03,  3.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 075 | Learning rate 0.000938 | train normalized MSE   0.0758 | val normalized MSE   0.0825, | val MAE   1.3441 | val MSE   8.2539\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  53%|█████▎    | 80/150 [04:20<03:48,  3.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 080 | Learning rate 0.000634 | train normalized MSE   0.0735 | val normalized MSE   0.0814, | val MAE   1.3631 | val MSE   8.1416\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  57%|█████▋    | 85/150 [04:36<03:31,  3.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 085 | Learning rate 0.000526 | train normalized MSE   0.0724 | val normalized MSE   0.0814, | val MAE   1.3564 | val MSE   8.1378\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  60%|██████    | 90/150 [04:53<03:19,  3.32s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 090 | Learning rate 0.000427 | train normalized MSE   0.0711 | val normalized MSE   0.0819, | val MAE   1.3627 | val MSE   8.1878\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  63%|██████▎   | 95/150 [05:09<03:02,  3.31s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 095 | Learning rate 0.000338 | train normalized MSE   0.0708 | val normalized MSE   0.0806, | val MAE   1.3157 | val MSE   8.0620\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  67%|██████▋   | 100/150 [05:26<02:47,  3.34s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 100 | Learning rate 0.000259 | train normalized MSE   0.0690 | val normalized MSE   0.0805, | val MAE   1.3013 | val MSE   8.0530\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  70%|███████   | 105/150 [05:43<02:29,  3.32s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 105 | Learning rate 0.000152 | train normalized MSE   0.0681 | val normalized MSE   0.0806, | val MAE   1.2998 | val MSE   8.0630\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  73%|███████▎  | 110/150 [05:59<02:13,  3.33s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 110 | Learning rate 0.000106 | train normalized MSE   0.0664 | val normalized MSE   0.0797, | val MAE   1.2998 | val MSE   7.9680\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  77%|███████▋  | 115/150 [06:16<01:56,  3.32s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 115 | Learning rate 0.000069 | train normalized MSE   0.0667 | val normalized MSE   0.0795, | val MAE   1.2899 | val MSE   7.9485\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  80%|████████  | 120/150 [06:32<01:38,  3.29s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 120 | Learning rate 0.000040 | train normalized MSE   0.0668 | val normalized MSE   0.0798, | val MAE   1.2879 | val MSE   7.9757\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  83%|████████▎ | 125/150 [06:49<01:22,  3.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 125 | Learning rate 0.000019 | train normalized MSE   0.0664 | val normalized MSE   0.0796, | val MAE   1.2900 | val MSE   7.9617\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  84%|████████▍ | 126/150 [06:55<01:19,  3.30s/epoch]","output_type":"stream"},{"name":"stdout","text":"==== EARLY STOP at epoch 127\n\nFOLD 2/4 ==================================\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch:   3%|▎         | 5/150 [00:21<10:20,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 005 | Learning rate 0.004890 | train normalized MSE   0.1721 | val normalized MSE   0.1617, | val MAE   2.1870 | val MSE  16.1707\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   7%|▋         | 10/150 [00:42<09:58,  4.27s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 010 | Learning rate 0.004727 | train normalized MSE   0.1250 | val normalized MSE   0.1327, | val MAE   1.9030 | val MSE  13.2657\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  10%|█         | 15/150 [01:03<09:28,  4.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 015 | Learning rate 0.004539 | train normalized MSE   0.1131 | val normalized MSE   0.1354, | val MAE   1.8576 | val MSE  13.5387\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  13%|█▎        | 20/150 [01:25<09:11,  4.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 020 | Learning rate 0.004327 | train normalized MSE   0.1079 | val normalized MSE   0.1310, | val MAE   1.9627 | val MSE  13.0963\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  17%|█▋        | 25/150 [01:46<08:55,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 025 | Learning rate 0.004097 | train normalized MSE   0.1317 | val normalized MSE   0.1387, | val MAE   1.9314 | val MSE  13.8661\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  20%|██        | 30/150 [02:07<08:30,  4.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 030 | Learning rate 0.003080 | train normalized MSE   0.1060 | val normalized MSE   0.1222, | val MAE   1.7565 | val MSE  12.2187\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  23%|██▎       | 35/150 [02:29<08:12,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 035 | Learning rate 0.002872 | train normalized MSE   0.0978 | val normalized MSE   0.1154, | val MAE   1.6757 | val MSE  11.5351\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  27%|██▋       | 40/150 [02:50<07:54,  4.31s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 040 | Learning rate 0.002658 | train normalized MSE   0.0934 | val normalized MSE   0.1171, | val MAE   1.6927 | val MSE  11.7089\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  30%|███       | 45/150 [03:12<07:28,  4.27s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 045 | Learning rate 0.002439 | train normalized MSE   0.0978 | val normalized MSE   0.1125, | val MAE   1.7313 | val MSE  11.2478\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  33%|███▎      | 50/150 [03:33<07:07,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 050 | Learning rate 0.002218 | train normalized MSE   0.0900 | val normalized MSE   0.1100, | val MAE   1.5847 | val MSE  10.9993\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  37%|███▋      | 55/150 [03:54<06:44,  4.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 055 | Learning rate 0.001598 | train normalized MSE   0.0850 | val normalized MSE   0.1054, | val MAE   1.6017 | val MSE  10.5395\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 60/150 [04:16<06:23,  4.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 060 | Learning rate 0.001425 | train normalized MSE   0.0829 | val normalized MSE   0.1030, | val MAE   1.6064 | val MSE  10.2966\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  43%|████▎     | 65/150 [04:37<06:00,  4.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 065 | Learning rate 0.001256 | train normalized MSE   0.0799 | val normalized MSE   0.1024, | val MAE   1.5573 | val MSE  10.2398\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  47%|████▋     | 70/150 [04:58<05:38,  4.23s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 070 | Learning rate 0.001093 | train normalized MSE   0.0779 | val normalized MSE   0.0951, | val MAE   1.4493 | val MSE   9.5064\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  50%|█████     | 75/150 [05:19<05:19,  4.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 075 | Learning rate 0.000938 | train normalized MSE   0.0775 | val normalized MSE   0.0970, | val MAE   1.4541 | val MSE   9.6995\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  53%|█████▎    | 80/150 [05:40<04:54,  4.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 080 | Learning rate 0.000634 | train normalized MSE   0.0739 | val normalized MSE   0.0941, | val MAE   1.4165 | val MSE   9.4136\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  57%|█████▋    | 85/150 [06:01<04:32,  4.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 085 | Learning rate 0.000526 | train normalized MSE   0.0726 | val normalized MSE   0.0951, | val MAE   1.4362 | val MSE   9.5057\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  60%|██████    | 90/150 [06:22<04:13,  4.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 090 | Learning rate 0.000427 | train normalized MSE   0.0723 | val normalized MSE   0.0943, | val MAE   1.4326 | val MSE   9.4309\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  63%|██████▎   | 95/150 [06:43<03:50,  4.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 095 | Learning rate 0.000338 | train normalized MSE   0.0705 | val normalized MSE   0.0954, | val MAE   1.4108 | val MSE   9.5413\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  67%|██████▋   | 100/150 [07:04<03:30,  4.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 100 | Learning rate 0.000259 | train normalized MSE   0.0695 | val normalized MSE   0.0925, | val MAE   1.4048 | val MSE   9.2484\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  70%|███████   | 105/150 [07:26<03:12,  4.29s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 105 | Learning rate 0.000152 | train normalized MSE   0.0693 | val normalized MSE   0.0928, | val MAE   1.4001 | val MSE   9.2828\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  73%|███████▎  | 110/150 [07:47<02:51,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 110 | Learning rate 0.000106 | train normalized MSE   0.0659 | val normalized MSE   0.0923, | val MAE   1.3818 | val MSE   9.2321\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  77%|███████▋  | 115/150 [08:09<02:29,  4.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 115 | Learning rate 0.000069 | train normalized MSE   0.0674 | val normalized MSE   0.0927, | val MAE   1.3919 | val MSE   9.2730\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  80%|████████  | 120/150 [08:30<02:09,  4.31s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 120 | Learning rate 0.000040 | train normalized MSE   0.0676 | val normalized MSE   0.0925, | val MAE   1.3804 | val MSE   9.2525\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  83%|████████▎ | 125/150 [08:51<01:46,  4.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 125 | Learning rate 0.000019 | train normalized MSE   0.0672 | val normalized MSE   0.0925, | val MAE   1.3781 | val MSE   9.2546\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  87%|████████▋ | 130/150 [09:12<01:23,  4.17s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 130 | Learning rate 0.000005 | train normalized MSE   0.0662 | val normalized MSE   0.0926, | val MAE   1.3783 | val MSE   9.2566\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  87%|████████▋ | 131/150 [09:20<01:21,  4.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"==== EARLY STOP at epoch 132\n\nFOLD 3/4 ==================================\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch:   3%|▎         | 5/150 [00:26<12:37,  5.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 005 | Learning rate 0.004890 | train normalized MSE   0.1653 | val normalized MSE   0.1537, | val MAE   2.2068 | val MSE  15.3742\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   7%|▋         | 10/150 [00:52<12:06,  5.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 010 | Learning rate 0.004727 | train normalized MSE   0.1282 | val normalized MSE   0.1201, | val MAE   1.7898 | val MSE  12.0131\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  10%|█         | 15/150 [01:18<11:42,  5.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 015 | Learning rate 0.004539 | train normalized MSE   0.1065 | val normalized MSE   0.1232, | val MAE   1.9477 | val MSE  12.3250\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  13%|█▎        | 20/150 [01:44<11:15,  5.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 020 | Learning rate 0.004327 | train normalized MSE   0.1031 | val normalized MSE   0.1015, | val MAE   1.5842 | val MSE  10.1475\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  17%|█▋        | 25/150 [02:09<10:46,  5.17s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 025 | Learning rate 0.004097 | train normalized MSE   0.0992 | val normalized MSE   0.1019, | val MAE   1.6254 | val MSE  10.1861\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  20%|██        | 30/150 [02:35<10:22,  5.18s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 030 | Learning rate 0.003080 | train normalized MSE   0.0942 | val normalized MSE   0.0970, | val MAE   1.6294 | val MSE   9.7030\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  23%|██▎       | 35/150 [03:01<09:58,  5.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 035 | Learning rate 0.002872 | train normalized MSE   0.0916 | val normalized MSE   0.0932, | val MAE   1.4365 | val MSE   9.3227\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  27%|██▋       | 40/150 [03:28<09:35,  5.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 040 | Learning rate 0.002658 | train normalized MSE   0.0896 | val normalized MSE   0.0924, | val MAE   1.4481 | val MSE   9.2434\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  30%|███       | 45/150 [03:53<09:02,  5.16s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 045 | Learning rate 0.002439 | train normalized MSE   0.0876 | val normalized MSE   0.0916, | val MAE   1.5504 | val MSE   9.1563\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  33%|███▎      | 50/150 [04:19<08:38,  5.18s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 050 | Learning rate 0.002218 | train normalized MSE   0.0869 | val normalized MSE   0.0890, | val MAE   1.4689 | val MSE   8.9020\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  37%|███▋      | 55/150 [04:45<08:05,  5.11s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 055 | Learning rate 0.001598 | train normalized MSE   0.0826 | val normalized MSE   0.0870, | val MAE   1.4037 | val MSE   8.7037\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 60/150 [05:11<07:46,  5.18s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 060 | Learning rate 0.001425 | train normalized MSE   0.0799 | val normalized MSE   0.0893, | val MAE   1.4727 | val MSE   8.9253\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  43%|████▎     | 65/150 [05:37<07:21,  5.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 065 | Learning rate 0.001256 | train normalized MSE   0.0799 | val normalized MSE   0.0870, | val MAE   1.4516 | val MSE   8.6966\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  47%|████▋     | 70/150 [06:03<06:57,  5.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 070 | Learning rate 0.001093 | train normalized MSE   0.0792 | val normalized MSE   0.0845, | val MAE   1.3774 | val MSE   8.4486\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  50%|█████     | 75/150 [06:29<06:28,  5.18s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 075 | Learning rate 0.000938 | train normalized MSE   0.0756 | val normalized MSE   0.0841, | val MAE   1.3821 | val MSE   8.4051\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  53%|█████▎    | 80/150 [06:54<05:59,  5.14s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 080 | Learning rate 0.000634 | train normalized MSE   0.0741 | val normalized MSE   0.0819, | val MAE   1.3346 | val MSE   8.1856\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  57%|█████▋    | 85/150 [07:20<05:35,  5.17s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 085 | Learning rate 0.000526 | train normalized MSE   0.0730 | val normalized MSE   0.0812, | val MAE   1.3284 | val MSE   8.1184\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  60%|██████    | 90/150 [07:46<05:11,  5.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 090 | Learning rate 0.000427 | train normalized MSE   0.0721 | val normalized MSE   0.0830, | val MAE   1.3493 | val MSE   8.2989\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  63%|██████▎   | 95/150 [08:12<04:46,  5.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 095 | Learning rate 0.000338 | train normalized MSE   0.0707 | val normalized MSE   0.0840, | val MAE   1.3509 | val MSE   8.4024\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  67%|██████▋   | 100/150 [08:38<04:19,  5.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 100 | Learning rate 0.000259 | train normalized MSE   0.0705 | val normalized MSE   0.0830, | val MAE   1.3449 | val MSE   8.3018\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  70%|███████   | 105/150 [09:04<03:54,  5.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 105 | Learning rate 0.000152 | train normalized MSE   0.0698 | val normalized MSE   0.0823, | val MAE   1.3326 | val MSE   8.2272\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  73%|███████▎  | 109/150 [09:30<03:34,  5.23s/epoch]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 110 | Learning rate 0.000106 | train normalized MSE   0.0695 | val normalized MSE   0.0819, | val MAE   1.3276 | val MSE   8.1908\n==== EARLY STOP at epoch 110\n\nFOLD 4/4 ==================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   3%|▎         | 5/150 [00:30<14:47,  6.12s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 005 | Learning rate 0.004890 | train normalized MSE   0.1568 | val normalized MSE   0.1253, | val MAE   1.8414 | val MSE  12.5292\n","output_type":"stream"},{"name":"stderr","text":"Epoch:   7%|▋         | 10/150 [01:01<14:17,  6.12s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 010 | Learning rate 0.004727 | train normalized MSE   0.1304 | val normalized MSE   0.1178, | val MAE   1.8108 | val MSE  11.7753\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  10%|█         | 15/150 [01:32<13:56,  6.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 015 | Learning rate 0.004539 | train normalized MSE   0.1069 | val normalized MSE   0.1034, | val MAE   1.6841 | val MSE  10.3351\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  13%|█▎        | 20/150 [02:03<13:21,  6.16s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 020 | Learning rate 0.004327 | train normalized MSE   0.1007 | val normalized MSE   0.0940, | val MAE   1.5678 | val MSE   9.4024\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  17%|█▋        | 25/150 [02:33<12:44,  6.11s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 025 | Learning rate 0.004097 | train normalized MSE   0.0983 | val normalized MSE   0.1020, | val MAE   1.6437 | val MSE  10.2041\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  20%|██        | 30/150 [03:04<12:13,  6.11s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 030 | Learning rate 0.003080 | train normalized MSE   0.0917 | val normalized MSE   0.0906, | val MAE   1.5491 | val MSE   9.0630\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  23%|██▎       | 35/150 [03:35<11:45,  6.14s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 035 | Learning rate 0.002872 | train normalized MSE   0.0903 | val normalized MSE   0.0939, | val MAE   1.6174 | val MSE   9.3933\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  27%|██▋       | 40/150 [04:05<11:13,  6.12s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 040 | Learning rate 0.002658 | train normalized MSE   0.0873 | val normalized MSE   0.0867, | val MAE   1.4234 | val MSE   8.6672\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  30%|███       | 45/150 [04:36<10:50,  6.19s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 045 | Learning rate 0.002439 | train normalized MSE   0.0832 | val normalized MSE   0.0880, | val MAE   1.5046 | val MSE   8.7999\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  33%|███▎      | 50/150 [05:07<10:14,  6.15s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 050 | Learning rate 0.002218 | train normalized MSE   0.0831 | val normalized MSE   0.0873, | val MAE   1.4658 | val MSE   8.7334\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  37%|███▋      | 55/150 [05:38<09:45,  6.17s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 055 | Learning rate 0.001598 | train normalized MSE   0.0791 | val normalized MSE   0.0819, | val MAE   1.3776 | val MSE   8.1887\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 60/150 [06:09<09:14,  6.16s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 060 | Learning rate 0.001425 | train normalized MSE   0.0789 | val normalized MSE   0.0815, | val MAE   1.3570 | val MSE   8.1545\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  43%|████▎     | 65/150 [06:40<08:50,  6.24s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 065 | Learning rate 0.001256 | train normalized MSE   0.0780 | val normalized MSE   0.0842, | val MAE   1.4278 | val MSE   8.4168\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  47%|████▋     | 70/150 [07:11<08:20,  6.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 070 | Learning rate 0.001093 | train normalized MSE   0.0761 | val normalized MSE   0.0817, | val MAE   1.3358 | val MSE   8.1690\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  50%|█████     | 75/150 [07:42<07:46,  6.22s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 075 | Learning rate 0.000938 | train normalized MSE   0.0744 | val normalized MSE   0.0807, | val MAE   1.3238 | val MSE   8.0699\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  53%|█████▎    | 80/150 [08:13<07:14,  6.21s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 080 | Learning rate 0.000634 | train normalized MSE   0.0731 | val normalized MSE   0.0783, | val MAE   1.3117 | val MSE   7.8253\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  57%|█████▋    | 85/150 [08:45<06:45,  6.23s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 085 | Learning rate 0.000526 | train normalized MSE   0.0719 | val normalized MSE   0.0778, | val MAE   1.3068 | val MSE   7.7824\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  60%|██████    | 90/150 [09:16<06:11,  6.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 090 | Learning rate 0.000427 | train normalized MSE   0.0705 | val normalized MSE   0.0778, | val MAE   1.3213 | val MSE   7.7802\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  63%|██████▎   | 95/150 [09:47<05:45,  6.28s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 095 | Learning rate 0.000338 | train normalized MSE   0.0704 | val normalized MSE   0.0780, | val MAE   1.2929 | val MSE   7.8049\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  67%|██████▋   | 100/150 [10:18<05:12,  6.26s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 100 | Learning rate 0.000259 | train normalized MSE   0.0700 | val normalized MSE   0.0770, | val MAE   1.2869 | val MSE   7.7045\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  70%|███████   | 105/150 [10:50<04:41,  6.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 105 | Learning rate 0.000152 | train normalized MSE   0.0681 | val normalized MSE   0.0777, | val MAE   1.2794 | val MSE   7.7721\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  73%|███████▎  | 110/150 [11:21<04:08,  6.20s/epoch]","output_type":"stream"},{"name":"stdout","text":"Epoch 110 | Learning rate 0.000106 | train normalized MSE   0.0672 | val normalized MSE   0.0785, | val MAE   1.2787 | val MSE   7.8484\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  75%|███████▍  | 112/150 [11:39<03:57,  6.25s/epoch]","output_type":"stream"},{"name":"stdout","text":"==== EARLY STOP at epoch 113\nBEST VALIDATION LOSS (NORMALIZED MSE) SEEN: 0.07671434622495732, AT (epoch, fold) = (88, 4)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Make predictions on the test set\nmodel_predictions_df = predict(test_data)\nassert len(model_predictions_df) == 126000, f\"Incorrect number of rows in output, expected 126000, got {len(model_predictions_df)}\"\n\n# Save output in the submission foldder, timestamped!\nsubmission_path = os.path.join(submission_dir, f\"submission-{get_timestamp()}.csv\")\nmodel_predictions_df.to_csv(submission_path)\nprint(f\"Submission saved locally as: '{submission_path}'.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T22:35:40.747195Z","iopub.execute_input":"2025-05-22T22:35:40.747500Z","iopub.status.idle":"2025-05-22T22:35:41.832678Z","shell.execute_reply.started":"2025-05-22T22:35:40.747475Z","shell.execute_reply":"2025-05-22T22:35:41.831862Z"}},"outputs":[{"name":"stdout","text":"Submission saved locally as: './submission/submission-2025-05-22_10-35PM.csv'.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# Visualize predictions\n\nThese functions are taken from the milestone notebook, with minor additions","metadata":{}},{"cell_type":"code","source":"def plot_trajectory(ax, pred, gt, title=None):\n    ax.cla()\n    # Plot the predicted future trajectory\n    ax.plot(pred[0,:60,0], pred[0,:60,1], color='palevioletred', label='Predicted Future Trajectory')\n    \n    # Plot the ground truth future trajectory\n    ax.plot(gt[0,:60,0], gt[0,:60,1], color='navy', label='Ground Truth Future Trajectory')\n    \n    # Optionally set axis limits, labels, and title.\n    x_max = max(pred[..., 0].max(), gt[..., 0].max())\n    x_min = min(pred[..., 0].min(), gt[..., 0].min())\n    y_max = max(pred[..., 1].max(), gt[..., 1].max())\n    y_min = min(pred[..., 1].min(), gt[..., 1].min())\n    \n    ax.set_xlim(x_min, x_max)\n    ax.set_ylim(y_min, y_max)\n    ax.set_xlabel('X-axis')\n    ax.set_ylabel('Y-axis')\n    \n    if title:\n        ax.set_title(title)\n    \n    ax.legend()\n    ax.grid(True, linestyle='--', alpha=0.7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T22:35:41.833550Z","iopub.execute_input":"2025-05-22T22:35:41.833811Z","iopub.status.idle":"2025-05-22T22:35:41.840085Z","shell.execute_reply.started":"2025-05-22T22:35:41.833792Z","shell.execute_reply":"2025-05-22T22:35:41.839334Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def visualize_predictions(model, val_dataset, graph_save_path: str = f\"{get_timestamp()}_graph.png\"):\n    global input_features\n\n    model.load_state_dict(torch.load(\"best_model.pt\"))\n    model.eval()\n\n    # randomly select 4 samples from the validation set\n    random_indices = random.sample(range(len(val_dataset)), 4)\n    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n    axes = axes.flatten()  # Flatten the array to iterate single axes objects\n\n    for i, idx in enumerate(random_indices):\n        batch = val_dataset[idx]\n        batch_x, batch_y = None, None\n        if isinstance(batch, tuple) or isinstance(batch, list):\n            batch_x, batch_y = batch\n            X_val_tensor = torch.FloatTensor(batch_x).reshape((-1, input_features)).to(device)\n            y_val_tensor = torch.FloatTensor(batch_y.view(-1, 60, 2))\n\n            pred = model(X_val_tensor).cpu().reshape((-1, 60, 2))\n            gt = torch.stack(torch.split(y_val_tensor, 60, dim=0), dim=0).squeeze(dim=0) # getting a phantom dimension\n        else:\n            batch = batch.to(device)\n            batch_x = batch.x\n            batch_y = batch.y\n        \n            pred = model(batch_x)\n            gt = torch.stack(torch.split(batch_y, 60, dim=0), dim=0)\n\n            pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n            gt = torch.stack(torch.split(batch_y, 60, dim=0), dim=0) * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n\n        pred = pred.detach().cpu().numpy()\n        gt = gt.detach().cpu().numpy()\n\n        # Plot the trajectory using the i-th axis\n        plot_trajectory(axes[i], pred, gt, title=f\"Sample {idx}\")\n\n    plt.savefig(fname=graph_save_path)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T22:35:41.843346Z","iopub.execute_input":"2025-05-22T22:35:41.843613Z","iopub.status.idle":"2025-05-22T22:35:41.856793Z","shell.execute_reply.started":"2025-05-22T22:35:41.843597Z","shell.execute_reply":"2025-05-22T22:35:41.856279Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model = get_model()\nif not isinstance(model, SceneContextModel):\n    # LSTM can handle the timeseries data directly\n    # TrajectoryDataset expects numpy arrays\n    collate_func = lambda x: Batch.from_data_list(x)\n    train_dataset = TrajectoryDatasetTrain(train_data, scale=scale, augment=True)\nelse:\n    train_x: np.ndarray = train_data[..., :50, :]\n    train_y: np.ndarray = train_data[:, 0, 50:, :2]\n    X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n    y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n\nvisualize_predictions(model, train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T22:36:11.239641Z","iopub.execute_input":"2025-05-22T22:36:11.240208Z"}},"outputs":[],"execution_count":null}]}