{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission folder if it doesn't exist\n",
    "submission_dir = './submission'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# Uncomment the following block ONLY if you wish to inspect file paths in a Kaggle-like directory structure.\n",
    "# On your local system, you likely have the files in your local folder so this is not needed.\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "# Data Loading for Local Environment\n",
    "# Files are assumed to be in:\n",
    "# ./cse-251-b-2025/train.npz\n",
    "# ./cse-251-b-2025/test_input.npz\n",
    "\n",
    "train_file = np.load(\"./cse-251-b-2025/train.npz\")\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape:\", train_data.shape)  # Expected shape: (10000, 50, 110, 6)\n",
    "\n",
    "test_file = np.load(\"./cse-251-b-2025/test_input.npz\")\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape:\", test_data.shape)    # Expected shape: (2100, 50, 50, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trajectories from one training scene (static plot)\n",
    "data_matrix = train_data[0]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for agent in range(data_matrix.shape[0]):\n",
    "    xs = data_matrix[agent, :, 0]\n",
    "    ys = data_matrix[agent, :, 1]\n",
    "    # Remove zeros (padding)\n",
    "    xs = xs[xs != 0]\n",
    "    ys = ys[ys != 0]\n",
    "    plt.plot(xs, ys, alpha=0.7)\n",
    "plt.title(\"Trajectories from one training scene\")\n",
    "plt.xlabel(\"x-coordinate\")\n",
    "plt.ylabel(\"y-coordinate\")\n",
    "plt.show()\n",
    "\n",
    "# Create an animated gif for one training scene (exact code provided on kaggle)\n",
    "def make_gif(data_matrix, name='example'):\n",
    "    cmap = None\n",
    "    if sys.version_info.minor <= 7:\n",
    "        cmap = plt.cm.get_cmap(\"viridis\", 50)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"viridis\", 50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # Function to update plot for each frame\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        # Get data for current timestep\n",
    "        for i in range(1, data_matrix.shape[0]):\n",
    "            x = data_matrix[i, frame, 0]\n",
    "            y = data_matrix[i, frame, 1]\n",
    "            if x != 0 and y != 0:\n",
    "                xs = data_matrix[i, :frame+1, 0]  # Include current frame\n",
    "                ys = data_matrix[i, :frame+1, 1]  # Include current frame\n",
    "                # trim all zeros\n",
    "                mask = (xs != 0) & (ys != 0)  # Only keep points where both x and y are non-zero\n",
    "                xs = xs[mask]\n",
    "                ys = ys[mask]\n",
    "                # Only plot if we have points to plot\n",
    "                if len(xs) > 0 and len(ys) > 0:\n",
    "                    color = cmap(i)\n",
    "                    ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                    ax.scatter(x, y, s=80, color=color)\n",
    "        ax.plot(data_matrix[0, :frame, 0], data_matrix[0, :frame, 1],\n",
    "                color='tab:orange', label='Ego Vehicle')\n",
    "        ax.scatter(data_matrix[0, frame, 0], data_matrix[0, frame, 1],\n",
    "                   s=80, color='tab:orange')\n",
    "        # Set title with timestep\n",
    "        ax.set_title(f'Timestep {frame}')\n",
    "        # Set consistent axis limits\n",
    "        ax.set_xlim(data_matrix[:,:,0][data_matrix[:,:,0] != 0].min() - 10, \n",
    "                    data_matrix[:,:,0][data_matrix[:,:,0] != 0].max() + 10)\n",
    "        ax.set_ylim(data_matrix[:,:,1][data_matrix[:,:,1] != 0].min() - 10, \n",
    "                    data_matrix[:,:,1][data_matrix[:,:,1] != 0].max() + 10)\n",
    "        ax.legend()\n",
    "        return ax.collections + ax.lines\n",
    "\n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, data_matrix.shape[1], 3)),\n",
    "                                   interval=100, blit=True)\n",
    "    # Save as GIF\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "data_matrix = train_data[0]        \n",
    "make_gif(data_matrix, 'index0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1: Constant Velocity Model for Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this?\n",
    "run_constant_velocity_model = False\n",
    "\n",
    "if run_constant_velocity_model:\n",
    "    # Compute the velocity differences for the ego vehicle (agent index 0)\n",
    "    velocity_diff = test_data[..., 1:, :2] - test_data[..., :-1, :2]\n",
    "    print(\"Velocity difference shape:\", velocity_diff.shape)\n",
    "\n",
    "    # Compute average velocity for the ego vehicle (index 0) in each scene\n",
    "    constant_vel = np.mean(velocity_diff[:, 0, :, :], axis=1)\n",
    "    print(\"Constant velocity shape:\", constant_vel.shape)\n",
    "\n",
    "    # Generate predictions for 60 future time steps based on constant velocity\n",
    "    pred_y_const = np.zeros((test_data.shape[0], 60, 2))\n",
    "    starting_point = test_data[:, 0, -1, :2]  # Last observed position of ego vehicle\n",
    "\n",
    "    for t in range(60):\n",
    "        pred_y_const[:, t, :] = starting_point + (t + 1) * constant_vel\n",
    "\n",
    "    # Reshape predictions to submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_output_const = pred_y_const.reshape(-1, 2)\n",
    "    output_df_const = pd.DataFrame(pred_output_const, columns=['x', 'y'])\n",
    "    output_df_const.index.name = 'index'\n",
    "    # Save output in the submission folder\n",
    "    constant_vel_path = os.path.join(submission_dir, 'constant_vel_submission.csv')\n",
    "    output_df_const.to_csv(constant_vel_path)\n",
    "    print(f\"Constant velocity submission saved locally as '{constant_vel_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 2: MLP Model using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data: use first 50 time steps as input and last 60 time steps of the ego vehicle as output\n",
    "train_x = train_data[..., :50, :]  # Shape: (10000, 50, 50, 6)\n",
    "train_y = train_data[:, 0, 50:, :2]  # Shape: (10000, 60, 2)\n",
    "print(\"Train x shape:\", train_x.shape, \"Train y shape:\", train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline MLP model using Pytorch, untouched from the original notebook\n",
    "\n",
    "# Define the MLP model architecture\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, output_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModel(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(OurModel, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_features, 1024),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, output_features),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Change which model is used at the `model = ...(input_features, output_features)` line.\n",
    "\n",
    "Change which optimizer is used at the `optimizer = optim...` line.\n",
    "\n",
    "Do **NOT** change the `criterion`, as MSE is stated in the Data tab of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of input features after flattening and number of output features\n",
    "input_features = 50 * 50 * 6   # 50 agents, 50 time steps, 6 dimensions each\n",
    "output_features = 60 * 2       # 60 future time steps, 2 dimensions (x, y)\n",
    "\n",
    "# Create the model, loss criterion, and optimizer\n",
    "model = OurModel(input_features, output_features)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3,  weight_decay=1e-2)\n",
    "\n",
    "# Define the training loop for the MLP model\n",
    "def train_model(model, x_train, y_train, batch_size=64, epochs=10):\n",
    "    # Convert numpy arrays to PyTorch tensors and reshape\n",
    "    X_train_tensor = torch.FloatTensor(x_train).reshape((-1, input_features))\n",
    "    y_train_tensor = torch.FloatTensor(y_train).reshape((-1, output_features))\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for batch_X, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}')\n",
    "    return model\n",
    "\n",
    "# Train the model (tweak batch_size and epochs as needed)\n",
    "trained_model = train_model(model, train_x, train_y, batch_size=64, epochs=10)\n",
    "\n",
    "# Define a function for prediction on the test set\n",
    "def predict(model, X_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features))\n",
    "        predictions = model(X_test_tensor).reshape((-1, 60, 2))\n",
    "    return predictions.numpy()\n",
    "\n",
    "# Make predictions on the test set\n",
    "model_predictions = predict(trained_model, test_data)\n",
    "\n",
    "# Reshape predictions to match submission format: (2100, 60, 2) -> (12600, 2)\n",
    "pred_output = model_predictions.reshape(-1, 2)\n",
    "output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "output_df.index.name = 'index'\n",
    "\n",
    "# Save output in the submission foldder, timestamped!\n",
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "\n",
    "submission_path = os.path.join(submission_dir, f\"submission-{timestamp}.csv\")\n",
    "output_df.to_csv(submission_path)\n",
    "print(f\"Submission saved locally as: '{submission_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save and load the model (should correspond to what was trained!)\n",
    "def save_model(model, path=\"our_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "\n",
    "def load_model(path=\"our_model.pth\"):\n",
    "    loaded_model = OurModel(input_features, output_features)\n",
    "    loaded_model.load_state_dict(torch.load(path))\n",
    "    loaded_model.eval()\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# save_model(model)\n",
    "# model = load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
