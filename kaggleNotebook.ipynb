{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data's shape: (10000, 50, 110, 6)\n",
      "test_data's shape: (2100, 50, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create submission folder if it doesn't exist\n",
    "submission_dir = './submission'\n",
    "os.makedirs(submission_dir, exist_ok=True)\n",
    "\n",
    "# Uncomment the following block ONLY if you wish to inspect file paths in a Kaggle-like directory structure.\n",
    "# On your local system, you likely have the files in your local folder so this is not needed.\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "# Data Loading for Local Environment\n",
    "# Files are assumed to be in:\n",
    "# ./cse-251-b-2025/train.npz\n",
    "# ./cse-251-b-2025/test_input.npz\n",
    "\n",
    "train_file = np.load(\"./cse-251-b-2025/train.npz\")\n",
    "train_data = train_file['data']\n",
    "print(\"train_data's shape:\", train_data.shape)  # Expected shape: (10000, 50, 110, 6)\n",
    "\n",
    "test_file = np.load(\"./cse-251-b-2025/test_input.npz\")\n",
    "test_data = test_file['data']\n",
    "print(\"test_data's shape:\", test_data.shape)    # Expected shape: (2100, 50, 50, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run visualizations?\n",
    "run_visualizations: bool = False\n",
    "\n",
    "# From data loading notebook\n",
    "def plot_one_training_scene(idx: int = 0):\n",
    "    # Plot trajectories from one training scene (static plot)\n",
    "    data_matrix = train_data[idx]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for agent in range(data_matrix.shape[idx]):\n",
    "        xs = data_matrix[agent, :, 0]\n",
    "        ys = data_matrix[agent, :, 1]\n",
    "        # Remove zeros (padding)\n",
    "        xs = xs[xs != 0]\n",
    "        ys = ys[ys != 0]\n",
    "        plt.plot(xs, ys, alpha=0.7)\n",
    "    plt.title(\"Trajectories from one training scene\")\n",
    "    plt.xlabel(\"x-coordinate\")\n",
    "    plt.ylabel(\"y-coordinate\")\n",
    "    plt.show()\n",
    "\n",
    "# Create an animated gif for one training scene (exact code provided on kaggle)\n",
    "def make_gif(data_matrix, name='example'):\n",
    "    cmap = None\n",
    "    if sys.version_info.minor <= 7:\n",
    "        cmap = plt.cm.get_cmap(\"viridis\", 50)\n",
    "    else:\n",
    "        cmap = plt.get_cmap(\"viridis\", 50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # Function to update plot for each frame\n",
    "    def update(frame):\n",
    "        ax.clear()\n",
    "        # Get data for current timestep\n",
    "        for i in range(1, data_matrix.shape[0]):\n",
    "            x = data_matrix[i, frame, 0]\n",
    "            y = data_matrix[i, frame, 1]\n",
    "            if x != 0 and y != 0:\n",
    "                xs = data_matrix[i, :frame+1, 0]  # Include current frame\n",
    "                ys = data_matrix[i, :frame+1, 1]  # Include current frame\n",
    "                # trim all zeros\n",
    "                mask = (xs != 0) & (ys != 0)  # Only keep points where both x and y are non-zero\n",
    "                xs = xs[mask]\n",
    "                ys = ys[mask]\n",
    "                # Only plot if we have points to plot\n",
    "                if len(xs) > 0 and len(ys) > 0:\n",
    "                    color = cmap(i)\n",
    "                    ax.plot(xs, ys, alpha=0.9, color=color)\n",
    "                    ax.scatter(x, y, s=80, color=color)\n",
    "        ax.plot(data_matrix[0, :frame, 0], data_matrix[0, :frame, 1],\n",
    "                color='tab:orange', label='Ego Vehicle')\n",
    "        ax.scatter(data_matrix[0, frame, 0], data_matrix[0, frame, 1],\n",
    "                   s=80, color='tab:orange')\n",
    "        # Set title with timestep\n",
    "        ax.set_title(f'Timestep {frame}')\n",
    "        # Set consistent axis limits\n",
    "        ax.set_xlim(data_matrix[:,:,0][data_matrix[:,:,0] != 0].min() - 10, \n",
    "                    data_matrix[:,:,0][data_matrix[:,:,0] != 0].max() + 10)\n",
    "        ax.set_ylim(data_matrix[:,:,1][data_matrix[:,:,1] != 0].min() - 10, \n",
    "                    data_matrix[:,:,1][data_matrix[:,:,1] != 0].max() + 10)\n",
    "        ax.legend()\n",
    "        return ax.collections + ax.lines\n",
    "\n",
    "    # Create animation\n",
    "    anim = animation.FuncAnimation(fig, update, frames=list(range(0, data_matrix.shape[1], 3)),\n",
    "                                   interval=100, blit=True)\n",
    "    # Save as GIF\n",
    "    anim.save(f'trajectory_visualization_{name}.gif', writer='pillow')\n",
    "    plt.close()\n",
    "\n",
    "if run_visualizations:\n",
    "    plot_one_training_scene(0)\n",
    "    make_gif(train_data[0], 'index0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant velocity from test set\n",
    "Untouched from original data loading notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run constant velocity model (Kaggle score of ~50)?\n",
    "run_constant_velocity_model: bool = False\n",
    "\n",
    "if run_constant_velocity_model:\n",
    "    # Compute the velocity differences for the ego vehicle (agent index 0)\n",
    "    velocity_diff = test_data[..., 1:, :2] - test_data[..., :-1, :2]\n",
    "    print(\"Velocity difference shape:\", velocity_diff.shape)\n",
    "\n",
    "    # Compute average velocity for the ego vehicle (index 0) in each scene\n",
    "    constant_vel = np.mean(velocity_diff[:, 0, :, :], axis=1)\n",
    "    print(\"Constant velocity shape:\", constant_vel.shape)\n",
    "\n",
    "    # Generate predictions for 60 future time steps based on constant velocity\n",
    "    pred_y_const = np.zeros((test_data.shape[0], 60, 2))\n",
    "    starting_point = test_data[:, 0, -1, :2]  # Last observed position of ego vehicle\n",
    "\n",
    "    for t in range(60):\n",
    "        pred_y_const[:, t, :] = starting_point + (t + 1) * constant_vel\n",
    "\n",
    "    # Reshape predictions to submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_output_const = pred_y_const.reshape(-1, 2)\n",
    "    output_df_const = pd.DataFrame(pred_output_const, columns=['x', 'y'])\n",
    "    output_df_const.index.name = 'index'\n",
    "    # Save output in the submission folder\n",
    "    constant_vel_path = os.path.join(submission_dir, 'constant_vel_submission.csv')\n",
    "    output_df_const.to_csv(constant_vel_path)\n",
    "    print(f\"Constant velocity submission saved locally as '{constant_vel_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model with residual blocks: ineffective for TimeSeries data\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super().__init__()\n",
    "\n",
    "        # Lazy layers infer the input size instead of having to explicitly pass it in\n",
    "        # Backbone: linear -> BatchNorm -> PReLU -> Dropout\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_features, 2048),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LazyBatchNorm1d(),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        ) # Note: residual width must match the last width of the net\n",
    "\n",
    "        # Residual block added to avoid vanishing gradient issue\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.LazyLinear(256),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(256),\n",
    "        )\n",
    "\n",
    "        # Infer last input shape, then do final projection (60*2)\n",
    "        self.head = nn.LazyLinear(output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, 50, 50, 6) or flattened already\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.net(x) #(batch, 256)\n",
    "        h = h + self.residual(h)  # residual skip\n",
    "        return self.head(h) #(batch, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base LSTM given to us in the milestone notebook\n",
    "class BaseLSTM(nn.Module):\n",
    "    def __init__(self, input_dim:int =6, hidden_dim:int =128, output_dim:int =60 * 2, dropout:float = 0):\n",
    "        super(BaseLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In case you passed in a DataBatch\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi agent scene context model\n",
    "class SceneContextModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.agent_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.ego_encoder = nn.Sequential(\n",
    "            nn.Linear(50 * 6, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 60 * 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_flat):# In case you passed in a DataBatch\n",
    "        if not isinstance(x_flat, torch.Tensor):\n",
    "            x_flat = x_flat.x\n",
    "\n",
    "        B = x_flat.size(0)\n",
    "        x = x_flat.view(B, 50, 50, 6) #(B, agents, timesteps, features)\n",
    "        x_agents = x.view(B, 50, -1)  #(B, 50, 300)\n",
    "        agent_feats = self.agent_encoder(x_agents) #(B, 50, hidden_dim)\n",
    "        scene_context = agent_feats.mean(dim=1) #(B, hidden_dim)\n",
    "\n",
    "        ego_input = x[:, 0, :, :].reshape(B, -1) #(B, 300)\n",
    "        ego_feat = self.ego_encoder(ego_input) #(B, hidden_dim)\n",
    "\n",
    "        combined = torch.cat([ego_feat, scene_context], dim=1)\n",
    "        return self.decoder(combined) #(B, 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "\n",
    "`TrajectoryDataset*` are taken from the milestone notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                # future = future @ R gives DeprecationWarning: future a torch.Tensor\n",
    "                future = torch.from_numpy(np.dot(future.numpy(), R)) \n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        # future = future - origin -> same DeprecationWarning\n",
    "        future = torch.from_numpy(future.numpy() - origin)\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "Change which model is used at the `model = ...(input_features, output_features)` line.\n",
    "\n",
    "Change which optimizer is used at the `optimizer = optim...` line.\n",
    "\n",
    "Do **NOT** change the `criterion`, as MSE is stated in the Data tab of the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "# Taken from milestone notebook\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save and load the model (should correspond to what was trained!)\n",
    "def save_model(model, path=\"our_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "\n",
    "def load_model(model_instance, path=\"our_model.pth\"):\n",
    "    loaded_model = model_instance\n",
    "    loaded_model.load_state_dict(torch.load(path))\n",
    "    loaded_model.eval()\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# save_model(trained_model)\n",
    "# model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD 1/4 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▎         | 5/200 [00:11<07:12,  2.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.009212 | train normalized MSE   0.1994 | val normalized MSE   0.1968, | val MAE   2.5233 | val MSE  19.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 10/200 [00:22<07:07,  2.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.008286 | train normalized MSE   0.1787 | val normalized MSE   0.1959, | val MAE   2.5990 | val MSE  19.5908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 15/200 [00:36<08:35,  2.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.007425 | train normalized MSE   0.1532 | val normalized MSE   0.1507, | val MAE   2.0977 | val MSE  15.0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 20/200 [00:51<08:59,  3.00s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.006627 | train normalized MSE   0.1365 | val normalized MSE   0.1258, | val MAE   1.8434 | val MSE  12.5803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 25/200 [01:06<08:36,  2.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.005892 | train normalized MSE   0.1255 | val normalized MSE   0.1314, | val MAE   1.8664 | val MSE  13.1405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 30/200 [01:19<07:45,  2.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.005218 | train normalized MSE   0.1196 | val normalized MSE   0.1153, | val MAE   1.7319 | val MSE  11.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 35/200 [01:33<07:38,  2.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.004602 | train normalized MSE   0.1121 | val normalized MSE   0.1124, | val MAE   1.6705 | val MSE  11.2447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 40/200 [01:47<07:19,  2.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.004042 | train normalized MSE   0.1117 | val normalized MSE   0.1151, | val MAE   1.6735 | val MSE  11.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▎       | 45/200 [02:01<07:26,  2.88s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.003535 | train normalized MSE   0.1014 | val normalized MSE   0.1077, | val MAE   1.6668 | val MSE  10.7653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 50/200 [02:15<06:41,  2.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Learning rate 0.003078 | train normalized MSE   0.0972 | val normalized MSE   0.0990, | val MAE   1.5061 | val MSE   9.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 55/200 [02:28<06:26,  2.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Learning rate 0.002668 | train normalized MSE   0.0951 | val normalized MSE   0.1014, | val MAE   1.5444 | val MSE  10.1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 60/200 [02:41<06:05,  2.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 060 | Learning rate 0.002302 | train normalized MSE   0.0932 | val normalized MSE   0.1016, | val MAE   1.5286 | val MSE  10.1582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▎      | 65/200 [02:54<05:51,  2.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 065 | Learning rate 0.001976 | train normalized MSE   0.0921 | val normalized MSE   0.0958, | val MAE   1.4562 | val MSE   9.5786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 70/200 [03:08<05:50,  2.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 070 | Learning rate 0.001687 | train normalized MSE   0.0896 | val normalized MSE   0.0968, | val MAE   1.4962 | val MSE   9.6754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 75/200 [03:21<05:25,  2.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 075 | Learning rate 0.001433 | train normalized MSE   0.0938 | val normalized MSE   0.0999, | val MAE   1.5473 | val MSE   9.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 80/200 [03:36<05:47,  2.90s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 080 | Learning rate 0.001210 | train normalized MSE   0.0881 | val normalized MSE   0.0947, | val MAE   1.4270 | val MSE   9.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▎     | 85/200 [03:50<05:24,  2.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 085 | Learning rate 0.001015 | train normalized MSE   0.0871 | val normalized MSE   0.0957, | val MAE   1.4355 | val MSE   9.5691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 90/200 [04:03<04:58,  2.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 090 | Learning rate 0.000846 | train normalized MSE   0.0867 | val normalized MSE   0.0932, | val MAE   1.4456 | val MSE   9.3195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 95/200 [04:17<04:43,  2.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 095 | Learning rate 0.000700 | train normalized MSE   0.0842 | val normalized MSE   0.0935, | val MAE   1.4403 | val MSE   9.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 100/200 [04:31<04:34,  2.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Learning rate 0.000575 | train normalized MSE   0.0814 | val normalized MSE   0.0941, | val MAE   1.4502 | val MSE   9.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▎    | 105/200 [04:44<04:21,  2.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 | Learning rate 0.000468 | train normalized MSE   0.0807 | val normalized MSE   0.0914, | val MAE   1.4162 | val MSE   9.1353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 110/200 [04:58<04:02,  2.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 | Learning rate 0.000377 | train normalized MSE   0.0793 | val normalized MSE   0.0920, | val MAE   1.3971 | val MSE   9.2035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▊    | 115/200 [05:11<03:41,  2.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 | Learning rate 0.000301 | train normalized MSE   0.0770 | val normalized MSE   0.0912, | val MAE   1.3934 | val MSE   9.1181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 120/200 [05:24<03:26,  2.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 | Learning rate 0.000238 | train normalized MSE   0.0785 | val normalized MSE   0.0908, | val MAE   1.3913 | val MSE   9.0845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 125/200 [05:37<03:18,  2.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 | Learning rate 0.000185 | train normalized MSE   0.0778 | val normalized MSE   0.0916, | val MAE   1.4048 | val MSE   9.1596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 125/200 [05:40<03:24,  2.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EARLY STOP at epoch 126\n",
      "\n",
      "FOLD 2/4 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   2%|▎         | 5/200 [00:24<15:37,  4.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.009212 | train normalized MSE   0.1733 | val normalized MSE   0.1664, | val MAE   2.1893 | val MSE  16.6385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 10/200 [00:47<14:23,  4.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.008286 | train normalized MSE   0.1359 | val normalized MSE   0.1432, | val MAE   1.9968 | val MSE  14.3215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 15/200 [01:09<13:49,  4.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.007425 | train normalized MSE   0.1180 | val normalized MSE   0.1210, | val MAE   1.6747 | val MSE  12.0971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 20/200 [01:32<13:17,  4.43s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.006627 | train normalized MSE   0.1114 | val normalized MSE   0.1116, | val MAE   1.6363 | val MSE  11.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 25/200 [01:54<13:04,  4.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.005892 | train normalized MSE   0.1050 | val normalized MSE   0.1113, | val MAE   1.6734 | val MSE  11.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 30/200 [02:17<12:48,  4.52s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.005218 | train normalized MSE   0.1021 | val normalized MSE   0.1063, | val MAE   1.5571 | val MSE  10.6291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 35/200 [02:42<13:29,  4.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.004602 | train normalized MSE   0.0971 | val normalized MSE   0.1119, | val MAE   1.7463 | val MSE  11.1862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 40/200 [03:08<13:55,  5.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.004042 | train normalized MSE   0.0992 | val normalized MSE   0.1059, | val MAE   1.5736 | val MSE  10.5924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▎       | 45/200 [03:34<13:32,  5.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.003535 | train normalized MSE   0.0911 | val normalized MSE   0.1012, | val MAE   1.5317 | val MSE  10.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 50/200 [03:57<11:39,  4.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Learning rate 0.003078 | train normalized MSE   0.0892 | val normalized MSE   0.1071, | val MAE   1.6161 | val MSE  10.7060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 55/200 [04:19<10:30,  4.35s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Learning rate 0.002668 | train normalized MSE   0.0876 | val normalized MSE   0.0983, | val MAE   1.5416 | val MSE   9.8277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 60/200 [04:41<10:49,  4.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 060 | Learning rate 0.002302 | train normalized MSE   0.0867 | val normalized MSE   0.0984, | val MAE   1.5197 | val MSE   9.8356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▎      | 65/200 [05:05<10:37,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 065 | Learning rate 0.001976 | train normalized MSE   0.0854 | val normalized MSE   0.0974, | val MAE   1.5103 | val MSE   9.7410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 70/200 [05:29<10:04,  4.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 070 | Learning rate 0.001687 | train normalized MSE   0.0831 | val normalized MSE   0.0966, | val MAE   1.4802 | val MSE   9.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 75/200 [05:52<09:48,  4.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 075 | Learning rate 0.001433 | train normalized MSE   0.0819 | val normalized MSE   0.0967, | val MAE   1.4718 | val MSE   9.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 80/200 [06:16<09:31,  4.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 080 | Learning rate 0.001210 | train normalized MSE   0.0831 | val normalized MSE   0.0938, | val MAE   1.4415 | val MSE   9.3752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▎     | 85/200 [06:39<08:55,  4.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 085 | Learning rate 0.001015 | train normalized MSE   0.0785 | val normalized MSE   0.0923, | val MAE   1.4121 | val MSE   9.2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 90/200 [07:03<08:33,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 090 | Learning rate 0.000846 | train normalized MSE   0.0788 | val normalized MSE   0.0954, | val MAE   1.4401 | val MSE   9.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 95/200 [07:26<08:10,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 095 | Learning rate 0.000700 | train normalized MSE   0.0775 | val normalized MSE   0.0931, | val MAE   1.4130 | val MSE   9.3101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 100/200 [07:48<07:26,  4.46s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Learning rate 0.000575 | train normalized MSE   0.0771 | val normalized MSE   0.0925, | val MAE   1.4342 | val MSE   9.2525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▎    | 105/200 [08:10<06:56,  4.39s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 | Learning rate 0.000468 | train normalized MSE   0.0756 | val normalized MSE   0.0918, | val MAE   1.3861 | val MSE   9.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 110/200 [08:32<06:46,  4.52s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 | Learning rate 0.000377 | train normalized MSE   0.0751 | val normalized MSE   0.0923, | val MAE   1.4008 | val MSE   9.2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▊    | 115/200 [08:55<06:20,  4.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 | Learning rate 0.000301 | train normalized MSE   0.0729 | val normalized MSE   0.0914, | val MAE   1.3882 | val MSE   9.1436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 120/200 [09:17<05:55,  4.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 | Learning rate 0.000238 | train normalized MSE   0.0741 | val normalized MSE   0.0921, | val MAE   1.4006 | val MSE   9.2071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 125/200 [09:40<05:32,  4.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 | Learning rate 0.000185 | train normalized MSE   0.0727 | val normalized MSE   0.0911, | val MAE   1.3852 | val MSE   9.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 130/200 [10:01<05:03,  4.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 | Learning rate 0.000142 | train normalized MSE   0.0730 | val normalized MSE   0.0918, | val MAE   1.3800 | val MSE   9.1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 131/200 [10:10<05:21,  4.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EARLY STOP at epoch 132\n",
      "\n",
      "FOLD 3/4 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   2%|▎         | 5/200 [00:32<21:06,  6.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.009212 | train normalized MSE   0.1655 | val normalized MSE   0.1515, | val MAE   1.9834 | val MSE  15.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 10/200 [01:05<20:32,  6.48s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.008286 | train normalized MSE   0.1327 | val normalized MSE   0.1525, | val MAE   2.0923 | val MSE  15.2541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 15/200 [01:36<19:28,  6.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.007425 | train normalized MSE   0.1109 | val normalized MSE   0.1132, | val MAE   1.7599 | val MSE  11.3239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 20/200 [02:07<18:28,  6.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.006627 | train normalized MSE   0.1152 | val normalized MSE   0.1087, | val MAE   1.6222 | val MSE  10.8716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 25/200 [02:37<17:14,  5.91s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.005892 | train normalized MSE   0.0985 | val normalized MSE   0.1040, | val MAE   1.6316 | val MSE  10.4038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 30/200 [03:08<18:00,  6.36s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.005218 | train normalized MSE   0.0974 | val normalized MSE   0.1029, | val MAE   1.5670 | val MSE  10.2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 35/200 [03:36<15:20,  5.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.004602 | train normalized MSE   0.0932 | val normalized MSE   0.0954, | val MAE   1.4789 | val MSE   9.5362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 40/200 [04:02<14:08,  5.30s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.004042 | train normalized MSE   0.0911 | val normalized MSE   0.0914, | val MAE   1.4380 | val MSE   9.1385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▎       | 45/200 [04:30<14:13,  5.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.003535 | train normalized MSE   0.0898 | val normalized MSE   0.0905, | val MAE   1.4436 | val MSE   9.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 50/200 [04:58<14:05,  5.64s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Learning rate 0.003078 | train normalized MSE   0.0874 | val normalized MSE   0.0902, | val MAE   1.4225 | val MSE   9.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 55/200 [05:30<14:45,  6.11s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Learning rate 0.002668 | train normalized MSE   0.0857 | val normalized MSE   0.0899, | val MAE   1.4300 | val MSE   8.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 60/200 [05:59<13:26,  5.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 060 | Learning rate 0.002302 | train normalized MSE   0.0844 | val normalized MSE   0.0874, | val MAE   1.4122 | val MSE   8.7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▎      | 65/200 [06:29<13:42,  6.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 065 | Learning rate 0.001976 | train normalized MSE   0.0834 | val normalized MSE   0.0871, | val MAE   1.3899 | val MSE   8.7059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 70/200 [06:59<13:28,  6.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 070 | Learning rate 0.001687 | train normalized MSE   0.0820 | val normalized MSE   0.0895, | val MAE   1.3847 | val MSE   8.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 75/200 [07:32<13:19,  6.40s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 075 | Learning rate 0.001433 | train normalized MSE   0.0804 | val normalized MSE   0.0868, | val MAE   1.3992 | val MSE   8.6764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 80/200 [08:03<12:28,  6.24s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 080 | Learning rate 0.001210 | train normalized MSE   0.0801 | val normalized MSE   0.0847, | val MAE   1.3642 | val MSE   8.4742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▎     | 85/200 [08:33<11:36,  6.05s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 085 | Learning rate 0.001015 | train normalized MSE   0.0785 | val normalized MSE   0.0855, | val MAE   1.3847 | val MSE   8.5486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 90/200 [09:03<11:02,  6.02s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 090 | Learning rate 0.000846 | train normalized MSE   0.0776 | val normalized MSE   0.0839, | val MAE   1.3521 | val MSE   8.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 95/200 [09:33<10:24,  5.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 095 | Learning rate 0.000700 | train normalized MSE   0.0764 | val normalized MSE   0.0841, | val MAE   1.3403 | val MSE   8.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 100/200 [10:04<10:29,  6.30s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Learning rate 0.000575 | train normalized MSE   0.0764 | val normalized MSE   0.0853, | val MAE   1.3550 | val MSE   8.5288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▎    | 105/200 [10:34<09:05,  5.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 | Learning rate 0.000468 | train normalized MSE   0.0770 | val normalized MSE   0.0844, | val MAE   1.3390 | val MSE   8.4439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 110/200 [11:00<08:06,  5.40s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 | Learning rate 0.000377 | train normalized MSE   0.0750 | val normalized MSE   0.0840, | val MAE   1.3277 | val MSE   8.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▊    | 115/200 [11:27<07:49,  5.52s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 | Learning rate 0.000301 | train normalized MSE   0.0737 | val normalized MSE   0.0842, | val MAE   1.3460 | val MSE   8.4212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  59%|█████▉    | 118/200 [11:51<08:14,  6.03s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EARLY STOP at epoch 119\n",
      "\n",
      "FOLD 4/4 ==================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   2%|▎         | 5/200 [00:35<23:10,  7.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.009212 | train normalized MSE   0.1502 | val normalized MSE   0.1412, | val MAE   2.0292 | val MSE  14.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 10/200 [01:09<22:04,  6.97s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.008286 | train normalized MSE   0.1346 | val normalized MSE   0.1734, | val MAE   2.2311 | val MSE  17.3427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 15/200 [01:44<21:09,  6.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.007425 | train normalized MSE   0.1091 | val normalized MSE   0.1090, | val MAE   1.6654 | val MSE  10.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 20/200 [02:17<20:13,  6.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.006627 | train normalized MSE   0.1009 | val normalized MSE   0.1043, | val MAE   1.5834 | val MSE  10.4346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 25/200 [02:52<20:42,  7.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.005892 | train normalized MSE   0.0969 | val normalized MSE   0.1037, | val MAE   1.6797 | val MSE  10.3749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 30/200 [03:25<18:39,  6.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.005218 | train normalized MSE   0.0939 | val normalized MSE   0.0944, | val MAE   1.4601 | val MSE   9.4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 35/200 [04:01<20:11,  7.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.004602 | train normalized MSE   0.0911 | val normalized MSE   0.0926, | val MAE   1.4399 | val MSE   9.2643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 40/200 [04:42<21:33,  8.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.004042 | train normalized MSE   0.0889 | val normalized MSE   0.0935, | val MAE   1.4736 | val MSE   9.3471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▎       | 45/200 [05:20<19:22,  7.50s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.003535 | train normalized MSE   0.1099 | val normalized MSE   0.1040, | val MAE   1.6041 | val MSE  10.3984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 50/200 [05:54<16:46,  6.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Learning rate 0.003078 | train normalized MSE   0.0981 | val normalized MSE   0.0990, | val MAE   1.4877 | val MSE   9.8956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 55/200 [06:28<16:49,  6.96s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Learning rate 0.002668 | train normalized MSE   0.0948 | val normalized MSE   0.0972, | val MAE   1.4939 | val MSE   9.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 55/200 [06:36<17:24,  7.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EARLY STOP at epoch 056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved locally as: './submission\\submission-2025-05-09_01-17PM.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of input features after flattening and number of output features\n",
    "# Note: LSTM models take features in different dimensions\n",
    "input_features:int = 50 * 50 * 6   # 50 agents, 50 time steps, 6 dimensions each (15000 input features)\n",
    "output_features:int = 60 * 2       # 60 future time steps, 2 dimensions (x, y) (120 output features)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size:int = 64\n",
    "num_folds:int = 4\n",
    "early_stopping_patience:int = 20\n",
    "early_stopping_threshold:float = 1e-4\n",
    "epochs:int = 200\n",
    "starting_lr:float = 1e-2\n",
    "scale:float = 10.0\n",
    "\n",
    "lstm_hidden_dim = 128\n",
    "\n",
    "SEED: int = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def train_model(full_training_data: np.ndarray, \n",
    "                batch_size:int = 64, epochs:int = 10, num_folds:int = 5,\n",
    "                early_stopping_patience:int = 5, early_stopping_threshold:float = 1e-3):\n",
    "    global starting_lr, gamma, scale, lstm_hidden_dim, output_features\n",
    "\n",
    "    # Time series data needs to keep its data in relative order, so no shuffling can occur\n",
    "    #   like in regular KFold cross validation\n",
    "    splitter = TimeSeriesSplit(n_splits=num_folds)\n",
    "\n",
    "    # Perform cross-validation, the best model will be saved as \"best_model.pt\" to be loaded in later\n",
    "    overall_best_val_loss = float(\"inf\")\n",
    "\n",
    "    # Resources used:\n",
    "    # Project milestone notebook\n",
    "    # https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-pytorch.md\n",
    "    # https://www.geeksforgeeks.org/time-series-cross-validation/\n",
    "    for fold_i, (train_idx, val_idx) in enumerate(splitter.split(full_training_data)):\n",
    "        print(f\"\\nFOLD {fold_i + 1}/{num_folds} ==================================\")\n",
    "\n",
    "        # Create the model, loss criterion, and optimizer (reset per fold, to find the best model)\n",
    "        # If you change the model here, ensure its the same in the test loop!\n",
    "        # DO NOT CHANGE CRITERION\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        model = BaseLSTM(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n",
    "        # model = SceneContextModel(hidden_dim=864).to(device)\n",
    "\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=starting_lr, weight_decay=1e-2)\n",
    "        schedulers: list[lr_scheduler.LRScheduler] =[\n",
    "            lr_scheduler.ExponentialLR(optimizer, gamma=0.98),\n",
    "            lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, \n",
    "                T_max= int(epochs * 0.9),\n",
    "                eta_min=1e-5\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Prepare data from this fold\n",
    "        train_fold: np.ndarray = full_training_data[train_idx]\n",
    "        val_fold: np.ndarray = full_training_data[val_idx]\n",
    "        collate_func = None     # Optional for DataLoader, taken from milestone notebook\n",
    "        if isinstance(model, BaseLSTM):\n",
    "            # LSTM can handle the timeseries data directly\n",
    "            # TrajectoryDataset expects numpy arrays\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            train_dataset = TrajectoryDatasetTrain(train_fold, scale=scale, augment=True)\n",
    "            val_dataset = TrajectoryDatasetTrain(val_fold, scale=scale, augment=False)\n",
    "        else:\n",
    "            train_x: np.ndarray = train_fold[..., :50, :]\n",
    "            train_y: np.ndarray = train_fold[:, 0, 50:, :2]\n",
    "            X_train_tensor = torch.FloatTensor(train_x).reshape((-1, input_features))\n",
    "            y_train_tensor = torch.FloatTensor(train_y).reshape((-1, output_features))\n",
    "            train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "            val_x: np.ndarray = val_fold[..., :50, :]\n",
    "            val_y: np.ndarray = val_fold[:, 0, 50:, :2]\n",
    "            X_val_tensor = torch.FloatTensor(val_x).reshape((-1, input_features))\n",
    "            y_val_tensor = torch.FloatTensor(val_y).reshape((-1, output_features))\n",
    "            val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "       \n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_func)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "        best_val_loss: float = float(\"inf\")\n",
    "        no_improvement: int = 0\n",
    "\n",
    "        # Training and validation loops are taken from the milestone notebook,\n",
    "        #   with modifications to allow for different data loading shapes      \n",
    "        for epoch in tqdm(range(epochs), desc=\"Epoch\", unit=\"epoch\"):\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch in train_dataloader:\n",
    "                batch_x = None\n",
    "                batch_y = None\n",
    "                if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                    batch_x, batch_y = batch\n",
    "                else: # DataBatch type\n",
    "                    batch = batch.to(device)\n",
    "                    batch_x = batch.x\n",
    "                    batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_mae = 0\n",
    "            val_mse = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    batch_x = None\n",
    "                    batch_y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        batch_x, batch_y = batch\n",
    "                    else: # DataBatch type\n",
    "                        batch = batch.to(device)\n",
    "                        batch_x = batch.x\n",
    "                        batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                    pred = model(batch_x)\n",
    "                    val_loss += criterion(pred, batch_y).item()\n",
    "\n",
    "                    # show MAE and MSE with unnormalized data\n",
    "                    y = None\n",
    "                    if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                        y = batch_y\n",
    "                    else: # DataBatch type\n",
    "                        pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                        y = batch_y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                    val_mae += nn.L1Loss()(pred, y).item()\n",
    "                    val_mse += nn.MSELoss()(pred, y).item()\n",
    "\n",
    "            train_loss /= len(train_dataloader)\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_mae /= len(val_dataloader)\n",
    "            val_mse /= len(val_dataloader)\n",
    "\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                tqdm.write(f\"Epoch {(epoch + 1):03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "\n",
    "            if val_loss < best_val_loss - early_stopping_threshold:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "\n",
    "                # Better than the overall seen so far?\n",
    "                if best_val_loss < overall_best_val_loss:\n",
    "                    overall_best_val_loss = best_val_loss\n",
    "                    torch.save(model.state_dict(), \"best_model.pt\")\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                if no_improvement >= early_stopping_patience:\n",
    "                    print(f\"==== EARLY STOP at epoch {(epoch + 1):03d}\")\n",
    "                    break\n",
    "\n",
    "            for sched in schedulers:\n",
    "                sched.step()\n",
    "\n",
    "\n",
    "# Load in the model saved during testing to use on X_test\n",
    "# Mostly taken from milestone notebook\n",
    "def predict(X_test, best_model_path: str = \"best_model.pt\"):\n",
    "    global scale, batch_size, lstm_hidden_dim, output_features\n",
    "\n",
    "    # Ensure this aligns with the trained model!\n",
    "    best_model = torch.load(best_model_path)\n",
    "    model = BaseLSTM(input_dim=6, hidden_dim=lstm_hidden_dim, output_dim=output_features).to(device)\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model, BaseLSTM): # Using DataBatch type from a DataLoader\n",
    "            collate_func = lambda x: Batch.from_data_list(x)\n",
    "            test_dataset = TrajectoryDatasetTest(X_test, scale=scale)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                pred_norm = model(batch.x)\n",
    "\n",
    "                # Reshape the prediction to (N, 60, 2)\n",
    "                pred = pred_norm * batch.scale.view(-1,1,1) + batch.origin.unsqueeze(1)\n",
    "                pred_list.append(pred.cpu().numpy())\n",
    "        else:\n",
    "            X_test_tensor = torch.FloatTensor(X_test).reshape((-1, input_features)).to(device)\n",
    "            pred = model(X_test_tensor).cpu().reshape((-1, 60, 2))\n",
    "            pred_list.append(pred.numpy())\n",
    "\n",
    "    # Reshape predictions to match submission format: (2100, 60, 2) -> (12600, 2)\n",
    "    pred_list = np.concatenate(pred_list, axis=0)  # (N,60,2)\n",
    "    pred_output = pred_list.reshape(-1, 2)  # (N*60, 2)\n",
    "    output_df = pd.DataFrame(pred_output, columns=['x', 'y'])\n",
    "    output_df.index.name = 'index'\n",
    "    return output_df\n",
    "\n",
    "# Train the model (tweak batch_size and epochs as needed at top of this block)\n",
    "# Saved as \"best_model.pt\" to be loaded in during testing\n",
    "train_model(train_data, batch_size=batch_size, epochs=epochs, num_folds=num_folds,\n",
    "            early_stopping_patience=early_stopping_patience,\n",
    "            early_stopping_threshold=early_stopping_threshold)\n",
    "\n",
    "# Make predictions on the test set\n",
    "model_predictions_df = predict(test_data)\n",
    "assert len(model_predictions_df) == 126000, f\"Incorrect number of rows in output, expected 126000, got {len(model_predictions_df)}\"\n",
    "\n",
    "# Save output in the submission foldder, timestamped!\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%I-%M%p\")\n",
    "\n",
    "submission_path = os.path.join(submission_dir, f\"submission-{timestamp}.csv\")\n",
    "model_predictions_df.to_csv(submission_path)\n",
    "print(f\"Submission saved locally as: '{submission_path}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
