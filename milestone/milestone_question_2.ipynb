{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d633ff66",
   "metadata": {},
   "source": [
    "# CSE 251B Project Milestone Problem 2 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eb0a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apple Silicon GPU\n"
     ]
    }
   ],
   "source": [
    "# from starter file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ParameterGrid, TimeSeriesSplit\n",
    "from typing import Dict, List, Tuple\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "import itertools\n",
    "\n",
    "\n",
    "train_npz = np.load('./train.npz')\n",
    "train_data = train_npz['data']\n",
    "test_npz  = np.load('./test_input.npz')\n",
    "test_data  = test_npz['data']\n",
    "\n",
    "X_train = train_data[..., :50, :]\n",
    "Y_train = train_data[:, 0, 50:, :2]\n",
    "\n",
    "class TrajectoryDatasetTrain(Dataset):\n",
    "    def __init__(self, data, scale=10.0, augment=True):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Training data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        augment: Whether to apply data augmentation (only for training)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]\n",
    "        # Getting 50 historical timestamps and 60 future timestamps\n",
    "        hist = scene[:, :50, :].copy()    # (agents=50, time_seq=50, 6)\n",
    "        future = torch.tensor(scene[0, 50:, :2].copy(), dtype=torch.float32)  # (60, 2)\n",
    "        \n",
    "        # Data augmentation(only for training)\n",
    "        if self.augment:\n",
    "            if np.random.rand() < 0.5:\n",
    "                theta = np.random.uniform(-np.pi, np.pi)\n",
    "                R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                              [np.sin(theta),  np.cos(theta)]], dtype=np.float32)\n",
    "                # Rotate the historical trajectory and future trajectory\n",
    "                hist[..., :2] = hist[..., :2] @ R\n",
    "                hist[..., 2:4] = hist[..., 2:4] @ R\n",
    "                future = future @ R\n",
    "            if np.random.rand() < 0.5:\n",
    "                hist[..., 0] *= -1\n",
    "                hist[..., 2] *= -1\n",
    "                future[:, 0] *= -1\n",
    "\n",
    "        # Use the last timeframe of the historical trajectory as the origin\n",
    "        origin = hist[0, 49, :2].copy()  # (2,)\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        future = future - origin\n",
    "\n",
    "        # Normalize the historical trajectory and future trajectory\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "        future = future / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            y=future.type(torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "        return data_item\n",
    "    \n",
    "\n",
    "class TrajectoryDatasetTest(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        \"\"\"\n",
    "        data: Shape (N, 50, 110, 6) Testing data\n",
    "        scale: Scale for normalization (suggested to use 10.0 for Argoverse 2 data)\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.scale = scale\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Testing data only contains historical trajectory\n",
    "        scene = self.data[idx]  # (50, 50, 6)\n",
    "        hist = scene.copy()\n",
    "        \n",
    "        origin = hist[0, 49, :2].copy()\n",
    "        hist[..., :2] = hist[..., :2] - origin\n",
    "        hist[..., :4] = hist[..., :4] / self.scale\n",
    "\n",
    "        data_item = Data(\n",
    "            x=torch.tensor(hist, dtype=torch.float32),\n",
    "            origin=torch.tensor(origin, dtype=torch.float32).unsqueeze(0),\n",
    "            scale=torch.tensor(self.scale, dtype=torch.float32),\n",
    "        )\n",
    "        return data_item\n",
    "\n",
    "torch.manual_seed(251)\n",
    "np.random.seed(42)\n",
    "\n",
    "scale = 7.0\n",
    "\n",
    "N = len(train_data)\n",
    "val_size = int(0.1 * N)\n",
    "train_size = N - val_size\n",
    "\n",
    "train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "# Set device for training speedup\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Using Apple Silicon GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e989437",
   "metadata": {},
   "source": [
    "Disclaimer: some code taken from starter code notebook and some code is referenced from AI sources (i.e. ChatGPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9fe51",
   "metadata": {},
   "source": [
    "### Problem 2A - Searching for the optimal parameters to train our model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dea3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided to use the Adam optimizer\n",
    "# define hyperparameter search space\n",
    "search_params = {\n",
    "    'learning_rate': [1e-2, 5e-3, 1e-3, 5e-4],\n",
    "    'weight_decay': [1e-3, 1e-4, 1e-5, 0.0],\n",
    "    'step_size': [10, 20, 30],\n",
    "    'gamma': [0.5, 0.25, 0.1]\n",
    "}\n",
    "\n",
    "# define model to use for the search (LSTM in this case)\n",
    "model_kwargs = {\n",
    "    'input_dim': 6,\n",
    "    'hidden_dim': 128,\n",
    "    'output_dim': 60*2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd60e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search(\n",
    "    train_data: np.ndarray,\n",
    "    model_class,\n",
    "    model_kwargs: Dict = {},\n",
    "    search_params: Dict = None,\n",
    "    batch_size: int = 32,\n",
    "    val_ratio: float = 0.1,\n",
    "    scale: float = 7.0,\n",
    "    max_epochs: int = 30,\n",
    "    early_stopping_patience: int = 5,\n",
    "    device: torch.device = None,\n",
    "    results_dir: str = 'hyperparameter_search_results',\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter search for trajectory prediction model.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training data\n",
    "        model_class: Model class to instantiate\n",
    "        model_kwargs: Additional model parameters\n",
    "        search_params: Dictionary of parameters to search over\n",
    "        batch_size: Batch size for training\n",
    "        val_ratio: Proportion of data to use for validation\n",
    "        scale: Scale factor for normalization\n",
    "        max_epochs: Maximum number of epochs to train\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "        device: Device to train on\n",
    "        results_dir: Directory to save results\n",
    "        verbose: Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        results_df: DataFrame of results\n",
    "        best_params: Best parameters found\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device('mps')\n",
    "            print(\"Using Apple Silicon GPU\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(\"Using CUDA GPU\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"Using CPU\")\n",
    "    \n",
    "    if search_params is None:\n",
    "        search_params = {\n",
    "            'learning_rate': [1e-2, 1e-3, 5e-4],\n",
    "            'weight_decay': [1e-4, 1e-5, 0.0],\n",
    "            'step_size': [10, 20, 30],\n",
    "            'gamma': [0.5, 0.25, 0.1]\n",
    "        }\n",
    "    \n",
    "    # Create directory for results\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Prepare the data\n",
    "    N = len(train_data)\n",
    "    val_size = int(val_ratio * N)\n",
    "    train_size = N - val_size\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "    val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=lambda x: Batch.from_data_list(x)\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=lambda x: Batch.from_data_list(x)\n",
    "    )\n",
    "    \n",
    "    # Generate parameter combinations\n",
    "    param_grid = list(ParameterGrid(search_params))\n",
    "    if verbose:\n",
    "        print(f\"Testing {len(param_grid)} parameter combinations\")\n",
    "    \n",
    "    # Initialize results tracking\n",
    "    results = []\n",
    "    \n",
    "    # Run hyperparameter search\n",
    "    for param_idx, params in enumerate(param_grid):\n",
    "        if verbose:\n",
    "            print(f\"\\nParameter set {param_idx+1}/{len(param_grid)}: {params}\")\n",
    "        \n",
    "        # Create model\n",
    "        model = model_class(**model_kwargs).to(device)\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        optimizer = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=params['learning_rate'],\n",
    "            weight_decay=params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size=params['step_size'],\n",
    "            gamma=params['gamma']\n",
    "        )\n",
    "        \n",
    "        # Track best validation loss\n",
    "        best_val_loss = float('inf')\n",
    "        no_improvement = 0\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Track metrics\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        val_maes = []\n",
    "        val_mses = []\n",
    "        epoch_times = []\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(max_epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # ---- Training ----\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for batch in train_dataloader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                loss = criterion(pred, y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            # ---- Validation ----\n",
    "            model.eval()\n",
    "            val_loss = 0\n",
    "            val_mae = 0\n",
    "            val_mse = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in val_dataloader:\n",
    "                    batch = batch.to(device)\n",
    "                    pred = model(batch)\n",
    "                    y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                    val_loss += criterion(pred, y).item()\n",
    "                    \n",
    "                    # Unnormalize for metric calculation\n",
    "                    pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                    y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                    \n",
    "                    val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
    "                    val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
    "            \n",
    "            # Calculate average losses\n",
    "            train_loss /= len(train_dataloader)\n",
    "            val_loss /= len(val_dataloader)\n",
    "            val_mae /= len(val_dataloader)\n",
    "            val_mse /= len(val_dataloader)\n",
    "            \n",
    "            # Step scheduler\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Track time\n",
    "            epoch_time = time.time() - start_time\n",
    "            epoch_times.append(epoch_time)\n",
    "            \n",
    "            # Track metrics\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            val_maes.append(val_mae)\n",
    "            val_mses.append(val_mse)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch:03d} | LR {optimizer.param_groups[0]['lr']:.6f} | \"\n",
    "                      f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
    "                      f\"Val MAE {val_mae:.4f} | Val ADE {val_mae:.4f} | \"\n",
    "                      f\"Time {epoch_time:.2f}s\")\n",
    "            \n",
    "            # Check for improvement\n",
    "            if val_loss < best_val_loss - 1e-3:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement = 0\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "                if no_improvement >= early_stopping_patience:\n",
    "                    if verbose:\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "        \n",
    "        # Record results for this parameter set\n",
    "        avg_epoch_time = sum(epoch_times) / len(epoch_times)\n",
    "        best_epoch = val_losses.index(min(val_losses))\n",
    "        \n",
    "        param_results = {\n",
    "            **params,\n",
    "            'best_val_loss': min(val_losses),\n",
    "            'best_val_mae': val_maes[best_epoch],\n",
    "            'best_val_mse': val_mses[best_epoch],\n",
    "            'best_epoch': best_epoch,\n",
    "            'epoch_time_seconds': avg_epoch_time,\n",
    "            'total_epochs': len(train_losses)\n",
    "        }\n",
    "        \n",
    "        results.append(param_results)\n",
    "        \n",
    "        # Create and save training curve plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_losses, label='Train Loss')\n",
    "        plt.plot(val_losses, label='Val Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.title('Training Curves')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(val_maes, label='MAE (meters)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.title('Validation MAE')\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        lr_values = [optimizer.param_groups[0]['lr'] * (params['gamma'] ** (i // params['step_size'])) \n",
    "                     for i in range(len(train_losses))]\n",
    "        plt.plot(lr_values)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.title('Learning Rate Schedule')\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.bar(['Learning Rate', 'Weight Decay', 'Step Size', 'Gamma'], \n",
    "                [params['learning_rate'], params['weight_decay'], params['step_size'], params['gamma']])\n",
    "        plt.title('Hyperparameters')\n",
    "        plt.yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{results_dir}/params_{param_idx+1}_plot.png\")\n",
    "        plt.close()\n",
    "        \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Sort by validation MAE\n",
    "    results_df = results_df.sort_values('best_val_mae')\n",
    "    \n",
    "    # Save results\n",
    "    results_df.to_csv(f\"{results_dir}/hyperparameter_search_results.csv\", index=False)\n",
    "    \n",
    "    # Get best parameters\n",
    "    best_params = results_df.iloc[0].to_dict()\n",
    "    \n",
    "    # Plot comparative results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    param_labels = [f\"lr={p['learning_rate']:.0e}, wd={p['weight_decay']:.0e}, ss={p['step_size']}, γ={p['gamma']}\" \n",
    "                   for _, p in results_df.iloc[:10].iterrows()]\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.barh(param_labels, results_df['best_val_mae'].iloc[:10])\n",
    "    plt.xlabel('MAE (meters)')\n",
    "    plt.title('Top 10 Parameter Sets by MAE')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.barh(param_labels, results_df['best_val_mse'].iloc[:10])\n",
    "    plt.xlabel('MSE (square meters)')\n",
    "    plt.title('MSE for Top 10 Parameter Sets')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.barh(param_labels, results_df['epoch_time_seconds'].iloc[:10])\n",
    "    plt.xlabel('Average Epoch Time (seconds)')\n",
    "    plt.title('Training Time for Top 10 Parameter Sets')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.barh(param_labels, results_df['best_epoch'].iloc[:10])\n",
    "    plt.xlabel('Best Epoch')\n",
    "    plt.title('Convergence Speed for Top 10 Parameter Sets')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{results_dir}/comparative_results.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nHyperparameter search complete!\")\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "    \n",
    "    return results_df, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541c2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hyperparameter_effects(results_df: pd.DataFrame, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Visualize the effects of different hyperparameters on model performance.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame of hyperparameter search results\n",
    "        save_path: Path to save the visualization\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # Effect of learning rate\n",
    "    plt.subplot(2, 2, 1)\n",
    "    lr_groups = results_df.groupby('learning_rate')['best_val_mae'].mean().reset_index()\n",
    "    plt.bar(lr_groups['learning_rate'].astype(str), lr_groups['best_val_mae'])\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Average MAE (meters)')\n",
    "    plt.title('Effect of Learning Rate on MAE')\n",
    "    \n",
    "    # Effect of weight decay\n",
    "    plt.subplot(2, 2, 2)\n",
    "    wd_groups = results_df.groupby('weight_decay')['best_val_mae'].mean().reset_index()\n",
    "    plt.bar(wd_groups['weight_decay'].astype(str), wd_groups['best_val_mae'])\n",
    "    plt.xlabel('Weight Decay')\n",
    "    plt.ylabel('Average MAE (meters)')\n",
    "    plt.title('Effect of Weight Decay on MAE')\n",
    "    \n",
    "    # Effect of step size\n",
    "    plt.subplot(2, 2, 3)\n",
    "    ss_groups = results_df.groupby('step_size')['best_val_mae'].mean().reset_index()\n",
    "    plt.bar(ss_groups['step_size'].astype(str), ss_groups['best_val_mae'])\n",
    "    plt.xlabel('Step Size')\n",
    "    plt.ylabel('Average MAE (meters)')\n",
    "    plt.title('Effect of Step Size on MAE')\n",
    "    \n",
    "    # Effect of gamma\n",
    "    plt.subplot(2, 2, 4)\n",
    "    gamma_groups = results_df.groupby('gamma')['best_val_mae'].mean().reset_index()\n",
    "    plt.bar(gamma_groups['gamma'].astype(str), gamma_groups['best_val_mae'])\n",
    "    plt.xlabel('Gamma')\n",
    "    plt.ylabel('Average MAE (meters)')\n",
    "    plt.title('Effect of Gamma on MAE')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d967ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_best_model_training(\n",
    "    train_data: np.ndarray,\n",
    "    model_class,\n",
    "    model_kwargs: Dict = {},\n",
    "    best_params: Dict = None,\n",
    "    batch_size: int = 32,\n",
    "    val_ratio: float = 0.1,\n",
    "    scale: float = 7.0,\n",
    "    max_epochs: int = 100,\n",
    "    early_stopping_patience: int = 10,\n",
    "    device: torch.device = None,\n",
    "    save_model_path: str = 'best_model.pt',\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a model with the best hyperparameters.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Training data\n",
    "        model_class: Model class to instantiate\n",
    "        model_kwargs: Additional model parameters\n",
    "        best_params: Best hyperparameters from search\n",
    "        batch_size: Batch size for training\n",
    "        val_ratio: Proportion of data to use for validation\n",
    "        scale: Scale factor for normalization\n",
    "        max_epochs: Maximum number of epochs to train\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "        device: Device to train on\n",
    "        save_model_path: Path to save the best model\n",
    "        verbose: Whether to print progress\n",
    "        \n",
    "    Returns:\n",
    "        trained_model: Trained model\n",
    "        history: Training history\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device('mps')\n",
    "            print(\"Using Apple Silicon GPU\")\n",
    "        elif torch.cuda.is_available():\n",
    "            device = torch.device('cuda')\n",
    "            print(\"Using CUDA GPU\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "            print(\"Using CPU\")\n",
    "    \n",
    "    if best_params is None:\n",
    "        best_params = {\n",
    "            'learning_rate': 1e-3,\n",
    "            'weight_decay': 1e-4,\n",
    "            'step_size': 20,\n",
    "            'gamma': 0.25\n",
    "        }\n",
    "    \n",
    "    # Prepare the data\n",
    "    N = len(train_data)\n",
    "    val_size = int(val_ratio * N)\n",
    "    train_size = N - val_size\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TrajectoryDatasetTrain(train_data[:train_size], scale=scale, augment=True)\n",
    "    val_dataset = TrajectoryDatasetTrain(train_data[train_size:], scale=scale, augment=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=lambda x: Batch.from_data_list(x)\n",
    "    )\n",
    "    \n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=lambda x: Batch.from_data_list(x)\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = model_class(**model_kwargs).to(device)\n",
    "    \n",
    "    # Setup optimizer and scheduler\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=best_params['step_size'],\n",
    "        gamma=best_params['gamma']\n",
    "    )\n",
    "    \n",
    "    # Track best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Track metrics\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_mae': [],\n",
    "        'val_mse': [],\n",
    "        'learning_rate': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    for epoch in tqdm(range(max_epochs), desc=\"Training with best parameters\"):\n",
    "        epoch_start = time.time()\n",
    "        \n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            loss = criterion(pred, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        val_mse = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                val_loss += criterion(pred, y).item()\n",
    "                \n",
    "                # Unnormalize for metric calculation\n",
    "                pred_unnorm = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                y_unnorm = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                \n",
    "                val_mae += nn.L1Loss()(pred_unnorm, y_unnorm).item()\n",
    "                val_mse += nn.MSELoss()(pred_unnorm, y_unnorm).item()\n",
    "        \n",
    "        # Calculate average losses\n",
    "        train_loss /= len(train_dataloader)\n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_mae /= len(val_dataloader)\n",
    "        val_mse /= len(val_dataloader)\n",
    "        \n",
    "        # Step scheduler\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Track metrics\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_mae'].append(val_mae)\n",
    "        history['val_mse'].append(val_mse)\n",
    "        history['learning_rate'].append(current_lr)\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch:03d} | LR {current_lr:.6f} | \"\n",
    "                  f\"Train MSE {train_loss:.4f} | Val MSE {val_loss:.4f} | \"\n",
    "                  f\"Val MAE {val_mae:.4f} | Val MSE {val_mse:.4f} | \"\n",
    "                  f\"Time {epoch_time:.2f}s\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss - 1e-3:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), save_model_path)\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= early_stopping_patience:\n",
    "                if verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    if verbose:\n",
    "        print(f\"Training completed in {total_time:.2f} seconds\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    \n",
    "    # Create and save training curve plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.title('Training Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['val_mae'], label='MAE (meters)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Validation MAE')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['learning_rate'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history['val_mse'], label='MSE (square meters)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Validation MSE')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"best_model_training_curves.png\")\n",
    "    \n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e93ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim=6, hidden_dim=128, output_dim=60 * 2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        x= x.reshape(-1, 50, 50, 6)  # (batch_size, num_agents, seq_len, input_dim)\n",
    "        x = x[:, 0, :, :] # Only Consider ego agent index 0\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # lstm_out is of shape (batch_size, seq_len, hidden_dim) and we want the last time step output\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 2-3 hours to run on original notebook, so skipping running here\n",
    "# results loaded in markdown cell below as well as in the listed files \n",
    "# run hyperparameter search\n",
    "print(\"Starting hyperparameter search...\")\n",
    "results_df, best_params = hyperparameter_search(\n",
    "    train_data=train_data,\n",
    "    model_class=LSTM,\n",
    "    model_kwargs=model_kwargs,\n",
    "    search_params=search_params,\n",
    "    batch_size=32,\n",
    "    max_epochs=50,\n",
    "    results_dir='lstm_hyperparameter_search'\n",
    ")\n",
    "\n",
    "# visualize hyperparameter effects\n",
    "print(\"Visualizing hyperparameter effects...\")\n",
    "visualize_hyperparameter_effects(\n",
    "    results_df=results_df,\n",
    "    save_path='lstm_hyperparameter_effects.png'\n",
    ")\n",
    "\n",
    "# train best model\n",
    "print(\"Training final model with best hyperparameters...\")\n",
    "best_model, history = run_best_model_training(\n",
    "    train_data=train_data,\n",
    "    model_class=LSTM,\n",
    "    model_kwargs=model_kwargs,\n",
    "    best_params=best_params,\n",
    "    max_epochs=100,\n",
    "    save_model_path='lstm_best_model.pt'\n",
    ")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2bb87",
   "metadata": {},
   "source": [
    "Best parameters: {'gamma': 0.5, 'learning_rate': 0.005, 'step_size': 10.0, 'weight_decay': 0.0, 'best_val_loss': 0.1667313063517213, 'best_val_mae': 1.339437248185277, 'best_val_mse': 8.169826827943325, 'best_epoch': 37.0, 'epoch_time_seconds': 4.156487265298533, 'total_epochs': 43.0}\n",
    "\n",
    "Although, best parameters are not the same as those that yield on average the lowest MAE - just something to keep in mind.\n",
    "\n",
    "All additional output files are found in `/question_2_files` directory.\n",
    "- Hyperparameter effects on MAE loaded in `lystm_hyperparameter_effects.png`\n",
    "- Model with the best parameters loaded in `lstm_best_model.pt`\n",
    "- Training curves for model with best parameters loaded in `best_model_training_curves.png`\n",
    "- Output of each hyperparameter combination loaded in `hyperparameter_search_results.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1c09e",
   "metadata": {},
   "source": [
    "### Problem 2B - Deciding which model we should use to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe58379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim=50 * 50 * 2, output_dim=60 * 2):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x[..., :2] # (batch*50, 50, 2)\n",
    "        x = x.reshape(-1, 50 * 50 * 2) # (batch, 5000)\n",
    "        x = self.linear(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f523aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_adam(model, optimizer, scheduler):\n",
    "    early_stopping_patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in tqdm.tqdm(range(50), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = model(batch)\n",
    "            y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "            loss = criterion(pred, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_mae = 0\n",
    "        val_mse = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                batch = batch.to(device)\n",
    "                pred = model(batch)\n",
    "                y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "                val_loss += criterion(pred, y).item()\n",
    "\n",
    "                # show MAE and MSE with unnormalized data\n",
    "                pred = pred * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                y = y * batch.scale.view(-1, 1, 1) + batch.origin.unsqueeze(1)\n",
    "                val_mae += nn.L1Loss()(pred, y).item()\n",
    "                val_mse += nn.MSELoss()(pred, y).item()\n",
    "        \n",
    "        train_loss /= len(train_dataloader)\n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_mae /= len(val_dataloader)\n",
    "        val_mse /= len(val_dataloader)\n",
    "        scheduler.step()\n",
    "        # scheduler.step(val_loss)\n",
    "        \n",
    "        tqdm.tqdm.write(f\"Epoch {epoch:03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "        if val_loss < best_val_loss - 1e-3:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "            if no_improvement >= early_stopping_patience:\n",
    "                print(\"Early stop!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fb0aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?epoch/s]/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:59: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future @ R\n",
      "/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:68: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future - origin\n",
      "Epoch:   2%|▏         | 1/50 [00:03<03:13,  3.95s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Learning rate 0.005000 | train normalized MSE 872151.6035 | val normalized MSE 501180.2974, | val MAE 2790.7326 | val MSE 24557834.4062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:06<02:42,  3.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.005000 | train normalized MSE 532459.7002 | val normalized MSE 622617.3989, | val MAE 3102.9715 | val MSE 30508252.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:10<02:33,  3.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.005000 | train normalized MSE 517074.2379 | val normalized MSE 575209.7065, | val MAE 2973.5589 | val MSE 28185276.2812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:13<02:28,  3.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.005000 | train normalized MSE 502019.5635 | val normalized MSE 575427.1555, | val MAE 2939.7223 | val MSE 28195930.3906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:16<02:21,  3.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.005000 | train normalized MSE 561039.4572 | val normalized MSE 249077.3333, | val MAE 2101.9020 | val MSE 12204788.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:19<02:20,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.005000 | train normalized MSE 462470.3681 | val normalized MSE 557208.3867, | val MAE 2997.2091 | val MSE 27303211.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:22<02:20,  3.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.005000 | train normalized MSE 457640.1743 | val normalized MSE 547150.2930, | val MAE 3296.1719 | val MSE 26810364.1562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:26<02:15,  3.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.005000 | train normalized MSE 539183.4640 | val normalized MSE 588926.9092, | val MAE 3142.2813 | val MSE 28857418.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:29<02:09,  3.15s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.005000 | train normalized MSE 607500.1388 | val normalized MSE 965869.8281, | val MAE 3855.4744 | val MSE 47327622.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [00:32<02:07,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.002500 | train normalized MSE 519629.8412 | val normalized MSE 439051.5698, | val MAE 2530.0212 | val MSE 21513526.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [00:35<02:05,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.002500 | train normalized MSE 188078.8295 | val normalized MSE 76766.2495, | val MAE 1224.3653 | val MSE 3761546.2539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:38<02:02,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.002500 | train normalized MSE 137313.9342 | val normalized MSE 124978.3351, | val MAE 1487.6870 | val MSE 6123938.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [00:41<01:58,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.002500 | train normalized MSE 137252.6397 | val normalized MSE 167827.0641, | val MAE 1675.4626 | val MSE 8223526.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [00:44<01:53,  3.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.002500 | train normalized MSE 162514.1235 | val normalized MSE 76100.1370, | val MAE 1196.5497 | val MSE 3728906.6797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [00:47<01:47,  3.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.002500 | train normalized MSE 122159.8023 | val normalized MSE 202453.8706, | val MAE 1789.6585 | val MSE 9920239.6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [00:51<01:44,  3.09s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.002500 | train normalized MSE 142035.3397 | val normalized MSE 163516.7207, | val MAE 1697.2523 | val MSE 8012319.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [00:54<01:45,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.002500 | train normalized MSE 131829.7372 | val normalized MSE 118021.9673, | val MAE 1536.0177 | val MSE 5783076.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [00:57<01:40,  3.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.002500 | train normalized MSE 116732.8641 | val normalized MSE 85660.5085, | val MAE 1225.2630 | val MSE 4197364.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [01:00<01:37,  3.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.002500 | train normalized MSE 148908.7279 | val normalized MSE 94117.8333, | val MAE 1230.1388 | val MSE 4611773.8008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [01:03<01:36,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.001250 | train normalized MSE 119562.3462 | val normalized MSE 135442.8687, | val MAE 1399.0751 | val MSE 6636700.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [01:07<01:39,  3.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.001250 | train normalized MSE 50436.6120 | val normalized MSE 38982.1766, | val MAE 836.1175 | val MSE 1910126.6816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [01:11<01:36,  3.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.001250 | train normalized MSE 41441.9490 | val normalized MSE 35504.0084, | val MAE 796.5497 | val MSE 1739696.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [01:15<01:35,  3.55s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.001250 | train normalized MSE 45805.1977 | val normalized MSE 24635.2404, | val MAE 638.8877 | val MSE 1207126.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [01:18<01:31,  3.52s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.001250 | train normalized MSE 38877.5559 | val normalized MSE 28059.5773, | val MAE 747.3991 | val MSE 1374919.2754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [01:21<01:25,  3.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.001250 | train normalized MSE 39208.0954 | val normalized MSE 22332.5503, | val MAE 632.6210 | val MSE 1094294.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [01:25<01:20,  3.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.001250 | train normalized MSE 34656.3980 | val normalized MSE 22063.7740, | val MAE 625.7281 | val MSE 1081124.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [01:28<01:16,  3.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Learning rate 0.001250 | train normalized MSE 33645.0434 | val normalized MSE 23884.0143, | val MAE 678.7630 | val MSE 1170316.6982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [01:31<01:12,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Learning rate 0.001250 | train normalized MSE 34777.1785 | val normalized MSE 31092.6352, | val MAE 680.0121 | val MSE 1523539.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [01:34<01:07,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Learning rate 0.001250 | train normalized MSE 34068.2223 | val normalized MSE 40983.5138, | val MAE 817.9870 | val MSE 2008192.1270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [01:37<01:03,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Learning rate 0.000625 | train normalized MSE 36343.2863 | val normalized MSE 20107.1384, | val MAE 563.6772 | val MSE 985249.7705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [01:40<01:00,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.000625 | train normalized MSE 13896.3272 | val normalized MSE 9058.9697, | val MAE 415.9834 | val MSE 443889.5195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [01:44<00:58,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Learning rate 0.000625 | train normalized MSE 11696.5372 | val normalized MSE 7548.7192, | val MAE 377.3616 | val MSE 369887.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 33/50 [01:47<00:55,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Learning rate 0.000625 | train normalized MSE 10401.7839 | val normalized MSE 6986.4814, | val MAE 374.2352 | val MSE 342337.5972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 34/50 [01:50<00:52,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Learning rate 0.000625 | train normalized MSE 9748.5807 | val normalized MSE 7135.6912, | val MAE 374.8431 | val MSE 349648.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [01:54<00:48,  3.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Learning rate 0.000625 | train normalized MSE 10018.7164 | val normalized MSE 7614.3450, | val MAE 377.1314 | val MSE 373102.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▏  | 36/50 [01:57<00:44,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.000625 | train normalized MSE 9854.8931 | val normalized MSE 6657.9258, | val MAE 340.3397 | val MSE 326238.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  74%|███████▍  | 37/50 [02:00<00:41,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | Learning rate 0.000625 | train normalized MSE 10057.6122 | val normalized MSE 11223.2444, | val MAE 426.8594 | val MSE 549938.9717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  76%|███████▌  | 38/50 [02:03<00:38,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | Learning rate 0.000625 | train normalized MSE 10143.7375 | val normalized MSE 7020.6107, | val MAE 367.5894 | val MSE 344009.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  78%|███████▊  | 39/50 [02:06<00:36,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | Learning rate 0.000625 | train normalized MSE 9529.0222 | val normalized MSE 8292.1713, | val MAE 384.4319 | val MSE 406316.3921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 40/50 [02:10<00:32,  3.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | Learning rate 0.000313 | train normalized MSE 9429.1726 | val normalized MSE 8069.0980, | val MAE 362.6443 | val MSE 395385.8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  82%|████████▏ | 41/50 [02:13<00:29,  3.30s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.000313 | train normalized MSE 3854.8445 | val normalized MSE 5128.6185, | val MAE 303.4684 | val MSE 251302.3052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  84%|████████▍ | 42/50 [02:16<00:26,  3.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | Learning rate 0.000313 | train normalized MSE 3319.7639 | val normalized MSE 4059.6756, | val MAE 268.1120 | val MSE 198924.1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  86%|████████▌ | 43/50 [02:19<00:22,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | Learning rate 0.000313 | train normalized MSE 3105.0771 | val normalized MSE 3507.5700, | val MAE 257.4080 | val MSE 171870.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 44/50 [02:23<00:19,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | Learning rate 0.000313 | train normalized MSE 3170.6070 | val normalized MSE 4885.9118, | val MAE 286.0231 | val MSE 239409.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 45/50 [02:26<00:16,  3.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 | Learning rate 0.000313 | train normalized MSE 3181.9204 | val normalized MSE 3477.9235, | val MAE 244.4828 | val MSE 170418.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▏| 46/50 [02:30<00:14,  3.58s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.000313 | train normalized MSE 3045.8693 | val normalized MSE 2344.8812, | val MAE 211.6103 | val MSE 114899.1775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  94%|█████████▍| 47/50 [02:33<00:10,  3.49s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | Learning rate 0.000313 | train normalized MSE 2870.1511 | val normalized MSE 2104.6113, | val MAE 202.4587 | val MSE 103125.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 48/50 [02:37<00:06,  3.44s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 047 | Learning rate 0.000313 | train normalized MSE 2858.6133 | val normalized MSE 2563.6937, | val MAE 212.3176 | val MSE 125620.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  98%|█████████▊| 49/50 [02:40<00:03,  3.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 | Learning rate 0.000313 | train normalized MSE 2867.8652 | val normalized MSE 3634.4509, | val MAE 255.3746 | val MSE 178088.0935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 50/50 [02:43<00:00,  3.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 | Learning rate 0.000156 | train normalized MSE 3248.1229 | val normalized MSE 2880.5482, | val MAE 221.3872 | val MSE 141146.8619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# running the linear regression model\n",
    "model = LinearRegressionModel().to(device)\n",
    "\n",
    "# setting Adam with the parameters from Part A (first ran with best parameters that the lstm model used)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) # You can try different schedulers\n",
    "\n",
    "run_model_with_adam(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0c42288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?epoch/s]/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:68: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future - origin\n",
      "/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:59: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future @ R\n",
      "Epoch:   2%|▏         | 1/50 [00:04<03:28,  4.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Learning rate 0.001000 | train normalized MSE 35850.8932 | val normalized MSE 14766.7557, | val MAE 542.5683 | val MSE 723571.0146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:07<02:52,  3.59s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.001000 | train normalized MSE 21370.5092 | val normalized MSE 20659.2856, | val MAE 602.1485 | val MSE 1012304.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:10<02:43,  3.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.001000 | train normalized MSE 20602.2097 | val normalized MSE 18463.4015, | val MAE 576.6624 | val MSE 904706.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:13<02:33,  3.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.001000 | train normalized MSE 23057.2355 | val normalized MSE 15343.6091, | val MAE 535.4515 | val MSE 751836.8350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:17<02:31,  3.36s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.001000 | train normalized MSE 20582.0501 | val normalized MSE 40170.4522, | val MAE 814.7236 | val MSE 1968352.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:20<02:29,  3.40s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.001000 | train normalized MSE 21676.8813 | val normalized MSE 13969.9550, | val MAE 490.3682 | val MSE 684527.7896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:24<02:25,  3.37s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.001000 | train normalized MSE 18527.8854 | val normalized MSE 10985.6292, | val MAE 472.6377 | val MSE 538295.8301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:27<02:21,  3.38s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.001000 | train normalized MSE 18959.2283 | val normalized MSE 14030.9455, | val MAE 525.7732 | val MSE 687516.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:30<02:16,  3.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.001000 | train normalized MSE 20987.2147 | val normalized MSE 18737.5311, | val MAE 575.4323 | val MSE 918139.0117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [00:33<02:11,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.000100 | train normalized MSE 22669.8741 | val normalized MSE 15571.9845, | val MAE 543.1097 | val MSE 763027.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [00:37<02:07,  3.27s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.000100 | train normalized MSE 3375.3879 | val normalized MSE 1456.0560, | val MAE 168.6393 | val MSE 71346.7430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:40<02:02,  3.22s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.000100 | train normalized MSE 1454.6642 | val normalized MSE 1186.9200, | val MAE 153.2105 | val MSE 58159.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [00:43<01:58,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.000100 | train normalized MSE 1122.1071 | val normalized MSE 1065.6548, | val MAE 145.5477 | val MSE 52217.0867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [00:46<01:56,  3.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.000100 | train normalized MSE 944.0622 | val normalized MSE 941.3627, | val MAE 132.5787 | val MSE 46126.7709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [00:50<01:54,  3.28s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.000100 | train normalized MSE 870.6615 | val normalized MSE 703.6312, | val MAE 120.9610 | val MSE 34477.9291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [00:53<01:49,  3.21s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.000100 | train normalized MSE 810.6898 | val normalized MSE 748.7241, | val MAE 121.5505 | val MSE 36687.4775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [00:56<01:45,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.000100 | train normalized MSE 732.6024 | val normalized MSE 862.7189, | val MAE 127.9765 | val MSE 42273.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [00:59<01:42,  3.20s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.000100 | train normalized MSE 685.4968 | val normalized MSE 816.2894, | val MAE 127.2521 | val MSE 39998.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [01:02<01:38,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.000100 | train normalized MSE 674.5227 | val normalized MSE 663.7153, | val MAE 116.2323 | val MSE 32522.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [01:05<01:34,  3.14s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.000010 | train normalized MSE 603.5712 | val normalized MSE 598.4256, | val MAE 108.8588 | val MSE 29322.8545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [01:08<01:31,  3.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.000010 | train normalized MSE 295.1442 | val normalized MSE 329.2002, | val MAE  81.6187 | val MSE 16130.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [01:12<01:28,  3.17s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.000010 | train normalized MSE 261.4215 | val normalized MSE 313.3359, | val MAE  79.7893 | val MSE 15353.4601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [01:15<01:24,  3.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.000010 | train normalized MSE 250.5910 | val normalized MSE 301.1397, | val MAE  78.3871 | val MSE 14755.8463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [01:18<01:20,  3.11s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.000010 | train normalized MSE 245.4379 | val normalized MSE 304.3890, | val MAE  78.4885 | val MSE 14915.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [01:21<01:18,  3.13s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.000010 | train normalized MSE 242.6634 | val normalized MSE 299.0688, | val MAE  77.9024 | val MSE 14654.3714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [01:24<01:16,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.000010 | train normalized MSE 237.8389 | val normalized MSE 296.1446, | val MAE  77.5531 | val MSE 14511.0843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [01:27<01:13,  3.18s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Learning rate 0.000010 | train normalized MSE 232.4395 | val normalized MSE 292.9917, | val MAE  77.2295 | val MSE 14356.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [01:30<01:09,  3.16s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Learning rate 0.000010 | train normalized MSE 229.6555 | val normalized MSE 289.6255, | val MAE  76.5121 | val MSE 14191.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [01:34<01:07,  3.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Learning rate 0.000010 | train normalized MSE 224.9906 | val normalized MSE 286.2961, | val MAE  76.2398 | val MSE 14028.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [01:37<01:03,  3.19s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Learning rate 0.000001 | train normalized MSE 223.5594 | val normalized MSE 281.2234, | val MAE  75.6290 | val MSE 13779.9454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [01:40<01:01,  3.26s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.000001 | train normalized MSE 197.3624 | val normalized MSE 262.3515, | val MAE  72.8018 | val MSE 12855.2251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [01:44<00:59,  3.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Learning rate 0.000001 | train normalized MSE 195.7196 | val normalized MSE 262.0870, | val MAE  72.7927 | val MSE 12842.2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 33/50 [01:47<00:56,  3.31s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Learning rate 0.000001 | train normalized MSE 195.4183 | val normalized MSE 262.3057, | val MAE  72.8233 | val MSE 12852.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 34/50 [01:50<00:53,  3.35s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Learning rate 0.000001 | train normalized MSE 193.7820 | val normalized MSE 260.9999, | val MAE  72.5722 | val MSE 12788.9937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [01:54<00:50,  3.33s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Learning rate 0.000001 | train normalized MSE 193.1072 | val normalized MSE 259.5596, | val MAE  72.3888 | val MSE 12718.4204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▏  | 36/50 [01:57<00:47,  3.40s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.000001 | train normalized MSE 191.9142 | val normalized MSE 260.3583, | val MAE  72.4869 | val MSE 12757.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  74%|███████▍  | 37/50 [02:01<00:44,  3.42s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | Learning rate 0.000001 | train normalized MSE 192.3538 | val normalized MSE 260.7412, | val MAE  72.5676 | val MSE 12776.3173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  76%|███████▌  | 38/50 [02:05<00:42,  3.54s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | Learning rate 0.000001 | train normalized MSE 191.0124 | val normalized MSE 259.3031, | val MAE  72.3495 | val MSE 12705.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  78%|███████▊  | 39/50 [02:08<00:38,  3.47s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | Learning rate 0.000001 | train normalized MSE 192.3569 | val normalized MSE 258.4489, | val MAE  72.2204 | val MSE 12663.9972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 40/50 [02:12<00:35,  3.51s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | Learning rate 0.000000 | train normalized MSE 191.7657 | val normalized MSE 258.1814, | val MAE  72.1948 | val MSE 12650.8881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  82%|████████▏ | 41/50 [02:15<00:32,  3.60s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.000000 | train normalized MSE 188.3147 | val normalized MSE 256.8890, | val MAE  71.9873 | val MSE 12587.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  84%|████████▍ | 42/50 [02:19<00:29,  3.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | Learning rate 0.000000 | train normalized MSE 187.6753 | val normalized MSE 256.6727, | val MAE  71.9600 | val MSE 12576.9623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  86%|████████▌ | 43/50 [02:23<00:25,  3.62s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | Learning rate 0.000000 | train normalized MSE 188.1057 | val normalized MSE 256.8076, | val MAE  71.9731 | val MSE 12583.5714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 44/50 [02:26<00:21,  3.61s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | Learning rate 0.000000 | train normalized MSE 189.8385 | val normalized MSE 256.6513, | val MAE  71.9496 | val MSE 12575.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 45/50 [02:30<00:17,  3.53s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 | Learning rate 0.000000 | train normalized MSE 188.7798 | val normalized MSE 256.6549, | val MAE  71.9516 | val MSE 12576.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▏| 46/50 [02:33<00:13,  3.45s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.000000 | train normalized MSE 187.0722 | val normalized MSE 256.6041, | val MAE  71.9353 | val MSE 12573.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  94%|█████████▍| 47/50 [02:36<00:10,  3.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | Learning rate 0.000000 | train normalized MSE 188.3030 | val normalized MSE 256.4078, | val MAE  71.9259 | val MSE 12563.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 48/50 [02:39<00:06,  3.25s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 047 | Learning rate 0.000000 | train normalized MSE 186.9761 | val normalized MSE 256.5194, | val MAE  71.9262 | val MSE 12569.4511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  98%|█████████▊| 49/50 [02:42<00:03,  3.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 | Learning rate 0.000000 | train normalized MSE 187.8277 | val normalized MSE 256.3864, | val MAE  71.9148 | val MSE 12562.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 50/50 [02:46<00:00,  3.32s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 | Learning rate 0.000000 | train normalized MSE 187.7085 | val normalized MSE 256.4414, | val MAE  71.9114 | val MSE 12565.6286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# running the linear regression model\n",
    "model = LinearRegressionModel().to(device)\n",
    "\n",
    "# setting Adam with the parameters from Part A (first ran with best parameters, and now \n",
    "# running with the parameters that had best average performance as that \n",
    "# appears to produce lower MSE values for linear regression model )\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) # You can try different schedulers\n",
    "\n",
    "run_model_with_adam(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14506bd3",
   "metadata": {},
   "source": [
    "Linear regression got val MAE down to 71-72 range, probs could get even lower if we specifically did a grid search for best parameters using this linear regression model.\n",
    "\n",
    "Next, looking into the MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc97a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(256, output_features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = x.x\n",
    "        x = x.reshape(-1, 50 * 50 * 6)\n",
    "        x = self.mlp(x)\n",
    "        return x.view(-1, 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the MLP model \n",
    "input_features = 50 * 50 * 6\n",
    "output_features = 60 * 2\n",
    "\n",
    "model = MLP(input_features, output_features).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a23ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]:   0%|          | 0/40 [00:00<?, ?it/s]/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/2808079002.py:71: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future - origin\n",
      "/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/2808079002.py:62: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future @ R\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Learning rate 0.001000 | train normalized MSE  91.6027 | val normalized MSE   3.0853, | val MAE   9.9695 | val MSE 308.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.001000 | train normalized MSE   3.4383 | val normalized MSE   3.0852, | val MAE   9.9679 | val MSE 308.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.001000 | train normalized MSE   3.2484 | val normalized MSE   3.0851, | val MAE   9.9656 | val MSE 308.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.001000 | train normalized MSE   3.0981 | val normalized MSE   3.0850, | val MAE   9.9633 | val MSE 308.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.001000 | train normalized MSE   3.0947 | val normalized MSE   3.0850, | val MAE   9.9609 | val MSE 308.4961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.001000 | train normalized MSE   3.0969 | val normalized MSE   3.0850, | val MAE   9.9586 | val MSE 308.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.001000 | train normalized MSE   3.0949 | val normalized MSE   3.0849, | val MAE   9.9559 | val MSE 308.4891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.001000 | train normalized MSE   3.1011 | val normalized MSE   3.0849, | val MAE   9.9537 | val MSE 308.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.001000 | train normalized MSE   3.0954 | val normalized MSE   3.0848, | val MAE   9.9516 | val MSE 308.4834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.001000 | train normalized MSE   3.1026 | val normalized MSE   3.0847, | val MAE   9.9493 | val MSE 308.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.001000 | train normalized MSE   3.0946 | val normalized MSE   3.0847, | val MAE   9.9464 | val MSE 308.4654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.000500 | train normalized MSE   3.0946 | val normalized MSE   3.0846, | val MAE   9.9452 | val MSE 308.4599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.000500 | train normalized MSE   4.7135 | val normalized MSE   3.0846, | val MAE   9.9435 | val MSE 308.4570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.000500 | train normalized MSE   3.1205 | val normalized MSE   3.0846, | val MAE   9.9436 | val MSE 308.4577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.000500 | train normalized MSE   3.0959 | val normalized MSE   3.0845, | val MAE   9.9430 | val MSE 308.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.000500 | train normalized MSE   3.2840 | val normalized MSE   3.0845, | val MAE   9.9417 | val MSE 308.4490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.000500 | train normalized MSE   3.1483 | val normalized MSE   3.0845, | val MAE   9.9417 | val MSE 308.4473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.000500 | train normalized MSE   3.0977 | val normalized MSE   3.0844, | val MAE   9.9400 | val MSE 308.4376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.000250 | train normalized MSE   3.0956 | val normalized MSE   3.0843, | val MAE   9.9390 | val MSE 308.4347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.000250 | train normalized MSE   3.0965 | val normalized MSE   3.0843, | val MAE   9.9382 | val MSE 308.4328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.000250 | train normalized MSE   3.0940 | val normalized MSE   3.0843, | val MAE   9.9381 | val MSE 308.4315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.000250 | train normalized MSE   3.0978 | val normalized MSE   3.0843, | val MAE   9.9383 | val MSE 308.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.000250 | train normalized MSE   3.0953 | val normalized MSE   3.0843, | val MAE   9.9365 | val MSE 308.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.000250 | train normalized MSE   3.0944 | val normalized MSE   3.0843, | val MAE   9.9353 | val MSE 308.4288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.000250 | train normalized MSE   3.0934 | val normalized MSE   3.0843, | val MAE   9.9356 | val MSE 308.4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.000250 | train normalized MSE   3.0988 | val normalized MSE   3.0843, | val MAE   9.9355 | val MSE 308.4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Learning rate 0.000250 | train normalized MSE   3.0947 | val normalized MSE   3.0843, | val MAE   9.9344 | val MSE 308.4321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Learning rate 0.000250 | train normalized MSE   3.0945 | val normalized MSE   3.0843, | val MAE   9.9338 | val MSE 308.4290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Learning rate 0.000250 | train normalized MSE   3.0943 | val normalized MSE   3.0843, | val MAE   9.9330 | val MSE 308.4277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Learning rate 0.000250 | train normalized MSE   3.0934 | val normalized MSE   3.0843, | val MAE   9.9329 | val MSE 308.4303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.000125 | train normalized MSE   3.0938 | val normalized MSE   3.0843, | val MAE   9.9330 | val MSE 308.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Learning rate 0.000125 | train normalized MSE   3.0945 | val normalized MSE   3.0843, | val MAE   9.9324 | val MSE 308.4283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Learning rate 0.000125 | train normalized MSE   3.0955 | val normalized MSE   3.0843, | val MAE   9.9321 | val MSE 308.4271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Learning rate 0.000125 | train normalized MSE   3.1594 | val normalized MSE   3.0843, | val MAE   9.9318 | val MSE 308.4253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Learning rate 0.000125 | train normalized MSE   3.0946 | val normalized MSE   3.0842, | val MAE   9.9310 | val MSE 308.4228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.000125 | train normalized MSE   3.0943 | val normalized MSE   3.0842, | val MAE   9.9301 | val MSE 308.4192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | Learning rate 0.000063 | train normalized MSE   3.0937 | val normalized MSE   3.0842, | val MAE   9.9302 | val MSE 308.4192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | Learning rate 0.000063 | train normalized MSE   3.0932 | val normalized MSE   3.0842, | val MAE   9.9302 | val MSE 308.4189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | Learning rate 0.000063 | train normalized MSE   3.0941 | val normalized MSE   3.0842, | val MAE   9.9302 | val MSE 308.4184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | Learning rate 0.000063 | train normalized MSE   3.0939 | val normalized MSE   3.0842, | val MAE   9.9300 | val MSE 308.4176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.000063 | train normalized MSE   3.0943 | val normalized MSE   3.0842, | val MAE   9.9298 | val MSE 308.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | Learning rate 0.000063 | train normalized MSE   3.0934 | val normalized MSE   3.0842, | val MAE   9.9295 | val MSE 308.4167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | Learning rate 0.000031 | train normalized MSE   3.1020 | val normalized MSE   3.0842, | val MAE   9.9291 | val MSE 308.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | Learning rate 0.000031 | train normalized MSE   3.0938 | val normalized MSE   3.0842, | val MAE   9.9291 | val MSE 308.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 | Learning rate 0.000031 | train normalized MSE   3.0998 | val normalized MSE   3.0841, | val MAE   9.9290 | val MSE 308.4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.000031 | train normalized MSE   3.0941 | val normalized MSE   3.0841, | val MAE   9.9289 | val MSE 308.4142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | Learning rate 0.000031 | train normalized MSE   3.0942 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 047 | Learning rate 0.000031 | train normalized MSE   3.0942 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 | Learning rate 0.000016 | train normalized MSE   3.0933 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 | Learning rate 0.000016 | train normalized MSE   3.0930 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 050 | Learning rate 0.000016 | train normalized MSE   3.0943 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 051 | Learning rate 0.000016 | train normalized MSE   3.0932 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 052 | Learning rate 0.000016 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 053 | Learning rate 0.000016 | train normalized MSE   3.0936 | val normalized MSE   3.0841, | val MAE   9.9287 | val MSE 308.4129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 054 | Learning rate 0.000008 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9287 | val MSE 308.4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 055 | Learning rate 0.000008 | train normalized MSE   3.0942 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 056 | Learning rate 0.000008 | train normalized MSE   3.0940 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 057 | Learning rate 0.000008 | train normalized MSE   3.1033 | val normalized MSE   3.0841, | val MAE   9.9286 | val MSE 308.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 058 | Learning rate 0.000008 | train normalized MSE   3.0937 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 059 | Learning rate 0.000008 | train normalized MSE   3.1008 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 060 | Learning rate 0.000004 | train normalized MSE   3.1555 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 061 | Learning rate 0.000004 | train normalized MSE   3.0941 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 062 | Learning rate 0.000004 | train normalized MSE   3.0943 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 063 | Learning rate 0.000004 | train normalized MSE   3.0936 | val normalized MSE   3.0841, | val MAE   9.9285 | val MSE 308.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 064 | Learning rate 0.000004 | train normalized MSE   3.0943 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 065 | Learning rate 0.000004 | train normalized MSE   3.0940 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 066 | Learning rate 0.000002 | train normalized MSE   3.0936 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 067 | Learning rate 0.000002 | train normalized MSE   3.1200 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 068 | Learning rate 0.000002 | train normalized MSE   3.0936 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 069 | Learning rate 0.000002 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 070 | Learning rate 0.000002 | train normalized MSE   3.0948 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 071 | Learning rate 0.000002 | train normalized MSE   3.0940 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 072 | Learning rate 0.000001 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 073 | Learning rate 0.000001 | train normalized MSE   3.0938 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 074 | Learning rate 0.000001 | train normalized MSE   3.0941 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 075 | Learning rate 0.000001 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 076 | Learning rate 0.000001 | train normalized MSE   3.0936 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 077 | Learning rate 0.000001 | train normalized MSE   3.1237 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 078 | Learning rate 0.000000 | train normalized MSE   3.0937 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 079 | Learning rate 0.000000 | train normalized MSE   3.0939 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 080 | Learning rate 0.000000 | train normalized MSE   3.0938 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 081 | Learning rate 0.000000 | train normalized MSE   3.2711 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 082 | Learning rate 0.000000 | train normalized MSE   3.0945 | val normalized MSE   3.0841, | val MAE   9.9284 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 083 | Learning rate 0.000000 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 084 | Learning rate 0.000000 | train normalized MSE   3.0935 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 085 | Learning rate 0.000000 | train normalized MSE   3.0939 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 086 | Learning rate 0.000000 | train normalized MSE   3.0934 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 087 | Learning rate 0.000000 | train normalized MSE   3.0947 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 088 | Learning rate 0.000000 | train normalized MSE   3.0941 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 089 | Learning rate 0.000000 | train normalized MSE   3.0935 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 090 | Learning rate 0.000000 | train normalized MSE   3.0940 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 091 | Learning rate 0.000000 | train normalized MSE   3.0938 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 092 | Learning rate 0.000000 | train normalized MSE   3.0942 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 093 | Learning rate 0.000000 | train normalized MSE   3.1125 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 094 | Learning rate 0.000000 | train normalized MSE   3.0935 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 095 | Learning rate 0.000000 | train normalized MSE   3.0943 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 096 | Learning rate 0.000000 | train normalized MSE   3.0938 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 097 | Learning rate 0.000000 | train normalized MSE   3.0935 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 098 | Learning rate 0.000000 | train normalized MSE   3.0942 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 099 | Learning rate 0.000000 | train normalized MSE   3.0943 | val normalized MSE   3.0841, | val MAE   9.9283 | val MSE 308.4124\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 66/66 [00:00<00:00, 139.42it/s]\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, device, num_epochs=100, early_stopping_patience=15):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    # for storing metrics\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_maes = []\n",
    "    val_mses = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Training loop ----------------\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False):\n",
    "            batch_x = None #[3200, 50, 6] --> input features, 3200 total sequences each length 50 with 6 features\n",
    "            batch_y = None #[3840, 2] --> target features associated with input data \n",
    "\n",
    "            if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                batch_x, batch_y = batch\n",
    "                batch_y = batch_y.view(-1, 60, 2)\n",
    "            else:\n",
    "                batch = batch.to(device)\n",
    "                batch_x = batch.x \n",
    "                batch_y = batch.y.view(batch.num_graphs, 60, 2) \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_x)\n",
    "            targets = batch.y.to(device)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            \n",
    "            # Backward pass \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch.num_graphs\n",
    "        \n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation ----------------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_mae = 0.0\n",
    "        val_mse = 0.0\n",
    "        num_val_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm.tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False):\n",
    "                batch_x = None\n",
    "                batch_y = None\n",
    "                if isinstance(batch, tuple) or isinstance(batch, list):\n",
    "                    batch_x, batch_y = batch\n",
    "                    batch_y = batch_y.view(-1, 60, 2)\n",
    "                else:\n",
    "                    batch = batch.to(device)\n",
    "                    batch_x = batch.x\n",
    "                    batch_y = batch.y.view(batch.num_graphs, 60, 2)\n",
    "\n",
    "                batch_size = batch.num_graphs\n",
    "                num_val_samples += batch_size\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(batch_x)\n",
    "                targets = batch.y.to(device)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                val_loss += loss.item() * batch_size\n",
    "            \n",
    "                scale_factor = batch.scale.view(-1, 1, 1).to(device)\n",
    "                pred_unnormalized = outputs * scale_factor\n",
    "                targets_unnormalized = targets.view(outputs.shape) * scale_factor\n",
    "\n",
    "                mae = torch.abs(pred_unnormalized - targets_unnormalized).mean().item()\n",
    "                mse = ((pred_unnormalized - targets_unnormalized) ** 2).mean().item()\n",
    "                val_mae += mae * batch_size\n",
    "                val_mse += mse * batch_size\n",
    "        \n",
    "        # do metric stuff\n",
    "        val_loss /= num_val_samples\n",
    "        val_mae /= num_val_samples\n",
    "        val_mse /= num_val_samples\n",
    "        \n",
    "        val_losses.append(val_loss)\n",
    "        val_maes.append(val_mae)\n",
    "        val_mses.append(val_mse)\n",
    "        tqdm.tqdm.write(f\"Epoch {epoch:03d} | Learning rate {optimizer.param_groups[0]['lr']:.6f} | train normalized MSE {train_loss:8.4f} | val normalized MSE {val_loss:8.4f}, | val MAE {val_mae:8.4f} | val MSE {val_mse:8.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                tqdm.tqdm.write(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_maes, val_mses\n",
    "\n",
    "# Create and train the MLP model\n",
    "input_features = 50 * 50 * 6  # our data dimensions\n",
    "output_features = 60 * 2      # 60 timestamps and 2 coordinates (x, y)\n",
    "\n",
    "model = MLP(input_features, output_features)\n",
    "model, train_losses, val_losses, val_maes, val_mses = train_model(\n",
    "    model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    device,\n",
    "    num_epochs=100,\n",
    "    early_stopping_patience=15\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Normalized MSE')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(val_maes)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Validation MAE')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(val_mses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Validation MSE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'mlp_model.pth')\n",
    "\n",
    "# For testing on test data\n",
    "def test_model(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            batch = batch.to(device)\n",
    "            outputs = model(batch.x)\n",
    "            \n",
    "            # Unnormalize predictions\n",
    "            scale_factor = batch.scale.view(-1, 1, 1).to(device)\n",
    "            pred_unnormalized = outputs * scale_factor\n",
    "            origin = batch.origin.to(device)  \n",
    "            pred_unnormalized = pred_unnormalized + origin.view(-1, 1, 2)\n",
    "            \n",
    "            # Append to predictions list\n",
    "            predictions.append(pred_unnormalized.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.concatenate(predictions, axis=0)\n",
    "    return all_predictions\n",
    "\n",
    "# run tests now \n",
    "test_dataset = TrajectoryDatasetTest(test_data, scale=scale)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: Batch.from_data_list(x))\n",
    "\n",
    "test_predictions = test_model(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb5441",
   "metadata": {},
   "source": [
    "Can see that MLP has much lower val MAE than linear regression (in the 9.9-10 range)! \n",
    "\n",
    "Alas, now we test the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7add30ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?epoch/s]/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:68: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future - origin\n",
      "/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/1780213679.py:59: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future @ R\n",
      "Epoch:   2%|▏         | 1/50 [00:06<05:05,  6.23s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Learning rate 0.005000 | train normalized MSE   0.8825 | val normalized MSE   0.4166, | val MAE   2.4641 | val MSE  20.4139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:10<04:16,  5.34s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.005000 | train normalized MSE   0.3915 | val normalized MSE   0.3979, | val MAE   2.3917 | val MSE  19.4976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:15<03:52,  4.94s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.005000 | train normalized MSE   0.3497 | val normalized MSE   0.3200, | val MAE   2.1203 | val MSE  15.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:19<03:39,  4.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.005000 | train normalized MSE   0.3183 | val normalized MSE   0.2758, | val MAE   1.9326 | val MSE  13.5122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:24<03:32,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.005000 | train normalized MSE   0.2971 | val normalized MSE   0.2718, | val MAE   1.8995 | val MSE  13.3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:29<03:27,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.005000 | train normalized MSE   0.2712 | val normalized MSE   0.2416, | val MAE   1.7790 | val MSE  11.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:33<03:22,  4.70s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.005000 | train normalized MSE   0.2551 | val normalized MSE   0.2448, | val MAE   1.8591 | val MSE  11.9964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:38<03:19,  4.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.005000 | train normalized MSE   0.2471 | val normalized MSE   0.2244, | val MAE   1.7467 | val MSE  10.9936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:43<03:14,  4.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.005000 | train normalized MSE   0.2356 | val normalized MSE   0.2133, | val MAE   1.6523 | val MSE  10.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [00:48<03:09,  4.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.002500 | train normalized MSE   0.2689 | val normalized MSE   0.2358, | val MAE   1.8523 | val MSE  11.5523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [00:52<03:03,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.002500 | train normalized MSE   0.2161 | val normalized MSE   0.2059, | val MAE   1.5263 | val MSE  10.0883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:57<02:57,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.002500 | train normalized MSE   0.2074 | val normalized MSE   0.2019, | val MAE   1.5572 | val MSE   9.8921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [01:02<02:53,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.002500 | train normalized MSE   0.2032 | val normalized MSE   0.1953, | val MAE   1.4866 | val MSE   9.5694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [01:06<02:48,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.002500 | train normalized MSE   0.2019 | val normalized MSE   0.1921, | val MAE   1.5037 | val MSE   9.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [01:11<02:44,  4.69s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.002500 | train normalized MSE   0.1995 | val normalized MSE   0.1902, | val MAE   1.4642 | val MSE   9.3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [01:16<02:40,  4.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.002500 | train normalized MSE   0.1998 | val normalized MSE   0.1981, | val MAE   1.5966 | val MSE   9.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [01:21<02:35,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.002500 | train normalized MSE   0.1965 | val normalized MSE   0.1896, | val MAE   1.4800 | val MSE   9.2923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [01:25<02:29,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.002500 | train normalized MSE   0.1947 | val normalized MSE   0.1912, | val MAE   1.5272 | val MSE   9.3664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [01:30<02:25,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.002500 | train normalized MSE   0.1949 | val normalized MSE   0.1968, | val MAE   1.5331 | val MSE   9.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [01:35<02:20,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.001250 | train normalized MSE   0.1970 | val normalized MSE   0.1846, | val MAE   1.4772 | val MSE   9.0444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [01:39<02:15,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.001250 | train normalized MSE   0.1830 | val normalized MSE   0.1752, | val MAE   1.4007 | val MSE   8.5824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [01:44<02:14,  4.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.001250 | train normalized MSE   0.1817 | val normalized MSE   0.1814, | val MAE   1.4576 | val MSE   8.8865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [01:49<02:08,  4.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.001250 | train normalized MSE   0.1800 | val normalized MSE   0.1787, | val MAE   1.3890 | val MSE   8.7565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [01:54<02:03,  4.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.001250 | train normalized MSE   0.1787 | val normalized MSE   0.1815, | val MAE   1.4392 | val MSE   8.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [01:58<01:59,  4.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.001250 | train normalized MSE   0.1794 | val normalized MSE   0.1788, | val MAE   1.4009 | val MSE   8.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [02:03<01:52,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.001250 | train normalized MSE   0.1789 | val normalized MSE   0.1753, | val MAE   1.4199 | val MSE   8.5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [02:08<01:47,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Learning rate 0.001250 | train normalized MSE   0.1764 | val normalized MSE   0.1771, | val MAE   1.4428 | val MSE   8.6783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [02:12<01:42,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Learning rate 0.001250 | train normalized MSE   0.1768 | val normalized MSE   0.1724, | val MAE   1.3996 | val MSE   8.4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [02:17<01:37,  4.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Learning rate 0.001250 | train normalized MSE   0.1782 | val normalized MSE   0.1750, | val MAE   1.3896 | val MSE   8.5759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [02:22<01:32,  4.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Learning rate 0.000625 | train normalized MSE   0.1776 | val normalized MSE   0.1781, | val MAE   1.4039 | val MSE   8.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [02:26<01:28,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.000625 | train normalized MSE   0.1725 | val normalized MSE   0.1717, | val MAE   1.3830 | val MSE   8.4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [02:31<01:23,  4.66s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Learning rate 0.000625 | train normalized MSE   0.1708 | val normalized MSE   0.1673, | val MAE   1.3545 | val MSE   8.1996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 33/50 [02:36<01:19,  4.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Learning rate 0.000625 | train normalized MSE   0.1695 | val normalized MSE   0.1688, | val MAE   1.3442 | val MSE   8.2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 34/50 [02:40<01:14,  4.65s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Learning rate 0.000625 | train normalized MSE   0.1694 | val normalized MSE   0.1770, | val MAE   1.3630 | val MSE   8.6732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [02:45<01:11,  4.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Learning rate 0.000625 | train normalized MSE   0.1689 | val normalized MSE   0.1726, | val MAE   1.3622 | val MSE   8.4556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▏  | 36/50 [02:50<01:06,  4.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.000625 | train normalized MSE   0.1685 | val normalized MSE   0.1709, | val MAE   1.3654 | val MSE   8.3739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  74%|███████▍  | 37/50 [02:55<01:01,  4.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 036 | Learning rate 0.000625 | train normalized MSE   0.1680 | val normalized MSE   0.1690, | val MAE   1.3323 | val MSE   8.2814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  76%|███████▌  | 38/50 [02:59<00:56,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 037 | Learning rate 0.000625 | train normalized MSE   0.1672 | val normalized MSE   0.1701, | val MAE   1.3563 | val MSE   8.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  78%|███████▊  | 39/50 [03:04<00:51,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 038 | Learning rate 0.000625 | train normalized MSE   0.1676 | val normalized MSE   0.1684, | val MAE   1.3265 | val MSE   8.2496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 40/50 [03:09<00:46,  4.67s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 039 | Learning rate 0.000313 | train normalized MSE   0.1682 | val normalized MSE   0.1710, | val MAE   1.3575 | val MSE   8.3786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  82%|████████▏ | 41/50 [03:13<00:42,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 040 | Learning rate 0.000313 | train normalized MSE   0.1660 | val normalized MSE   0.1659, | val MAE   1.3296 | val MSE   8.1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  84%|████████▍ | 42/50 [03:18<00:37,  4.68s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 041 | Learning rate 0.000313 | train normalized MSE   0.1636 | val normalized MSE   0.1685, | val MAE   1.3175 | val MSE   8.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  86%|████████▌ | 43/50 [03:23<00:33,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 042 | Learning rate 0.000313 | train normalized MSE   0.1634 | val normalized MSE   0.1687, | val MAE   1.3850 | val MSE   8.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 44/50 [03:28<00:28,  4.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 043 | Learning rate 0.000313 | train normalized MSE   0.1626 | val normalized MSE   0.1674, | val MAE   1.3394 | val MSE   8.2050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 45/50 [03:32<00:23,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 044 | Learning rate 0.000313 | train normalized MSE   0.1633 | val normalized MSE   0.1690, | val MAE   1.3458 | val MSE   8.2825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▏| 46/50 [03:37<00:18,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 045 | Learning rate 0.000313 | train normalized MSE   0.1620 | val normalized MSE   0.1675, | val MAE   1.3322 | val MSE   8.2062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  94%|█████████▍| 47/50 [03:42<00:14,  4.73s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 046 | Learning rate 0.000313 | train normalized MSE   0.1624 | val normalized MSE   0.1678, | val MAE   1.3541 | val MSE   8.2226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  96%|█████████▌| 48/50 [03:46<00:09,  4.74s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 047 | Learning rate 0.000313 | train normalized MSE   0.1628 | val normalized MSE   0.1663, | val MAE   1.3277 | val MSE   8.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  98%|█████████▊| 49/50 [03:51<00:04,  4.71s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 048 | Learning rate 0.000313 | train normalized MSE   0.1616 | val normalized MSE   0.1700, | val MAE   1.3681 | val MSE   8.3280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 50/50 [03:56<00:00,  4.72s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 049 | Learning rate 0.000156 | train normalized MSE   0.1616 | val normalized MSE   0.1682, | val MAE   1.3362 | val MSE   8.2403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model = LSTM().to(device) \n",
    "\n",
    "\n",
    "# setting Adam with the parameters from Part A (ran with best parameters)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) # You can try different schedulers\n",
    "\n",
    "run_model_with_adam(model, optimizer, scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f0a44",
   "metadata": {},
   "source": [
    "LSTM with Adam optimizer got val MAE  down lowest out of the 3 models (in the 1.3 range) and the val MSE is also the lowest (8.2 range). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aef9bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/50 [00:00<?, ?epoch/s]/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/2808079002.py:71: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future - origin\n",
      "/var/folders/k0/0k4d4ymn0d7_g9v6fws_l0j80000gn/T/ipykernel_257/2808079002.py:62: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  future = future @ R\n",
      "Epoch:   2%|▏         | 1/50 [00:02<01:38,  2.02s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Learning rate 0.001000 | train normalized MSE   2.4924 | val normalized MSE   1.4101, | val MAE   7.1328 | val MSE 141.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   4%|▍         | 2/50 [00:03<01:28,  1.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Learning rate 0.001000 | train normalized MSE   1.0932 | val normalized MSE   0.7870, | val MAE   5.3799 | val MSE  78.6953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   6%|▌         | 3/50 [00:05<01:24,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | Learning rate 0.001000 | train normalized MSE   0.6250 | val normalized MSE   0.4409, | val MAE   3.7792 | val MSE  44.0908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 4/50 [00:07<01:23,  1.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | Learning rate 0.001000 | train normalized MSE   0.3863 | val normalized MSE   0.3318, | val MAE   3.2726 | val MSE  33.1819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 5/50 [00:09<01:21,  1.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | Learning rate 0.001000 | train normalized MSE   0.2947 | val normalized MSE   0.2992, | val MAE   3.0995 | val MSE  29.9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▏        | 6/50 [00:11<01:21,  1.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | Learning rate 0.001000 | train normalized MSE   0.2741 | val normalized MSE   0.2693, | val MAE   2.9807 | val MSE  26.9334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  14%|█▍        | 7/50 [00:12<01:19,  1.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | Learning rate 0.001000 | train normalized MSE   0.2573 | val normalized MSE   0.2342, | val MAE   2.6024 | val MSE  23.4162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  16%|█▌        | 8/50 [00:14<01:18,  1.86s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | Learning rate 0.001000 | train normalized MSE   0.2403 | val normalized MSE   0.2282, | val MAE   2.6923 | val MSE  22.8225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 9/50 [00:16<01:15,  1.83s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | Learning rate 0.001000 | train normalized MSE   0.2283 | val normalized MSE   0.2083, | val MAE   2.4731 | val MSE  20.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 10/50 [00:18<01:11,  1.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | Learning rate 0.000100 | train normalized MSE   0.2151 | val normalized MSE   0.2141, | val MAE   2.7046 | val MSE  21.4127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▏       | 11/50 [00:20<01:10,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Learning rate 0.000100 | train normalized MSE   0.1943 | val normalized MSE   0.1820, | val MAE   2.1960 | val MSE  18.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  24%|██▍       | 12/50 [00:21<01:08,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | Learning rate 0.000100 | train normalized MSE   0.1827 | val normalized MSE   0.1812, | val MAE   2.2297 | val MSE  18.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  26%|██▌       | 13/50 [00:23<01:06,  1.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | Learning rate 0.000100 | train normalized MSE   0.1899 | val normalized MSE   0.1783, | val MAE   2.1908 | val MSE  17.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 14/50 [00:25<01:03,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | Learning rate 0.000100 | train normalized MSE   0.1856 | val normalized MSE   0.1750, | val MAE   2.2164 | val MSE  17.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 15/50 [00:27<01:01,  1.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | Learning rate 0.000100 | train normalized MSE   0.1840 | val normalized MSE   0.1741, | val MAE   2.1970 | val MSE  17.4109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▏      | 16/50 [00:28<00:59,  1.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | Learning rate 0.000100 | train normalized MSE   0.1816 | val normalized MSE   0.1743, | val MAE   2.2100 | val MSE  17.4331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  34%|███▍      | 17/50 [00:30<00:58,  1.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | Learning rate 0.000100 | train normalized MSE   0.1738 | val normalized MSE   0.1702, | val MAE   2.1649 | val MSE  17.0198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  36%|███▌      | 18/50 [00:32<00:56,  1.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | Learning rate 0.000100 | train normalized MSE   0.1792 | val normalized MSE   0.1686, | val MAE   2.1793 | val MSE  16.8618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 19/50 [00:34<00:54,  1.75s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | Learning rate 0.000100 | train normalized MSE   0.1711 | val normalized MSE   0.1648, | val MAE   2.0887 | val MSE  16.4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 20/50 [00:36<00:53,  1.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | Learning rate 0.000010 | train normalized MSE   0.1701 | val normalized MSE   0.1652, | val MAE   2.1061 | val MSE  16.5177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▏     | 21/50 [00:37<00:52,  1.82s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | Learning rate 0.000010 | train normalized MSE   0.1665 | val normalized MSE   0.1635, | val MAE   2.0729 | val MSE  16.3489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  44%|████▍     | 22/50 [00:39<00:50,  1.81s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 021 | Learning rate 0.000010 | train normalized MSE   0.1635 | val normalized MSE   0.1630, | val MAE   2.0753 | val MSE  16.3050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  46%|████▌     | 23/50 [00:41<00:48,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 022 | Learning rate 0.000010 | train normalized MSE   0.1651 | val normalized MSE   0.1625, | val MAE   2.0662 | val MSE  16.2524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 24/50 [00:43<00:46,  1.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 023 | Learning rate 0.000010 | train normalized MSE   0.1659 | val normalized MSE   0.1627, | val MAE   2.0714 | val MSE  16.2708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 25/50 [00:44<00:44,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 024 | Learning rate 0.000010 | train normalized MSE   0.1637 | val normalized MSE   0.1628, | val MAE   2.0693 | val MSE  16.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▏    | 26/50 [00:46<00:43,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 025 | Learning rate 0.000010 | train normalized MSE   0.1644 | val normalized MSE   0.1623, | val MAE   2.0688 | val MSE  16.2265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  54%|█████▍    | 27/50 [00:48<00:41,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 026 | Learning rate 0.000010 | train normalized MSE   0.1676 | val normalized MSE   0.1617, | val MAE   2.0704 | val MSE  16.1691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  56%|█████▌    | 28/50 [00:50<00:39,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 027 | Learning rate 0.000010 | train normalized MSE   0.1691 | val normalized MSE   0.1625, | val MAE   2.0760 | val MSE  16.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  58%|█████▊    | 29/50 [00:52<00:36,  1.76s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 028 | Learning rate 0.000010 | train normalized MSE   0.1636 | val normalized MSE   0.1622, | val MAE   2.0852 | val MSE  16.2237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 30/50 [00:53<00:35,  1.77s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 029 | Learning rate 0.000001 | train normalized MSE   0.1673 | val normalized MSE   0.1620, | val MAE   2.0665 | val MSE  16.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▏   | 31/50 [00:55<00:34,  1.79s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 030 | Learning rate 0.000001 | train normalized MSE   0.1649 | val normalized MSE   0.1619, | val MAE   2.0650 | val MSE  16.1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  64%|██████▍   | 32/50 [00:57<00:32,  1.80s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 031 | Learning rate 0.000001 | train normalized MSE   0.1673 | val normalized MSE   0.1618, | val MAE   2.0657 | val MSE  16.1829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  66%|██████▌   | 33/50 [00:59<00:30,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 032 | Learning rate 0.000001 | train normalized MSE   0.1676 | val normalized MSE   0.1618, | val MAE   2.0663 | val MSE  16.1760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 34/50 [01:01<00:28,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 033 | Learning rate 0.000001 | train normalized MSE   0.1633 | val normalized MSE   0.1617, | val MAE   2.0670 | val MSE  16.1738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [01:02<00:26,  1.78s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 034 | Learning rate 0.000001 | train normalized MSE   0.1646 | val normalized MSE   0.1616, | val MAE   2.0669 | val MSE  16.1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 35/50 [01:04<00:27,  1.85s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 035 | Learning rate 0.000001 | train normalized MSE   0.1636 | val normalized MSE   0.1614, | val MAE   2.0655 | val MSE  16.1394\n",
      "Early stop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model = LSTM().to(device) \n",
    "\n",
    "\n",
    "# setting Adam with the parameters from Part A (ran with best average parameters)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1) # You can try different schedulers\n",
    "\n",
    "run_model_with_adam(model, optimizer, scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd9d2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milestone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
